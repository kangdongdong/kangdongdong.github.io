<!-- build time:Fri Mar 05 2021 16:36:28 GMT+0800 (GMT+08:00) --><!DOCTYPE html><html><head><meta charset="utf-8"><title>HDFS客户端操作 | Hexo</title><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="theme-color" content="#3F51B5"><meta name="keywords" content="代码"><meta name="description" content="客户端环境准备1 将编译hadoop jar包放在路径下（比如：D:\environment\hadoop-2.7.2）2 配置HADOOP_HOME环境变量HADOOP_HOME : D:\environment\hadoop-2.7.23 配置Path环境变量%HADOOP_HOME%\bin4 创建一个Maven工程5 导入相应的依赖坐标+日志添加1234567891011121314151"><meta property="og:type" content="article"><meta property="og:title" content="HDFS客户端操作"><meta property="og:url" content="http://kiedeng.github.io/2020/02/13/HDFS%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%93%8D%E4%BD%9C/index.html"><meta property="og:site_name" content="Hexo"><meta property="og:description" content="客户端环境准备1 将编译hadoop jar包放在路径下（比如：D:\environment\hadoop-2.7.2）2 配置HADOOP_HOME环境变量HADOOP_HOME : D:\environment\hadoop-2.7.23 配置Path环境变量%HADOOP_HOME%\bin4 创建一个Maven工程5 导入相应的依赖坐标+日志添加1234567891011121314151"><meta property="og:locale" content="zh_CN"><meta property="article:published_time" content="2020-02-13T03:16:18.000Z"><meta property="article:modified_time" content="2020-02-28T02:03:37.072Z"><meta property="article:author" content="John Doe"><meta property="article:tag" content="代码"><meta name="twitter:card" content="summary"><link rel="alternate" type="application/atom+xml" title="Hexo" href="../../../../atom.xml"><link rel="shortcut icon" href="../../../../favicon.ico"><link rel="stylesheet" href="../../../../unpkg.com/hexo-theme-material-indigo@latest/css/style.css"><script>window.lazyScripts=[]</script><meta name="generator" content="Hexo 4.2.0"></head><body><div id="loading" class="active"></div><aside id="menu" class="hide"><div class="inner flex-row-vertical"><a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menu-off"><i class="icon icon-lg icon-close"></i></a><div class="brand-wrap" style="background-image:url(../../../../img/brand.jpg)"><div class="brand"><a href="../../../../index.html" class="avatar waves-effect waves-circle waves-light"><img src="../../../../img/avatar.jpg"></a><hgroup class="introduce"><h5 class="nickname">John Doe</h5><a href="mailto:634206017@qq.com" title="634206017@qq.com" class="mail">634206017@qq.com</a></hgroup></div></div><div class="scroll-wrap flex-col"><ul class="nav"><li class="waves-block waves-effect"><a href="../../../../index.html"><i class="icon icon-lg icon-home"></i> 主页</a></li><li class="waves-block waves-effect"><a href="../../../../archives"><i class="icon icon-lg icon-archives"></i> Archives</a></li><li class="waves-block waves-effect"><a href="../../../../tags"><i class="icon icon-lg icon-tags"></i> Tags</a></li><li class="waves-block waves-effect"><a href="../../../../categories"><i class="icon icon-lg icon-th-list"></i> Categories</a></li><li class="waves-block waves-effect"><a href="../../../../https:/github.com/yscoder" target="_blank"><i class="icon icon-lg icon-github"></i> Github</a></li><li class="waves-block waves-effect"><a href="../../../../http:/www.weibo.com/ysweb" target="_blank"><i class="icon icon-lg icon-weibo"></i> Weibo</a></li><li class="waves-block waves-effect"><a href="../../../../custom"><i class="icon icon-lg icon-link"></i> 测试</a></li></ul></div></div></aside><main id="main"><header class="top-header" id="header"><div class="flex-row"><a href="javascript:;" class="header-icon waves-effect waves-circle waves-light on" id="menu-toggle"><i class="icon icon-lg icon-navicon"></i></a><div class="flex-col header-title ellipsis">HDFS客户端操作</div><div class="search-wrap" id="search-wrap"><a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back"><i class="icon icon-lg icon-chevron-left"></i> </a><input type="text" id="key" class="search-input" autocomplete="off" placeholder="输入感兴趣的关键字"> <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="search"><i class="icon icon-lg icon-search"></i></a></div><a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menuShare"><i class="icon icon-lg icon-share-alt"></i></a></div></header><header class="content-header post-header"><div class="container fade-scale"><h1 class="title">HDFS客户端操作</h1><h5 class="subtitle"><time datetime="2020-02-13T03:16:18.000Z" itemprop="datePublished" class="page-time">2020-02-13</time><ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="../../../../categories/HDFS/">HDFS</a><ul class="article-category-list-child"><li class="article-category-list-item"><a class="article-category-list-link" href="../../../../categories/HDFS/Hadoop/">Hadoop</a></li></ul></li></ul></h5></div></header><div class="container body-wrap"><aside class="post-widget"><nav class="post-toc-wrap post-toc-shrink" id="post-toc"><h4>TOC</h4><ol class="post-toc"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#客户端环境准备"><span class="post-toc-number">1.</span> <span class="post-toc-text">客户端环境准备</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#1-将编译hadoop-jar包放在路径下（比如：D-environment-hadoop-2-7-2）"><span class="post-toc-number">1.0.1.</span> <span class="post-toc-text">1 将编译hadoop jar包放在路径下（比如：D:\environment\hadoop-2.7.2）</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#2-配置HADOOP-HOME环境变量"><span class="post-toc-number">1.0.2.</span> <span class="post-toc-text">2 配置HADOOP_HOME环境变量</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#3-配置Path环境变量"><span class="post-toc-number">1.0.3.</span> <span class="post-toc-text">3 配置Path环境变量</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#4-创建一个Maven工程"><span class="post-toc-number">1.0.4.</span> <span class="post-toc-text">4 创建一个Maven工程</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#5-导入相应的依赖坐标-日志添加"><span class="post-toc-number">1.0.5.</span> <span class="post-toc-text">5 导入相应的依赖坐标+日志添加</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#6-创建包名：com-atguigu-hdfs"><span class="post-toc-number">1.0.6.</span> <span class="post-toc-text">6 创建包名：com.atguigu.hdfs</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#7-创建HdfsClient类"><span class="post-toc-number">1.0.7.</span> <span class="post-toc-text">7 创建HdfsClient类</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#8-执行程序"><span class="post-toc-number">1.0.8.</span> <span class="post-toc-text">8 执行程序</span></a></li></ol></li></ol><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#HDFS的API操作"><span class="post-toc-number">2.</span> <span class="post-toc-text">HDFS的API操作</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#HDFS文件上传（测试参数优先级）"><span class="post-toc-number">2.1.</span> <span class="post-toc-text">HDFS文件上传（测试参数优先级）</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#1-编写源代码"><span class="post-toc-number">2.1.1.</span> <span class="post-toc-text">1 编写源代码</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#2-将hdfs-site-xml拷贝到项目的根目录（即资源目录下）"><span class="post-toc-number">2.1.2.</span> <span class="post-toc-text">2 将hdfs-site.xml拷贝到项目的根目录（即资源目录下）</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#3-参数优先级"><span class="post-toc-number">2.1.3.</span> <span class="post-toc-text">3 参数优先级</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#HDFS文件的下载"><span class="post-toc-number">2.2.</span> <span class="post-toc-text">HDFS文件的下载</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#HDFS文件的删除"><span class="post-toc-number">2.3.</span> <span class="post-toc-text">HDFS文件的删除</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#HDFS文件的改名"><span class="post-toc-number">2.4.</span> <span class="post-toc-text">HDFS文件的改名</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#HDFS文件详情的查看"><span class="post-toc-number">2.5.</span> <span class="post-toc-text">HDFS文件详情的查看</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#HDFS的I-O流操作"><span class="post-toc-number">3.</span> <span class="post-toc-text">HDFS的I&#x2F;O流操作</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#HDFS文件上传"><span class="post-toc-number">3.1.</span> <span class="post-toc-text">HDFS文件上传</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#HDFS文件下载"><span class="post-toc-number">3.2.</span> <span class="post-toc-text">HDFS文件下载</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#定位文件读取"><span class="post-toc-number">3.3.</span> <span class="post-toc-text">定位文件读取</span></a></li></ol></li></nav></aside><article id="post-HDFS客户端操作" class="post-article article-type-post fade" itemprop="blogPost"><div class="post-card"><h1 class="post-card-title">HDFS客户端操作</h1><div class="post-meta"><time class="post-time" title="2020-02-13 11:16:18" datetime="2020-02-13T03:16:18.000Z" itemprop="datePublished">2020-02-13</time><ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="../../../../categories/HDFS/">HDFS</a><ul class="article-category-list-child"><li class="article-category-list-item"><a class="article-category-list-link" href="../../../../categories/HDFS/Hadoop/">Hadoop</a></li></ul></li></ul><span id="busuanzi_container_page_pv" title="文章总阅读量" style="display:none"><i class="icon icon-eye icon-pr"></i><span id="busuanzi_value_page_pv"></span></span></div><div class="post-content" id="post-content" itemprop="postContent"><h2 id="客户端环境准备"><a href="#客户端环境准备" class="headerlink" title="客户端环境准备"></a>客户端环境准备</h2><h4 id="1-将编译hadoop-jar包放在路径下（比如：D-environment-hadoop-2-7-2）"><a href="#1-将编译hadoop-jar包放在路径下（比如：D-environment-hadoop-2-7-2）" class="headerlink" title="1 将编译hadoop jar包放在路径下（比如：D:\environment\hadoop-2.7.2）"></a>1 将编译hadoop jar包放在路径下（比如：D:\environment\hadoop-2.7.2）</h4><h4 id="2-配置HADOOP-HOME环境变量"><a href="#2-配置HADOOP-HOME环境变量" class="headerlink" title="2 配置HADOOP_HOME环境变量"></a>2 配置HADOOP_HOME环境变量</h4><blockquote><p>HADOOP_HOME : D:\environment\hadoop-2.7.2</p></blockquote><h4 id="3-配置Path环境变量"><a href="#3-配置Path环境变量" class="headerlink" title="3 配置Path环境变量"></a>3 配置Path环境变量</h4><blockquote><p>%HADOOP_HOME%\bin</p></blockquote><h4 id="4-创建一个Maven工程"><a href="#4-创建一个Maven工程" class="headerlink" title="4 创建一个Maven工程"></a>4 创建一个Maven工程</h4><h4 id="5-导入相应的依赖坐标-日志添加"><a href="#5-导入相应的依赖坐标-日志添加" class="headerlink" title="5 导入相应的依赖坐标+日志添加"></a>5 导入相应的依赖坐标+日志添加</h4><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">"http://maven.apache.org/POM/4.0.0"</span> <span class="attr">xmlns:xsi</span>=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span> <span class="attr">xsi:schemaLocation</span>=<span class="string">"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.atguigu<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>HDFS-0529<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.0.1-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">  </span><br><span class="line">  <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>RELEASE<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.logging.log4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>log4j-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>2.8.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-common<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-hdfs<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>2.7.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>jdk.tools<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>jdk.tools<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">version</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">scope</span>&gt;</span>system<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">			<span class="tag">&lt;<span class="name">systemPath</span>&gt;</span>$&#123;JAVA_HOME&#125;/lib/tools.jar<span class="tag">&lt;/<span class="name">systemPath</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line">  </span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br></pre></td></tr></table></figure><p>需要再项目的src/main/resources目录下，新建一个文件，命令为”log4j.properties”,在文件中填写</p><blockquote><p>log4j.rootLogger=INFO, stdout</p><p>log4j.appender.stdout=org.apache.log4j.ConsoleAppender</p><p>log4j.appender.stdout.layout=org.apache.log4j.PatternLayout</p><p>log4j.appender.stdout.layout.ConversionPattern=%d %p [%c] - %m%n</p><p>log4j.appender.logfile=org.apache.log4j.FileAppender</p><p>log4j.appender.logfile.File=target/spring.log</p><p>log4j.appender.logfile.layout=org.apache.log4j.PatternLayout</p><p>log4j.appender.logfile.layout.ConversionPattern=%d %p [%c] - %m%n</p></blockquote><h4 id="6-创建包名：com-atguigu-hdfs"><a href="#6-创建包名：com-atguigu-hdfs" class="headerlink" title="6 创建包名：com.atguigu.hdfs"></a>6 创建包名：com.atguigu.hdfs</h4><h4 id="7-创建HdfsClient类"><a href="#7-创建HdfsClient类" class="headerlink" title="7 创建HdfsClient类"></a>7 创建HdfsClient类</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HdfsClient</span></span>&#123;	</span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testMkdirs</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException, URISyntaxException</span>&#123;</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 1 获取文件系统</span></span><br><span class="line">		Configuration configuration = <span class="keyword">new</span> Configuration();</span><br><span class="line">		<span class="comment">// 配置在集群上运行</span></span><br><span class="line">		<span class="comment">// configuration.set("fs.defaultFS", "hdfs://hadoop102:9000");</span></span><br><span class="line">		<span class="comment">// FileSystem fs = FileSystem.get(configuration);</span></span><br><span class="line"></span><br><span class="line">		FileSystem fs = FileSystem.get(<span class="keyword">new</span> URI(<span class="string">"hdfs://hadoop102:9000"</span>), configuration, <span class="string">"atguigu"</span>);</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 2 创建目录</span></span><br><span class="line">		fs.mkdirs(<span class="keyword">new</span> Path(<span class="string">"/1108/daxian/banzhang"</span>));</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 3 关闭资源</span></span><br><span class="line">		fs.close();</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="8-执行程序"><a href="#8-执行程序" class="headerlink" title="8 执行程序"></a>8 执行程序</h4><blockquote><p>客户端去操作HDFS时，是有一个用户身份的。</p><p>默认情况下，HDFS客户端API会从JVM中获取一个参数来作为自己的用户身份：-DHADOOP_USER_NAME=atguigu，atguigu为用户名称。</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">		<span class="comment">// 配置文件</span></span><br><span class="line">		Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">		conf.set(<span class="string">"fs.defaultFS"</span>, <span class="string">"hdfs://hadoop102:9000"</span>);</span><br><span class="line">		<span class="comment">// 获取客户端对象</span></span><br><span class="line">		FileSystem fs = FileSystem.get(conf);</span><br><span class="line">		fs.mkdirs(<span class="keyword">new</span> Path(<span class="string">"/kangdong"</span>));</span><br><span class="line">		<span class="comment">// 关闭客户端</span></span><br><span class="line">		fs.close();</span><br><span class="line">		System.out.println(<span class="string">"Over!"</span>);</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure><h2 id="HDFS的API操作"><a href="#HDFS的API操作" class="headerlink" title="HDFS的API操作"></a>HDFS的API操作</h2><h3 id="HDFS文件上传（测试参数优先级）"><a href="#HDFS文件上传（测试参数优先级）" class="headerlink" title="HDFS文件上传（测试参数优先级）"></a>HDFS文件上传（测试参数优先级）</h3><h4 id="1-编写源代码"><a href="#1-编写源代码" class="headerlink" title="1 编写源代码"></a>1 编写源代码</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">		<span class="comment">// 配置文件</span></span><br><span class="line">		Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">		conf.set(<span class="string">"fs.defaultFS"</span>, <span class="string">"hdfs://hadoop102:9000"</span>);</span><br><span class="line">		<span class="comment">// 获取客户端对象</span></span><br><span class="line">		FileSystem fs = FileSystem.get(conf);</span><br><span class="line">		fs.mkdirs(<span class="keyword">new</span> Path(<span class="string">"/kangdong"</span>));</span><br><span class="line">		<span class="comment">// 关闭客户端</span></span><br><span class="line">		fs.close();</span><br><span class="line">		System.out.println(<span class="string">"Over!"</span>);</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure><h4 id="2-将hdfs-site-xml拷贝到项目的根目录（即资源目录下）"><a href="#2-将hdfs-site-xml拷贝到项目的根目录（即资源目录下）" class="headerlink" title="2 将hdfs-site.xml拷贝到项目的根目录（即资源目录下）"></a>2 将hdfs-site.xml拷贝到项目的根目录（即资源目录下）</h4><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><h4 id="3-参数优先级"><a href="#3-参数优先级" class="headerlink" title="3 参数优先级"></a>3 参数优先级</h4><blockquote><p>参数优先级排序：（1）客户端代码中设置的值 &gt;（2）ClassPath下的用户自定义配置文件 &gt;（3）然后是服务器的默认配置</p></blockquote><h3 id="HDFS文件的下载"><a href="#HDFS文件的下载" class="headerlink" title="HDFS文件的下载"></a>HDFS文件的下载</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// boolean delSrc 指是否将原文件删除</span></span><br><span class="line"><span class="comment">// Path src 指要下载的文件路径</span></span><br><span class="line"><span class="comment">// Path dst 指将文件下载到的路径</span></span><br><span class="line"><span class="comment">// boolean useRawLocalFileSystem 是否开启文件校验</span></span><br><span class="line">fs.copyToLocalFile(<span class="keyword">false</span>, <span class="keyword">new</span> Path(<span class="string">"/banzhang.txt"</span>), <span class="keyword">new</span> Path(<span class="string">"e:/banhua.txt"</span>), <span class="keyword">true</span>);</span><br></pre></td></tr></table></figure><h3 id="HDFS文件的删除"><a href="#HDFS文件的删除" class="headerlink" title="HDFS文件的删除"></a>HDFS文件的删除</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fs.delete(<span class="keyword">new</span> Path(<span class="string">"/0508/"</span>), <span class="keyword">true</span>);<span class="comment">//第一参数是路径，第二个参数是判断是否递归删除</span></span><br></pre></td></tr></table></figure><h3 id="HDFS文件的改名"><a href="#HDFS文件的改名" class="headerlink" title="HDFS文件的改名"></a>HDFS文件的改名</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fs.rename(<span class="keyword">new</span> Path(<span class="string">"/banzhang.txt"</span>), <span class="keyword">new</span> Path(<span class="string">"/banhua.txt"</span>));</span><br></pre></td></tr></table></figure><h3 id="HDFS文件详情的查看"><a href="#HDFS文件详情的查看" class="headerlink" title="HDFS文件详情的查看"></a>HDFS文件详情的查看</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testListFiles</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException, URISyntaxException</span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 1获取文件系统</span></span><br><span class="line">	Configuration configuration = <span class="keyword">new</span> Configuration();</span><br><span class="line">	FileSystem fs = FileSystem.get(<span class="keyword">new</span> URI(<span class="string">"hdfs://hadoop102:9000"</span>), configuration, <span class="string">"atguigu"</span>); </span><br><span class="line">		</span><br><span class="line">	<span class="comment">// 2 获取文件详情</span></span><br><span class="line">	RemoteIterator&lt;LocatedFileStatus&gt; listFiles = fs.listFiles(<span class="keyword">new</span> Path(<span class="string">"/"</span>), <span class="keyword">true</span>);</span><br><span class="line">		</span><br><span class="line">	<span class="keyword">while</span>(listFiles.hasNext())&#123;</span><br><span class="line">		LocatedFileStatus status = listFiles.next();</span><br><span class="line">			</span><br><span class="line">		<span class="comment">// 输出详情</span></span><br><span class="line">		<span class="comment">// 文件名称</span></span><br><span class="line">		System.out.println(status.getPath().getName());</span><br><span class="line">		<span class="comment">// 长度</span></span><br><span class="line">		System.out.println(status.getLen());</span><br><span class="line">		<span class="comment">// 权限</span></span><br><span class="line">		System.out.println(status.getPermission());</span><br><span class="line">		<span class="comment">// 分组</span></span><br><span class="line">		System.out.println(status.getGroup());</span><br><span class="line">			</span><br><span class="line">		<span class="comment">// 获取存储的块信息</span></span><br><span class="line">		BlockLocation[] blockLocations = status.getBlockLocations();</span><br><span class="line">			</span><br><span class="line">		<span class="keyword">for</span> (BlockLocation blockLocation : blockLocations) &#123;</span><br><span class="line">				</span><br><span class="line">			<span class="comment">// 获取块存储的主机节点</span></span><br><span class="line">			String[] hosts = blockLocation.getHosts();</span><br><span class="line">				</span><br><span class="line">			<span class="keyword">for</span> (String host : hosts) &#123;</span><br><span class="line">				System.out.println(host);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">			</span><br><span class="line">		System.out.println(<span class="string">"-----------班长的分割线----------"</span>);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 3 关闭资源</span></span><br><span class="line">fs.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="HDFS的I-O流操作"><a href="#HDFS的I-O流操作" class="headerlink" title="HDFS的I/O流操作"></a>HDFS的I/O流操作</h2><h3 id="HDFS文件上传"><a href="#HDFS文件上传" class="headerlink" title="HDFS文件上传"></a>HDFS文件上传</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">IOcopyFromLocal</span><span class="params">()</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">		Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">		FileSystem fs = FileSystem.get(<span class="keyword">new</span> URI(<span class="string">"hdfs://hadoop102:9000"</span>), conf, <span class="string">"atguigu"</span>);</span><br><span class="line">		FileInputStream fis = <span class="keyword">new</span> FileInputStream(<span class="keyword">new</span> File(<span class="string">"d:/kiedeng.txt"</span>));</span><br><span class="line">		FSDataOutputStream fout = fs.create(<span class="keyword">new</span> Path(<span class="string">"/kg.txt"</span>));</span><br><span class="line">		IOUtils.copyBytes(fis, fout, conf);</span><br><span class="line">		</span><br><span class="line">		IOUtils.closeStream(fis);</span><br><span class="line">		IOUtils.closeStream(fout);</span><br><span class="line">		fs.close();</span><br><span class="line">		</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure><h3 id="HDFS文件下载"><a href="#HDFS文件下载" class="headerlink" title="HDFS文件下载"></a>HDFS文件下载</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 文件下载</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">getFileFromHDFS</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException, URISyntaxException</span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 1 获取文件系统</span></span><br><span class="line">	Configuration configuration = <span class="keyword">new</span> Configuration();</span><br><span class="line">	FileSystem fs = FileSystem.get(<span class="keyword">new</span> URI(<span class="string">"hdfs://hadoop102:9000"</span>), configuration, <span class="string">"atguigu"</span>);</span><br><span class="line">		</span><br><span class="line">	<span class="comment">// 2 获取输入流</span></span><br><span class="line">	FSDataInputStream fis = fs.open(<span class="keyword">new</span> Path(<span class="string">"/banhua.txt"</span>));</span><br><span class="line">		</span><br><span class="line">	<span class="comment">// 3 获取输出流</span></span><br><span class="line">	FileOutputStream fos = <span class="keyword">new</span> FileOutputStream(<span class="keyword">new</span> File(<span class="string">"e:/banhua.txt"</span>));</span><br><span class="line">		</span><br><span class="line">	<span class="comment">// 4 流的对拷</span></span><br><span class="line">	IOUtils.copyBytes(fis, fos, configuration);</span><br><span class="line">		</span><br><span class="line">	<span class="comment">// 5 关闭资源</span></span><br><span class="line">	IOUtils.closeStream(fos);</span><br><span class="line">	IOUtils.closeStream(fis);</span><br><span class="line">	fs.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="定位文件读取"><a href="#定位文件读取" class="headerlink" title="定位文件读取"></a>定位文件读取</h3><ol><li><p>下载第一块</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">readFileSeek1</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException, URISyntaxException</span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 1 获取文件系统</span></span><br><span class="line">	Configuration configuration = <span class="keyword">new</span> Configuration();</span><br><span class="line">	FileSystem fs = FileSystem.get(<span class="keyword">new</span> URI(<span class="string">"hdfs://hadoop102:9000"</span>), configuration, <span class="string">"atguigu"</span>);</span><br><span class="line">		</span><br><span class="line">	<span class="comment">// 2 获取输入流</span></span><br><span class="line">	FSDataInputStream fis = fs.open(<span class="keyword">new</span> Path(<span class="string">"/hadoop-2.7.2.tar.gz"</span>));</span><br><span class="line">		</span><br><span class="line">	<span class="comment">// 3 创建输出流</span></span><br><span class="line">	FileOutputStream fos = <span class="keyword">new</span> FileOutputStream(<span class="keyword">new</span> File(<span class="string">"e:/hadoop-2.7.2.tar.gz.part1"</span>));</span><br><span class="line">		</span><br><span class="line">	<span class="comment">// 4 流的拷贝</span></span><br><span class="line">	<span class="keyword">byte</span>[] buf = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">1024</span>];</span><br><span class="line">		</span><br><span class="line">	<span class="keyword">for</span>(<span class="keyword">int</span> i =<span class="number">0</span> ; i &lt; <span class="number">1024</span> * <span class="number">128</span>; i++)&#123;</span><br><span class="line">		fis.read(buf);</span><br><span class="line">		fos.write(buf);</span><br><span class="line">	&#125;</span><br><span class="line">		</span><br><span class="line">	<span class="comment">// 5关闭资源</span></span><br><span class="line">	IOUtils.closeStream(fis);</span><br><span class="line">	IOUtils.closeStream(fos);</span><br><span class="line">fs.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>下载第二块</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">readFileSeek2</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException, URISyntaxException</span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 1 获取文件系统</span></span><br><span class="line">	Configuration configuration = <span class="keyword">new</span> Configuration();</span><br><span class="line">	FileSystem fs = FileSystem.get(<span class="keyword">new</span> URI(<span class="string">"hdfs://hadoop102:9000"</span>), configuration, <span class="string">"atguigu"</span>);</span><br><span class="line">		</span><br><span class="line">	<span class="comment">// 2 打开输入流</span></span><br><span class="line">	FSDataInputStream fis = fs.open(<span class="keyword">new</span> Path(<span class="string">"/hadoop-2.7.2.tar.gz"</span>));</span><br><span class="line">		</span><br><span class="line">	<span class="comment">// 3 定位输入数据位置</span></span><br><span class="line">	fis.seek(<span class="number">1024</span>*<span class="number">1024</span>*<span class="number">128</span>);</span><br><span class="line">		</span><br><span class="line">	<span class="comment">// 4 创建输出流</span></span><br><span class="line">	FileOutputStream fos = <span class="keyword">new</span> FileOutputStream(<span class="keyword">new</span> File(<span class="string">"e:/hadoop-2.7.2.tar.gz.part2"</span>));</span><br><span class="line">		</span><br><span class="line">	<span class="comment">// 5 流的对拷</span></span><br><span class="line">	IOUtils.copyBytes(fis, fos, configuration);</span><br><span class="line">		</span><br><span class="line">	<span class="comment">// 6 关闭资源</span></span><br><span class="line">	IOUtils.closeStream(fis);</span><br><span class="line">	IOUtils.closeStream(fos);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>合并文件</p><blockquote><p>​ 在Window命令窗口中进入到目录E:\，然后执行如下命令，对数据进行合并</p><p>​ type hadoop-2.7.2.tar.gz.part2 &gt;&gt; hadoop-2.7.2.tar.gz.part1</p><p>合并完成后，将hadoop-2.7.2.tar.gz.part1重新命名为hadoop-2.7.2.tar.gz。解压发现该tar包非常完整。</p></blockquote></li></ol></div><blockquote class="post-copyright"><div class="content"><span class="post-time">最后更新时间：<time datetime="2020-02-28T02:03:37.072Z" itemprop="dateUpdated">2020-02-28 10:03:37</time></span><br>这里可以写作者留言，标签和 hexo 中所有变量及辅助函数等均可调用，示例：<a href="" target="_blank" rel="external">http://kiedeng.github.io/2020/02/13/HDFS%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%93%8D%E4%BD%9C/</a></div><footer><a href="http://kiedeng.github.io"><img src="../../../../img/avatar.jpg" alt="John Doe"> John Doe</a></footer></blockquote><div class="page-reward"><a id="rewardBtn" href="javascript:;" class="page-reward-btn waves-effect waves-circle waves-light">赏</a></div><div class="post-footer"><ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="../../../../tags/%E4%BB%A3%E7%A0%81/" rel="tag">代码</a></li></ul><div class="page-share-wrap"><div class="page-share" id="pageShare"><ul class="reset share-icons"><li><a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=http://kiedeng.github.io/2020/02/13/HDFS%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%93%8D%E4%BD%9C/&title=《HDFS客户端操作》 — Hexo&pic=http://kiedeng.github.io/img/avatar.jpg" data-title="微博"><i class="icon icon-weibo"></i></a></li><li><a class="weixin share-sns wxFab" href="javascript:;" data-title="微信"><i class="icon icon-weixin"></i></a></li><li><a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://kiedeng.github.io/2020/02/13/HDFS%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%93%8D%E4%BD%9C/&title=《HDFS客户端操作》 — Hexo&source=" data-title=" QQ"><i class="icon icon-qq"></i></a></li><li><a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http://kiedeng.github.io/2020/02/13/HDFS%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%93%8D%E4%BD%9C/" data-title=" Facebook"><i class="icon icon-facebook"></i></a></li><li><a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《HDFS客户端操作》 — Hexo&url=http://kiedeng.github.io/2020/02/13/HDFS%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%93%8D%E4%BD%9C/&via=http://kiedeng.github.io" data-title=" Twitter"><i class="icon icon-twitter"></i></a></li><li><a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=http://kiedeng.github.io/2020/02/13/HDFS%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%93%8D%E4%BD%9C/" data-title=" Google+"><i class="icon icon-google-plus"></i></a></li></ul></div><a href="javascript:;" id="shareFab" class="page-share-fab waves-effect waves-circle"><i class="icon icon-share-alt icon-lg"></i></a></div></div></div><nav class="post-nav flex-row flex-justify-between"><div class="waves-block waves-effect prev"><a href="../HDFS%E7%9A%84%E6%95%B0%E6%8D%AE%E6%B5%81/" id="post-prev" class="post-nav-link"><div class="tips"><i class="icon icon-angle-left icon-lg icon-pr"></i> Prev</div><h4 class="title">HDFS的数据流</h4></a></div><div class="waves-block waves-effect next"><a href="../../12/Hadoop%E7%BC%96%E8%AF%91%E6%BA%90%E7%A0%81/" id="post-next" class="post-nav-link"><div class="tips">Next <i class="icon icon-angle-right icon-lg icon-pl"></i></div><h4 class="title">Hadoop编译源码</h4></a></div></nav></article><div id="reward" class="page-modal reward-lay"><a class="close" href="javascript:;"><i class="icon icon-close"></i></a><h3 class="reward-title"><i class="icon icon-quote-left"></i> 谢谢大爷~ <i class="icon icon-quote-right"></i></h3><div class="reward-content"><div class="reward-code"><img id="rewardCode" src="../../../../img/wechat.jpg" alt="打赏二维码"></div><label class="reward-toggle"><input id="rewardToggle" type="checkbox" class="reward-toggle-check" data-wechat="../../../../img/wechat.jpg" data-alipay="../../../../img/alipay.jpg"><div class="reward-toggle-ctrol"><span class="reward-toggle-item wechat">微信</span> <span class="reward-toggle-label"></span> <span class="reward-toggle-item alipay">支付宝</span></div></label></div></div></div><footer class="footer"><div class="top"><p><span id="busuanzi_container_site_uv" style="display:none">站点总访客数：<span id="busuanzi_value_site_uv"></span> </span><span id="busuanzi_container_site_pv" style="display:none">站点总访问量：<span id="busuanzi_value_site_pv"></span></span></p><p><span><a href="../../../../atom.xml" target="_blank" class="rss" title="rss"><i class="icon icon-lg icon-rss"></i></a></span> <span>博客内容遵循 <a rel="license noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank">知识共享 署名 - 非商业性 - 相同方式共享 4.0 国际协议</a></span></p></div><div class="bottom"><p><span>John Doe &copy; 2015 - 2021</span> <span>Power by <a href="http://hexo.io/" target="_blank">Hexo</a> Theme <a href="https://github.com/yscoder/hexo-theme-indigo" target="_blank">indigo</a></span></p></div></footer></main><div class="mask" id="mask"></div><a href="javascript:;" id="gotop" class="waves-effect waves-circle waves-light"><span class="icon icon-lg icon-chevron-up"></span></a><div class="global-share" id="globalShare"><ul class="reset share-icons"><li><a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=http://kiedeng.github.io/2020/02/13/HDFS%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%93%8D%E4%BD%9C/&title=《HDFS客户端操作》 — Hexo&pic=http://kiedeng.github.io/img/avatar.jpg" data-title="微博"><i class="icon icon-weibo"></i></a></li><li><a class="weixin share-sns wxFab" href="javascript:;" data-title="微信"><i class="icon icon-weixin"></i></a></li><li><a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://kiedeng.github.io/2020/02/13/HDFS%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%93%8D%E4%BD%9C/&title=《HDFS客户端操作》 — Hexo&source=" data-title=" QQ"><i class="icon icon-qq"></i></a></li><li><a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http://kiedeng.github.io/2020/02/13/HDFS%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%93%8D%E4%BD%9C/" data-title=" Facebook"><i class="icon icon-facebook"></i></a></li><li><a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《HDFS客户端操作》 — Hexo&url=http://kiedeng.github.io/2020/02/13/HDFS%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%93%8D%E4%BD%9C/&via=http://kiedeng.github.io" data-title=" Twitter"><i class="icon icon-twitter"></i></a></li><li><a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=http://kiedeng.github.io/2020/02/13/HDFS%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%93%8D%E4%BD%9C/" data-title=" Google+"><i class="icon icon-google-plus"></i></a></li></ul></div><div class="page-modal wx-share" id="wxShare"><a class="close" href="javascript:;"><i class="icon icon-close"></i></a><p>扫一扫，分享到微信</p><img src="//api.qrserver.com/v1/create-qr-code/?data=http://kiedeng.github.io/2020/02/13/HDFS%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%93%8D%E4%BD%9C/" alt="微信分享二维码"></div><script src="//cdn.bootcss.com/node-waves/0.7.4/waves.min.js"></script><script>var BLOG={ROOT:"/",SHARE:!0,REWARD:!0}</script><script src="../../../../unpkg.com/hexo-theme-material-indigo@latest/js/main.min.js"></script><div class="search-panel" id="search-panel"><ul class="search-result" id="search-result"></ul></div><template id="search-tpl"><li class="item"><a href="{path}" class="waves-block waves-effect"><div class="title ellipsis" title="{title}">{title}</div><div class="flex-row flex-middle"><div class="tags ellipsis">{tags}</div><time class="flex-col time">{date}</time></div></a></li></template><script src="../../../../unpkg.com/hexo-theme-material-indigo@latest/js/search.min.js" async></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script>!function(){var t,e=document.title;document.addEventListener("visibilitychange",function(){document.hidden?(document.title="死鬼去哪里了！",clearTimeout(t)):(document.title="(つェ⊂)咦!又好了!",t=setTimeout(function(){document.title=e},2e3))})}()</script></body></html><!-- rebuild by neat -->