<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>学习印记</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://kiedeng.github.io/"/>
  <updated>2020-05-17T09:14:14.771Z</updated>
  <id>http://kiedeng.github.io/</id>
  
  <author>
    <name>康栋</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>数据采集模块</title>
    <link href="http://kiedeng.github.io/2020/05/17/%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E6%A8%A1%E5%9D%97/"/>
    <id>http://kiedeng.github.io/2020/05/17/%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E6%A8%A1%E5%9D%97/</id>
    <published>2020-05-17T07:01:50.000Z</published>
    <updated>2020-05-17T09:14:14.771Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Mar 05 2021 21:11:12 GMT+0800 (GMT+08:00) --><h2 id="一，hadoop安装"><a href="#一，hadoop安装" class="headerlink" title="一，hadoop安装"></a>一，hadoop安装</h2><h3 id="1-HDFS存储多目录"><a href="#1-HDFS存储多目录" class="headerlink" title="1 HDFS存储多目录"></a>1 HDFS存储多目录</h3><p>在hdfs-site.xml中操作</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.datanode.data.dir&lt;&#x2F;name&gt;</span><br><span class="line">&lt;value&gt;file:&#x2F;&#x2F;&#x2F;$&#123;hadoop.tmp.dir&#125;&#x2F;dfs&#x2F;data1,file:&#x2F;&#x2F;&#x2F;hd2&#x2F;dfs&#x2F;data2,file:&#x2F;&#x2F;&#x2F;hd3&#x2F;dfs&#x2F;data3,file:&#x2F;&#x2F;&#x2F;hd4&#x2F;dfs&#x2F;data4&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br></pre></td></tr></table></figure><p>数据平衡指令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;start-balancer.sh –threshold 10</span><br><span class="line">## 对于参数10，代表的是集群中各个节点的磁盘空间利用率相差不超过10%</span><br><span class="line">bin&#x2F;stop-balancer.sh</span><br></pre></td></tr></table></figure><h3 id="2-支持LZO压缩配置"><a href="#2-支持LZO压缩配置" class="headerlink" title="2 支持LZO压缩配置"></a>2 支持LZO压缩配置</h3><ul><li><p>将编译好的hadoop-lzo-0.4.20.jar 放入hadoop-2.7.2/share/hadoop/common/，并且分发给其他hadoop机器</p></li><li><p>core-site.xml增加配置支持LZO压缩，并分发给其他机器</p></li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>io.compression.codecs<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span></span><br><span class="line">org.apache.hadoop.io.compress.GzipCodec,</span><br><span class="line">org.apache.hadoop.io.compress.DefaultCodec,</span><br><span class="line">org.apache.hadoop.io.compress.BZip2Codec,</span><br><span class="line">org.apache.hadoop.io.compress.SnappyCodec,</span><br><span class="line">com.hadoop.compression.lzo.LzoCodec,</span><br><span class="line">com.hadoop.compression.lzo.LzopCodec</span><br><span class="line"><span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>io.compression.codec.lzo.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.hadoop.compression.lzo.LzoCodec<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li>重启集群</li></ul><h3 id="3-LZO创建索引"><a href="#3-LZO创建索引" class="headerlink" title="3 LZO创建索引"></a>3 LZO创建索引</h3><p>LZO的可切片特性依赖于索引，所以需要为LZO压缩文件创建索引</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar &#x2F;opt&#x2F;module&#x2F;hadoop-2.7.2&#x2F;share&#x2F;hadoop&#x2F;common&#x2F;hadoop-lzo-0.4.20.jar  com.hadoop.compression.lzo.DistributedLzoIndexer &#x2F;input&#x2F;bigtable.lzo</span><br><span class="line"></span><br><span class="line"># hadoop jar (lzo的jar文件) com.hadoop.compression.lzo.DistributedLzoIndexer (输出文件)</span><br></pre></td></tr></table></figure><h3 id="4-基准测试"><a href="#4-基准测试" class="headerlink" title="4 基准测试"></a>4 基准测试</h3><p>1）测试写性能</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar &#x2F;opt&#x2F;module&#x2F;hadoop-2.7.2&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;hadoop-mapreduce-client-jobclient-2.7.2-tests.jar TestDFSIO -write -nrFiles 10 -fileSize 128MB</span><br></pre></td></tr></table></figure><p>2）测试读性能</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar &#x2F;opt&#x2F;module&#x2F;hadoop-2.7.2&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;hadoop-mapreduce-client-jobclient-2.7.2-tests.jar TestDFSIO -read -nrFiles 10 -fileSize 128MB</span><br></pre></td></tr></table></figure><p>3）测试删除生成数据</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar &#x2F;opt&#x2F;module&#x2F;hadoop-2.7.2&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;hadoop-mapreduce-client-jobclient-2.7.2-tests.jar TestDFSIO -clean</span><br></pre></td></tr></table></figure><h3 id="5-Hadoop参数调优"><a href="#5-Hadoop参数调优" class="headerlink" title="5 Hadoop参数调优"></a>5 Hadoop参数调优</h3><p>1 hdfs-site.xml</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">dfs.namenode.handler.count&#x3D;20 * log2(Cluster Size)，比如集群规模为8台时，此参数设置为60</span><br><span class="line"></span><br><span class="line">NameNode有一个工作线程池，用来处理不同DataNode的并发心跳以及客户端并发的元数据操作。</span><br><span class="line">对于大集群或者有大量客户端的集群来说，通常需要增大参数dfs.namenode.handler.count的默认值10。</span><br><span class="line">设置该值的一般原则是将其设置为集群大小的自然对数乘以20，即20logN，N为集群大小。</span><br></pre></td></tr></table></figure><p>2 参数调优yarn-site.xml</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">内存利用率不够。</span><br><span class="line">这个一般是Yarn的2个配置造成的，单个任务可以申请的最大内存大小，和Hadoop单个节点可用内存大小。调节这两个参数能提高系统内存的利用率。</span><br><span class="line">（a）yarn.nodemanager.resource.memory-mb</span><br><span class="line">表示该节点上YARN可使用的物理内存总量，默认是8192（MB），</span><br><span class="line">注意，如果你的节点内存资源不够8GB，则需要调减小这个值，而YARN不会智能的探测节点的物理内存总量。</span><br><span class="line">（b）yarn.scheduler.maximum-allocation-mb</span><br><span class="line">单个任务可申请的最多物理内存量，默认是8192（MB）。</span><br></pre></td></tr></table></figure><p>3 Hadoop宕机</p><ul><li><p>如果<strong>MR造成系统宕机</strong>。此时要控制Yarn同时运行的任务数，和每个任务申请的最大内存。</p></li><li><p>如果写入文件过量造成<strong>NameNode宕机</strong>。那么调高Kafka的存储大小，控制从Kafka到HDFS的写入速度。</p></li></ul><h2 id="二，Zookeeper安装"><a href="#二，Zookeeper安装" class="headerlink" title="二，Zookeeper安装"></a>二，Zookeeper安装</h2><h2 id="三，日志生成"><a href="#三，日志生成" class="headerlink" title="三，日志生成"></a>三，日志生成</h2><h2 id="四，采集日志Flume"><a href="#四，采集日志Flume" class="headerlink" title="四，采集日志Flume"></a>四，采集日志Flume</h2><h2 id="五，Kafka安装"><a href="#五，Kafka安装" class="headerlink" title="五，Kafka安装"></a>五，Kafka安装</h2><p>六</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Mar 05 2021 21:11:12 GMT+0800 (GMT+08:00) --&gt;&lt;h2 id=&quot;一，hadoop安装&quot;&gt;&lt;a href=&quot;#一，hadoop安装&quot; class=&quot;headerlink&quot; title=&quot;一，hadoo
      
    
    </summary>
    
    
      <category term="hadoop" scheme="http://kiedeng.github.io/categories/hadoop/"/>
    
    
      <category term="默认" scheme="http://kiedeng.github.io/tags/%E9%BB%98%E8%AE%A4/"/>
    
  </entry>
  
  <entry>
    <title>安装superset</title>
    <link href="http://kiedeng.github.io/2020/05/17/%E5%AE%89%E8%A3%85superset/"/>
    <id>http://kiedeng.github.io/2020/05/17/%E5%AE%89%E8%A3%85superset/</id>
    <published>2020-05-17T02:31:34.000Z</published>
    <updated>2020-05-17T02:47:16.263Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Mar 05 2021 21:11:12 GMT+0800 (GMT+08:00) --><p>概述：Apache Superset是一个开源的、现代的、轻量级BI分析工具，能够对接多种数据源、拥有丰富的图标展示形式、支持自定义仪表盘，且拥有友好的用户界面，十分易用。</p><h2 id="1-安装python环境"><a href="#1-安装python环境" class="headerlink" title="1 安装python环境"></a>1 安装python环境</h2><h3 id="安装Miniconda"><a href="#安装Miniconda" class="headerlink" title="安装Miniconda"></a>安装Miniconda</h3><p><strong>1</strong>）下载Miniconda（Python3版本）</p><p>下载地址：<a href="https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh" target="_blank" rel="noopener">https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh</a></p><p><strong>2</strong>）安装Miniconda</p><p>(1) 执行以下命令进行安装，并按照提示操作，直到安装完成。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash Miniconda3-latest-Linux-x86_64.sh</span><br></pre></td></tr></table></figure><p>(2) 安装过程中，可以指定安装路径</p><p>(3) 配置Miniconda的环境变量（可以不配，在安装路径的路径）</p><p>(4)取消激活base环境</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda config --set auto_activate_base false</span><br></pre></td></tr></table></figure><h3 id="创建Python3-6环境"><a href="#创建Python3-6环境" class="headerlink" title="创建Python3.6环境"></a>创建Python3.6环境</h3><p>1 配置conda国内镜像</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda config --add channels https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;pkgs&#x2F;free</span><br><span class="line">conda config --add channels https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;anaconda&#x2F;pkgs&#x2F;main</span><br><span class="line">conda config --set show_channel_urls yes</span><br></pre></td></tr></table></figure><p>2 创建Python3.6环境</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">conda create --name superset python&#x3D;3.6</span><br><span class="line">说明：conda环境管理常用命令</span><br><span class="line">创建环境：conda create -n env_name</span><br><span class="line">查看所有环境：conda info --envs</span><br><span class="line">删除一个环境：conda remove -n env_name --all</span><br></pre></td></tr></table></figure><p>3 激活superset环境</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda activate superset</span><br><span class="line">conda deactivate(退出激活)</span><br></pre></td></tr></table></figure><h2 id="2-Superset部署"><a href="#2-Superset部署" class="headerlink" title="2 Superset部署"></a>2 Superset部署</h2><p>1 安装依赖</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install -y python-setuptools</span><br><span class="line">sudo yum install -y gcc gcc-c++ libffi-devel python-devel python-pip python-wheel openssl-devel cyrus-sasl-devel openldap-devel</span><br></pre></td></tr></table></figure><p>2 安装superset</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">## 安装（更新）setuptools和pip</span><br><span class="line">pip install --upgrade setuptools pip -i https:&#x2F;&#x2F;pypi.douban.com&#x2F;simple&#x2F;</span><br><span class="line"></span><br><span class="line">## 安装Supetset</span><br><span class="line">pip install apache-superset -i https:&#x2F;&#x2F;pypi.douban.com&#x2F;simple&#x2F;</span><br><span class="line"></span><br><span class="line">## 初始化Supetset数据库</span><br><span class="line">superset db upgrade</span><br><span class="line"></span><br><span class="line">## 创建管理员用户</span><br><span class="line">export FLASK_APP&#x3D;superset</span><br><span class="line">flask fab create-admin</span><br><span class="line"></span><br><span class="line">## Superset初始化</span><br><span class="line">superset init</span><br></pre></td></tr></table></figure><p>3 启动superset</p><p>1 安装gunicorn</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install gunicorn -i https:&#x2F;&#x2F;pypi.douban.com&#x2F;simple&#x2F;</span><br></pre></td></tr></table></figure><p>2 启动superset（确保环境为superset）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">gunicorn --workers 5 --timeout 120 --bind hadoop102:8787  superset:app --daemon </span><br><span class="line"></span><br><span class="line">说明：</span><br><span class="line">--workers：指定进程个数</span><br><span class="line">--timeout：worker进程超时时间，超时会自动重启</span><br><span class="line">--bind：绑定本机地址，即为Superset访问地址</span><br><span class="line">--daemon：后台运行</span><br></pre></td></tr></table></figure><p>3 停止superseet</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ps -ef | awk &#39;&#x2F;gunicorn&#x2F; &amp;&amp; !&#x2F;awk&#x2F;&#123;print $2&#125;&#39; | xargs kill -9</span><br><span class="line"></span><br><span class="line">退出环境</span><br><span class="line">conda deactivate</span><br></pre></td></tr></table></figure><p>4 登录supserset</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">默认的端口为8787</span><br></pre></td></tr></table></figure><h2 id="3-Superset的使用"><a href="#3-Superset的使用" class="headerlink" title="3 Superset的使用"></a>3 Superset的使用</h2><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Mar 05 2021 21:11:12 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;概述：Apache Superset是一个开源的、现代的、轻量级BI分析工具，能够对接多种数据源、拥有丰富的图标展示形式、支持自定义仪表盘，且拥
      
    
    </summary>
    
    
      <category term="安装" scheme="http://kiedeng.github.io/categories/%E5%AE%89%E8%A3%85/"/>
    
    
      <category term="默认" scheme="http://kiedeng.github.io/tags/%E9%BB%98%E8%AE%A4/"/>
    
  </entry>
  
  <entry>
    <title>azkaban安装部署</title>
    <link href="http://kiedeng.github.io/2020/05/15/azkaban%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"/>
    <id>http://kiedeng.github.io/2020/05/15/azkaban%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/</id>
    <published>2020-05-15T09:12:43.000Z</published>
    <updated>2020-05-16T10:01:11.193Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Mar 05 2021 21:11:12 GMT+0800 (GMT+08:00) --><h2 id="生成密钥库所出现的问题"><a href="#生成密钥库所出现的问题" class="headerlink" title="生成密钥库所出现的问题"></a>生成密钥库所出现的问题</h2><p>补充：keytool -genkey -alias tomcat1 -keyalg RSA -keystore second.keystore</p><p>参考链接：<a href="https://blog.csdn.net/weixin_38038479/article/details/101207322" target="_blank" rel="noopener">链接</a></p><h2 id="配置邮箱"><a href="#配置邮箱" class="headerlink" title="配置邮箱"></a>配置邮箱</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># mail settings</span><br><span class="line">mail.sender&#x3D;572245955@qq.com</span><br><span class="line">mail.host&#x3D;smtp.qq.com</span><br><span class="line">mail.user&#x3D;572245955@qq.com</span><br><span class="line">mail.password&#x3D;(填写qq的授权码)</span><br><span class="line">job.failure.email&#x3D;</span><br><span class="line">job.success.email&#x3D;</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Mar 05 2021 21:11:12 GMT+0800 (GMT+08:00) --&gt;&lt;h2 id=&quot;生成密钥库所出现的问题&quot;&gt;&lt;a href=&quot;#生成密钥库所出现的问题&quot; class=&quot;headerlink&quot; title=&quot;生成密钥库
      
    
    </summary>
    
    
      <category term="Azkaba" scheme="http://kiedeng.github.io/categories/Azkaba/"/>
    
    
      <category term="默认" scheme="http://kiedeng.github.io/tags/%E9%BB%98%E8%AE%A4/"/>
    
  </entry>
  
  <entry>
    <title>常见命令行操作</title>
    <link href="http://kiedeng.github.io/2020/05/13/%E5%B8%B8%E8%A7%81%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%93%8D%E4%BD%9C/"/>
    <id>http://kiedeng.github.io/2020/05/13/%E5%B8%B8%E8%A7%81%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%93%8D%E4%BD%9C/</id>
    <published>2020-05-13T08:25:07.000Z</published>
    <updated>2020-05-13T09:40:20.395Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Mar 05 2021 21:11:12 GMT+0800 (GMT+08:00) --><h2 id="Kafka常见命令"><a href="#Kafka常见命令" class="headerlink" title="Kafka常见命令"></a>Kafka常见命令</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">启动生产者</span><br><span class="line">bin&#x2F;kafka-console-producer.sh \</span><br><span class="line">--broker-list hadoop102:9092 --topic first</span><br><span class="line">启动消费者（zookeeper存储offset）</span><br><span class="line">bin&#x2F;kafka-console-consumer.sh --topic atguigu --zookeeper hadoop102:2181</span><br><span class="line">启动消费者（本地存储offset）</span><br><span class="line">bin&#x2F;kafka-console-consumer.sh --topic shangguigu --bootstrap-server hadoop102:9092</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Mar 05 2021 21:11:12 GMT+0800 (GMT+08:00) --&gt;&lt;h2 id=&quot;Kafka常见命令&quot;&gt;&lt;a href=&quot;#Kafka常见命令&quot; class=&quot;headerlink&quot; title=&quot;Kafka常见命令
      
    
    </summary>
    
    
      <category term="大数据" scheme="http://kiedeng.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="默认" scheme="http://kiedeng.github.io/tags/%E9%BB%98%E8%AE%A4/"/>
    
  </entry>
  
  <entry>
    <title>主题的美化</title>
    <link href="http://kiedeng.github.io/2020/05/05/%E4%B8%BB%E9%A2%98%E7%9A%84%E7%BE%8E%E5%8C%96/"/>
    <id>http://kiedeng.github.io/2020/05/05/%E4%B8%BB%E9%A2%98%E7%9A%84%E7%BE%8E%E5%8C%96/</id>
    <published>2020-05-05T11:28:19.000Z</published>
    <updated>2020-05-06T13:22:42.344Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Mar 05 2021 21:11:12 GMT+0800 (GMT+08:00) --><h2 id="一，增加天气效果"><a href="#一，增加天气效果" class="headerlink" title="一，增加天气效果"></a>一，增加天气效果</h2><p>打开<a href="https://wanghongfeng.cn/go/aHR0cHM6Ly93d3cuc2VuaXZlcnNlLmNvbQ==" target="_blank" rel="noopener">心知天气</a>的官网，注册账号，并开通免费版服务。<br>之后在/handsome/component/headnav.php中搜索，在搜索到的地方的前一行添加如下代码，并把其中的公钥和私钥修改为你自己的即可。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 知心天气--&gt;</span><br><span class="line">    &lt;div id&#x3D;&quot;tp-weather-widget&quot; class&#x3D;&quot;navbar-form navbar-form-sm navbar-left shift&quot;&gt;&lt;&#x2F;div&gt;</span><br><span class="line">&lt;script&gt;(function(T,h,i,n,k,P,a,g,e)&#123;g&#x3D;function()&#123;P&#x3D;h.createElement(i);a&#x3D;h.getElementsByTagName(i)[0];P.src&#x3D;k;P.charset&#x3D;&quot;utf-8&quot;;P.async&#x3D;1;a.parentNode.insertBefore(P,a)&#125;;T[&quot;ThinkPageWeatherWidgetObject&quot;]&#x3D;n;T[n]||(T[n]&#x3D;function()&#123;(T[n].q&#x3D;T[n].q||[]).push(arguments)&#125;);T[n].l&#x3D;+new Date();if(T.attachEvent)&#123;T.attachEvent(&quot;onload&quot;,g)&#125;else&#123;T.addEventListener(&quot;load&quot;,g,false)&#125;&#125;(window,document,&quot;script&quot;,&quot;tpwidget&quot;,&quot;&#x2F;&#x2F;widget.seniverse.com&#x2F;widget&#x2F;chameleon.js&quot;))&lt;&#x2F;script&gt;</span><br><span class="line">&lt;script&gt;tpwidget(&quot;init&quot;, &#123;</span><br><span class="line">    &quot;flavor&quot;: &quot;slim&quot;,</span><br><span class="line">    &quot;location&quot;: &quot;WX4FBXXFKE4F&quot;,</span><br><span class="line">    &quot;geolocation&quot;: &quot;enabled&quot;,</span><br><span class="line">    &quot;language&quot;: &quot;auto&quot;,</span><br><span class="line">    &quot;unit&quot;: &quot;c&quot;,</span><br><span class="line">    &quot;theme&quot;: &quot;chameleon&quot;,</span><br><span class="line">    &quot;container&quot;: &quot;tp-weather-widget&quot;,</span><br><span class="line">    &quot;bubble&quot;: &quot;enabled&quot;,</span><br><span class="line">    &quot;alarmType&quot;: &quot;badge&quot;,</span><br><span class="line">    &quot;color&quot;: &quot;#C6C6C6&quot;,</span><br><span class="line">    &quot;uid&quot;: &quot;你的公钥&quot;,</span><br><span class="line">    &quot;hash&quot;: &quot;你的私钥&quot;</span><br><span class="line">&#125;);</span><br><span class="line">tpwidget(&quot;show&quot;);&lt;&#x2F;script&gt;</span><br><span class="line">&lt;!-- 心知结束--&gt;</span><br></pre></td></tr></table></figure><h2 id="二，美化"><a href="#二，美化" class="headerlink" title="二，美化"></a>二，美化</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;*</span><br><span class="line"> * 文章一二三四级标题美化</span><br><span class="line"> *&#x2F;</span><br><span class="line">#post-content h1 &#123;</span><br><span class="line">font-size: 30px</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">#post-content h2 &#123;</span><br><span class="line">position: relative;</span><br><span class="line">margin: 20px 0 32px!important;</span><br><span class="line">font-size: 1.55em;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">#post-content h3 &#123;</span><br><span class="line">font-size: 20px</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">#post-content h4 &#123;</span><br><span class="line">font-size: 15px</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">#post-content h2::after &#123;</span><br><span class="line">transition: all .35s;</span><br><span class="line">content: &quot;&quot;;</span><br><span class="line">position: absolute;</span><br><span class="line">background: linear-gradient(#3c67bd8c 30%,#3c67bd 70%);</span><br><span class="line">width: 1em;</span><br><span class="line">left: 0;</span><br><span class="line">box-shadow: 0 3px 3px rgba(32,160,255,.4);</span><br><span class="line">height: 3px;</span><br><span class="line">bottom: -8px;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">#post-content h2::before &#123;</span><br><span class="line">content: &quot;&quot;;</span><br><span class="line">width: 100%;</span><br><span class="line">border-bottom: 1px solid #eee;</span><br><span class="line">bottom: -7px;</span><br><span class="line">position: absolute</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">#post-content h2:hover::after &#123;</span><br><span class="line">width: 2.5em;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">#post-content h1,#post-content h2,#post-content h3,#post-content h4,#post-content h5,#post-content h6 &#123;</span><br><span class="line">color: #666;</span><br><span class="line">line-height: 1.4;</span><br><span class="line">font-weight: 700;</span><br><span class="line">margin: 30px 0 10px 0</span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#x2F;*</span><br><span class="line"> *  首页文章列表悬停上浮</span><br><span class="line"> *&#x2F;</span><br><span class="line">.blog-post .panel:not(article) &#123;</span><br><span class="line">transition: all 0.3s;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">.blog-post .panel:not(article):hover &#123;</span><br><span class="line">transform: translateY(-10px);</span><br><span class="line">box-shadow: 0 8px 10px rgba(73, 90, 47, 0.47);</span><br><span class="line">&#125;</span><br><span class="line">&#x2F;*</span><br><span class="line"> *  文章内头图和文章图片悬停放大并将超出范围隐藏</span><br><span class="line"> *&#x2F;</span><br><span class="line">.entry-thumbnail &#123;</span><br><span class="line">overflow: hidden;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">#post-content img &#123;</span><br><span class="line">border-radius: 10px;</span><br><span class="line">transition: 0.5s;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">#post-content img:hover &#123;</span><br><span class="line">transform: scale(1.05);</span><br><span class="line">&#125;</span><br><span class="line">&#x2F;*</span><br><span class="line"> *首页文章图片获取焦点放大</span><br><span class="line"> *&#x2F;</span><br><span class="line">.item-thumb &#123;</span><br><span class="line">cursor: pointer;</span><br><span class="line">transition: all 0.6s;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">.item-thumb:hover &#123;</span><br><span class="line">transform: scale(1.05);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">.item-thumb-small &#123;</span><br><span class="line">cursor: pointer;</span><br><span class="line">transition: all 0.6s;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">.item-thumb-small:hover &#123;</span><br><span class="line">transform: scale(1.05);</span><br><span class="line">&#125;</span><br><span class="line">&#x2F;*文章内打赏图标跳动*&#x2F;</span><br><span class="line">.btn - pay &#123;</span><br><span class="line">    animation: star 0.5s ease - in-out infinite alternate;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@keyframes star &#123;</span><br><span class="line">    from &#123;</span><br><span class="line">        transform: scale(1);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    to &#123;</span><br><span class="line">        transform: scale(1.1);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#x2F;*</span><br><span class="line"> *修改字体</span><br><span class="line"> *&#x2F;</span><br><span class="line">*&#123;font-family: &#39;Noto Serif SC&#39;, serif;</span><br><span class="line">font-family: &#39;Fira Code&#39;, monospace;&#125;</span><br></pre></td></tr></table></figure><h2 id="三，头像呼吸光环和鼠标悬停旋转放大"><a href="#三，头像呼吸光环和鼠标悬停旋转放大" class="headerlink" title="三，头像呼吸光环和鼠标悬停旋转放大"></a>三，头像呼吸光环和鼠标悬停旋转放大</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">.img-full &#123;</span><br><span class="line">    width: 100px;</span><br><span class="line">    border-radius: 50%;</span><br><span class="line">    animation: light 4s ease-in-out infinite;</span><br><span class="line">    transition: 0.5s;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">.img-full:hover &#123;</span><br><span class="line">    transform: scale(1.15) rotate(720deg);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@keyframes light &#123;</span><br><span class="line">    0% &#123;</span><br><span class="line">        box-shadow: 0 0 4px #f00;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    25% &#123;</span><br><span class="line">        box-shadow: 0 0 16px #0f0;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    50% &#123;</span><br><span class="line">        box-shadow: 0 0 4px #00f;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    75% &#123;</span><br><span class="line">        box-shadow: 0 0 16px #0f0;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    100% &#123;</span><br><span class="line">        box-shadow: 0 0 4px #f00;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="四，qq头像的图片链接"><a href="#四，qq头像的图片链接" class="headerlink" title="四，qq头像的图片链接"></a>四，qq头像的图片链接</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https:&#x2F;&#x2F;q1.qlogo.cn&#x2F;g?b&#x3D;qq&amp;nk&#x3D;572245955&amp;s&#x3D;640</span><br></pre></td></tr></table></figure><h2 id="五，自定义js美化"><a href="#五，自定义js美化" class="headerlink" title="五，自定义js美化"></a>五，自定义js美化</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;*彩色标签云*&#x2F;</span><br><span class="line">let tags &#x3D; document.querySelectorAll(&quot;#tag_cloud-2 a&quot;);</span><br><span class="line">let colorArr &#x3D; [&quot;#428BCA&quot;, &quot;#AEDCAE&quot;, &quot;#ECA9A7&quot;, &quot;#DA99FF&quot;, &quot;#FFB380&quot;, &quot;#D9B999&quot;];</span><br><span class="line">tags.forEach(tag &#x3D;&gt; &#123;</span><br><span class="line">    tagsColor &#x3D; colorArr[Math.floor(Math.random() * colorArr.length)];</span><br><span class="line">    tag.style.backgroundColor &#x3D; tagsColor;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><h2 id="六，博主介绍特效"><a href="#六，博主介绍特效" class="headerlink" title="六，博主介绍特效"></a>六，博主介绍特效</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;!--博主介绍的闪字特效--&gt;</span><br><span class="line">&lt;span class&#x3D;&quot;text-muted text-xs block&quot;&gt;&lt;div id&#x3D;&quot;chakhsu&quot;&gt;&lt;&#x2F;div&gt; &lt;script&gt; var chakhsu &#x3D; function (r) &#123;function t() &#123;return b[Math.floor(Math.random() * b.length)]&#125; function e() &#123;return String.fromCharCode(94 * Math.random() + 33)&#125; function n(r) &#123;for (var n &#x3D; document.createDocumentFragment(), i &#x3D; 0; r &gt; i; i++) &#123; var l &#x3D; document.createElement(&quot;span&quot;); l.textContent &#x3D; e(), l.style.color &#x3D; t(), n.appendChild(l) &#125; return n&#125;function i() &#123;var t &#x3D; o[c.skillI]; c.step ? c.step-- : (c.step &#x3D; g, c.prefixP &lt; l.length ? (c.prefixP &gt;&#x3D; 0 &amp;&amp; (c.text +&#x3D; l[c.prefixP]), c.prefixP++) : &quot;forward&quot; &#x3D;&#x3D;&#x3D; c.direction ? c.skillP &lt; t.length ? (c.text +&#x3D; t[c.skillP], c.skillP++) : c.delay ? c.delay-- : (c.direction &#x3D; &quot;backward&quot;, c.delay &#x3D; a) : c.skillP &gt; 0 ? (c.text &#x3D; c.text.slice(0, -1), c.skillP--) : (c.skillI &#x3D; (c.skillI + 1) % o.length, c.direction &#x3D; &quot;forward&quot;)), r.textContent &#x3D; c.text, r.appendChild(n(c.prefixP &lt; l.length ? Math.min(s, s + c.prefixP) : Math.min(s, t.length - c.skillP))), setTimeout(i, d) &#125; &#x2F;*以下内容自定义修改*&#x2F; var l &#x3D; &quot;&quot;, o &#x3D; [&quot;Keep Fighting&quot; ].map(function (r) &#123;return r + &quot;&quot;&#125;), a &#x3D; 2, g &#x3D; 1, s &#x3D; 5, d &#x3D; 75, b &#x3D; [&quot;rgb(110,64,170)&quot;, &quot;rgb(150,61,179)&quot;, &quot;rgb(191,60,175)&quot;, &quot;rgb(228,65,157)&quot;, &quot;rgb(254,75,131)&quot;, &quot;rgb(255,94,99)&quot;, &quot;rgb(255,120,71)&quot;, &quot;rgb(251,150,51)&quot;, &quot;rgb(226,183,47)&quot;, &quot;rgb(198,214,60)&quot;, &quot;rgb(175,240,91)&quot;, &quot;rgb(127,246,88)&quot;, &quot;rgb(82,246,103)&quot;, &quot;rgb(48,239,130)&quot;, &quot;rgb(29,223,163)&quot;, &quot;rgb(26,199,194)&quot;, &quot;rgb(35,171,216)&quot;, &quot;rgb(54,140,225)&quot;, &quot;rgb(76,110,219)&quot;, &quot;rgb(96,84,200)&quot;], c &#x3D; &#123;text: &quot;&quot;, prefixP: -s, skillI: 0, skillP: 0, direction: &quot;forward&quot;, delay: a, step: g&#125;; i() &#125;; chakhsu(document.getElementById(&#39;chakhsu&#39;)); &lt;&#x2F;script&gt; &lt;&#x2F;span&gt; &lt;&#x2F;span&gt;</span><br></pre></td></tr></table></figure><h2 id="七，倒计时"><a href="#七，倒计时" class="headerlink" title="七，倒计时"></a>七，倒计时</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;style&gt;        .gn_box&#123;             border: none;             border-radius: 15px;         &#125;          .gn_box &#123;             padding: 10px 14px;             margin: 10px;             margin-bottom: 20px;             text-align: center;             background-color: #fff;         &#125;          #t_d&#123;             color: #982585;             font-size: 18px;         &#125;          #t_h&#123;             color: #8f79c1;             font-size: 18px;         &#125;          #t_m&#123;             color: #65b4b5;             font-size: 18px;         &#125;          #t_s&#123;             color: #83caa3;             font-size: 18px;         &#125;       &lt;&#x2F;style&gt;       &lt;div class&#x3D;&quot;gn_box&quot;&gt;             &lt;h1 style&#x3D;&quot;font-size:1em;&quot;&gt;&lt;font color&#x3D;&quot;#E80017&quot;&gt;2&lt;&#x2F;font&gt;        &lt;font color&#x3D;&quot;#D1002E&quot;&gt;0&lt;&#x2F;font&gt;        &lt;font color&#x3D;&quot;#BA0045&quot;&gt;2&lt;&#x2F;font&gt;        &lt;font color&#x3D;&quot;#A3005C&quot;&gt;0&lt;&#x2F;font&gt;        &lt;font color&#x3D;&quot;#8C0073&quot;&gt;年&lt;&#x2F;font&gt;        &lt;font color&#x3D;&quot;#75008A&quot;&gt;-&lt;&#x2F;font&gt;         &lt;font color&#x3D;&quot;#5E00A1&quot;&gt;秋&lt;&#x2F;font&gt;        &lt;font color&#x3D;&quot;#4700B8&quot;&gt;招&lt;&#x2F;font&gt;        &lt;font color&#x3D;&quot;#3000CF&quot;&gt;倒&lt;&#x2F;font&gt;        &lt;font color&#x3D;&quot;#1900E6&quot;&gt;计&lt;&#x2F;font&gt;        &lt;font color&#x3D;&quot;#0200FD&quot;&gt;时&lt;&#x2F;font&gt;&lt;&#x2F;h1&gt;        &lt;center&gt;          &lt;div id&#x3D;&quot;CountMsg&quot; class&#x3D;&quot;HotDate&quot;&gt;            &lt;span id&#x3D;&quot;t_d&quot;&gt; 天&lt;&#x2F;span&gt;            &lt;span id&#x3D;&quot;t_h&quot;&gt; 时&lt;&#x2F;span&gt;&lt;span id&#x3D;&quot;t_m&quot;&gt; 分&lt;&#x2F;span&gt;            &lt;span id&#x3D;&quot;t_s&quot;&gt; 秒&lt;&#x2F;span&gt;          &lt;&#x2F;div&gt;        &lt;&#x2F;center&gt;         &lt;script type&#x3D;&quot;text&#x2F;javascript&quot;&gt;        function getRTime() &#123;                var EndTime &#x3D; new Date(&#39;2020&#x2F;09&#x2F;1 00:00:00&#39;);                       var NowTime &#x3D; new Date();                       var t &#x3D; EndTime.getTime() - NowTime.getTime();                              var d &#x3D; Math.floor(t &#x2F; 1000 &#x2F; 60 &#x2F; 60 &#x2F; 24);                              var h &#x3D; Math.floor(t &#x2F; 1000 &#x2F; 60 &#x2F; 60 % 24);                              var m &#x3D; Math.floor(t &#x2F; 1000 &#x2F; 60 % 60);                              var s &#x3D; Math.floor(t &#x2F; 1000 % 60);                      var day &#x3D; document.getElementById(&quot;t_d&quot;);                     if (day !&#x3D; null) &#123;                              day.innerHTML &#x3D; d + &quot; 天&quot;;                        &#125;                         var hour &#x3D; document.getElementById(&quot;t_h&quot;);                     if (hour !&#x3D; null) &#123;                             hour.innerHTML &#x3D; h + &quot; 时&quot;;                       &#125;                         var min &#x3D; document.getElementById(&quot;t_m&quot;);                     if (min !&#x3D; null) &#123;                            min.innerHTML &#x3D; m + &quot; 分&quot;;                        &#125;                         var sec &#x3D; document.getElementById(&quot;t_s&quot;);                     if (sec !&#x3D; null) &#123;                             sec.innerHTML &#x3D; s + &quot; 秒&quot;;                     &#125;          &#125;               setInterval(getRTime, 1000);              &lt;&#x2F;script&gt;      &lt;&#x2F;div&gt;            &lt;!--首页输出文章--&gt;</span><br></pre></td></tr></table></figure><h2 id="八，疫情图"><a href="#八，疫情图" class="headerlink" title="八，疫情图"></a>八，疫情图</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;iframe src&#x3D;&quot;https:&#x2F;&#x2F;www.lovestu.com&#x2F;api&#x2F;project&#x2F;cnmapyinqing&#x2F;obj.php&quot; height&#x3D;&quot;500&quot; frameborder&#x3D;&quot;no&quot; border&#x3D;&quot;0&quot; width&#x3D;&quot;100%&quot;&gt; &lt;&#x2F;iframe&gt;</span><br></pre></td></tr></table></figure><p>参考链接：<a href="https://wanghongfeng.cn/handsome-diy.html" target="_blank" rel="noopener">https://wanghongfeng.cn/handsome-diy.html</a></p><p><a href="https://rehtt.com/index.php/archives/193" target="_blank" rel="noopener">https://rehtt.com/index.php/archives/193</a></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Mar 05 2021 21:11:12 GMT+0800 (GMT+08:00) --&gt;&lt;h2 id=&quot;一，增加天气效果&quot;&gt;&lt;a href=&quot;#一，增加天气效果&quot; class=&quot;headerlink&quot; title=&quot;一，增加天气效果&quot;&gt;&lt;
      
    
    </summary>
    
    
      <category term="typecho" scheme="http://kiedeng.github.io/categories/typecho/"/>
    
    
      <category term="默认" scheme="http://kiedeng.github.io/tags/%E9%BB%98%E8%AE%A4/"/>
    
  </entry>
  
  <entry>
    <title>ArrayList源码分析</title>
    <link href="http://kiedeng.github.io/2020/04/20/ArrayList%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"/>
    <id>http://kiedeng.github.io/2020/04/20/ArrayList%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</id>
    <published>2020-04-20T04:22:21.000Z</published>
    <updated>2020-04-20T04:22:21.542Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Mar 05 2021 21:11:12 GMT+0800 (GMT+08:00) --><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Mar 05 2021 21:11:12 GMT+0800 (GMT+08:00) --&gt;&lt;!-- rebuild by neat --&gt;
      
    
    </summary>
    
    
      <category term="未分类" scheme="http://kiedeng.github.io/categories/%E6%9C%AA%E5%88%86%E7%B1%BB/"/>
    
    
      <category term="默认" scheme="http://kiedeng.github.io/tags/%E9%BB%98%E8%AE%A4/"/>
    
  </entry>
  
  <entry>
    <title>hql常见函数</title>
    <link href="http://kiedeng.github.io/2020/03/19/hql%E5%B8%B8%E8%A7%81%E5%87%BD%E6%95%B0/"/>
    <id>http://kiedeng.github.io/2020/03/19/hql%E5%B8%B8%E8%A7%81%E5%87%BD%E6%95%B0/</id>
    <published>2020-03-19T07:27:35.000Z</published>
    <updated>2020-03-19T07:28:42.883Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Mar 05 2021 21:11:12 GMT+0800 (GMT+08:00) --><p>常用日期函数</p><p>unix_timestamp:返回当前或指定时间的时间戳</p><p>from_unixtime：将时间戳转为日期格式</p><p>current_date：当前日期</p><p>current_timestamp：当前的日期加时间</p><p>to_date：抽取日期部分</p><p>year：获取年</p><p>month：获取月</p><p>day：获取日</p><p>hour：获取时</p><p>minute：获取分</p><p>second：获取秒</p><p>weekofyear：当前时间是一年中的第几周</p><p>dayofmonth：当前时间是一个月中的第几天</p><p>months_between： 两个日期间的月份</p><p>add_months：日期加减月</p><p>datediff：两个日期相差的天数</p><p>date_add：日期加天数</p><p>date_sub：日期减天数</p><p>last_day：日期的当月的最后一天</p><p>常用取整函数</p><p>round： 四舍五入</p><p>ceil： 向上取整</p><p>floor： 向下取整</p><p>常用字符串操作函数</p><p>upper： 转大写</p><p>lower： 转小写</p><p>length： 长度</p><p>trim： 前后去空格</p><p>lpad： 向左补齐，到指定长度</p><p>rpad： 向右补齐，到指定长度</p><p>regexp_replace： SELECT regexp_replace(‘100-200’, ‘(\d+)’, ‘num’) ；</p><p>​ 使用正则表达式匹配目标字符串，匹配成功后替换！</p><p>集合操作</p><p>size： 集合中元素的个数</p><p>map_keys： 返回map中的key</p><p>map_values: 返回map中的value</p><p>array_contains: 判断array中是否包含某个元素</p><p>sort_array： 将array中的元素排序</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Mar 05 2021 21:11:12 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;常用日期函数&lt;/p&gt;&lt;p&gt;unix_timestamp:返回当前或指定时间的时间戳&lt;/p&gt;&lt;p&gt;from_unixtime：将时间戳转为日期格式
      
    
    </summary>
    
    
      <category term="未分类" scheme="http://kiedeng.github.io/categories/%E6%9C%AA%E5%88%86%E7%B1%BB/"/>
    
    
      <category term="默认" scheme="http://kiedeng.github.io/tags/%E9%BB%98%E8%AE%A4/"/>
    
  </entry>
  
  <entry>
    <title>hive知识点</title>
    <link href="http://kiedeng.github.io/2020/03/18/hive%E7%9F%A5%E8%AF%86%E7%82%B9/"/>
    <id>http://kiedeng.github.io/2020/03/18/hive%E7%9F%A5%E8%AF%86%E7%82%B9/</id>
    <published>2020-03-18T14:14:15.586Z</published>
    <updated>2020-03-18T14:15:52.967Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Mar 05 2021 21:11:12 GMT+0800 (GMT+08:00) --><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Mar 05 2021 21:11:12 GMT+0800 (GMT+08:00) --&gt;&lt;!-- rebuild by neat --&gt;
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>HQL常见错误</title>
    <link href="http://kiedeng.github.io/2020/03/18/HQL%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF/"/>
    <id>http://kiedeng.github.io/2020/03/18/HQL%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF/</id>
    <published>2020-03-18T14:03:47.000Z</published>
    <updated>2020-03-18T15:13:59.298Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Mar 05 2021 21:11:12 GMT+0800 (GMT+08:00) --><h3 id="行转列过程中"><a href="#行转列过程中" class="headerlink" title="行转列过程中"></a>行转列过程中</h3><p>分组的时候只写了group，忘记了by</p><p>子查询不能写分号</p><h3 id="列名错误："><a href="#列名错误：" class="headerlink" title="列名错误："></a><strong>列名错误：</strong></h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Error: Error while compiling statement: FAILED: SemanticException [Error 10004]: Line 3:6 Invalid table alias or column reference &#39;orderdata&#39;: (possible column names are: name, orderdate, cost) (state&#x3D;42000,code&#x3D;10004)</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Mar 05 2021 21:11:12 GMT+0800 (GMT+08:00) --&gt;&lt;h3 id=&quot;行转列过程中&quot;&gt;&lt;a href=&quot;#行转列过程中&quot; class=&quot;headerlink&quot; title=&quot;行转列过程中&quot;&gt;&lt;/a&gt;行转列
      
    
    </summary>
    
    
      <category term="hive" scheme="http://kiedeng.github.io/categories/hive/"/>
    
    
      <category term="默认" scheme="http://kiedeng.github.io/tags/%E9%BB%98%E8%AE%A4/"/>
    
  </entry>
  
  <entry>
    <title>hive常见错误</title>
    <link href="http://kiedeng.github.io/2020/03/18/hive%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF/"/>
    <id>http://kiedeng.github.io/2020/03/18/hive%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF/</id>
    <published>2020-03-18T14:03:31.000Z</published>
    <updated>2020-03-18T14:03:31.318Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Mar 05 2021 21:11:12 GMT+0800 (GMT+08:00) --><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Mar 05 2021 21:11:12 GMT+0800 (GMT+08:00) --&gt;&lt;!-- rebuild by neat --&gt;
      
    
    </summary>
    
    
      <category term="未分类" scheme="http://kiedeng.github.io/categories/%E6%9C%AA%E5%88%86%E7%B1%BB/"/>
    
    
      <category term="默认" scheme="http://kiedeng.github.io/tags/%E9%BB%98%E8%AE%A4/"/>
    
  </entry>
  
  <entry>
    <title>mongdb导入json文件</title>
    <link href="http://kiedeng.github.io/2020/03/18/mongdb%E5%AF%BC%E5%85%A5json%E6%96%87%E4%BB%B6/"/>
    <id>http://kiedeng.github.io/2020/03/18/mongdb%E5%AF%BC%E5%85%A5json%E6%96%87%E4%BB%B6/</id>
    <published>2020-03-18T04:22:00.000Z</published>
    <updated>2020-03-18T04:29:16.461Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Mar 05 2021 21:11:12 GMT+0800 (GMT+08:00) --><h2 id="1-安装mongdb"><a href="#1-安装mongdb" class="headerlink" title="1 安装mongdb"></a>1 安装mongdb</h2><p>使用宝塔安装mongdb</p><h2 id="2-配置mongdb"><a href="#2-配置mongdb" class="headerlink" title="2 配置mongdb"></a>2 配置mongdb</h2><p><img src="https://kiedeng.site/usr/uploads/2020/03/962950381.jpg" alt="配置.jpg"></p><p>注：开放27017端口</p><h2 id="3-导入数据"><a href="#3-导入数据" class="headerlink" title="3 导入数据"></a>3 导入数据</h2><p>mongoimport –db mall –collection userData –file /Users/yeo/Desktop/userdata.json</p><p>注：执行命令在/www/server/mongodb/bin</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Mar 05 2021 21:11:12 GMT+0800 (GMT+08:00) --&gt;&lt;h2 id=&quot;1-安装mongdb&quot;&gt;&lt;a href=&quot;#1-安装mongdb&quot; class=&quot;headerlink&quot; title=&quot;1 安装mon
      
    
    </summary>
    
    
      <category term="mongdb" scheme="http://kiedeng.github.io/categories/mongdb/"/>
    
    
      <category term="默认" scheme="http://kiedeng.github.io/tags/%E9%BB%98%E8%AE%A4/"/>
    
  </entry>
  
  <entry>
    <title>hive使用mysql编码问题</title>
    <link href="http://kiedeng.github.io/2020/03/17/hive%E4%BD%BF%E7%94%A8mysql%E7%BC%96%E7%A0%81%E9%97%AE%E9%A2%98/"/>
    <id>http://kiedeng.github.io/2020/03/17/hive%E4%BD%BF%E7%94%A8mysql%E7%BC%96%E7%A0%81%E9%97%AE%E9%A2%98/</id>
    <published>2020-03-17T10:58:22.000Z</published>
    <updated>2020-03-17T11:07:52.618Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Mar 05 2021 21:11:12 GMT+0800 (GMT+08:00) --><h2 id="修改my-cnf文件"><a href="#修改my-cnf文件" class="headerlink" title="修改my.cnf文件"></a>修改my.cnf文件</h2><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 添加</span><br><span class="line">init_connect='SET collation_connection = utf8_unicode_ci'</span><br><span class="line">init_connect='SET NAMES utf8'</span><br><span class="line">character-set-server=utf8</span><br><span class="line">collation-server=utf8_unicode_ci</span><br><span class="line">skip-character-set-client-handshake</span><br></pre></td></tr></table></figure><p>重启mysql</p><p>启动使用bin/hive脚本</p><h2 id="修改metastore数据库"><a href="#修改metastore数据库" class="headerlink" title="修改metastore数据库"></a>修改metastore数据库</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">show variables like &#39;char%&#39;;</span><br><span class="line">show variables like &quot;colla%&quot;;</span><br></pre></td></tr></table></figure><p>使用上面两个命令，查看是否都为utf8的编码，（除character_set _filesystem为binary）</p><p>如果没有：则</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">修改表字段注解和表注解</span><br><span class="line">alter table COLUMNS_V2 modify column COMMENT varchar(256) character set utf8;</span><br><span class="line">alter table TABLE_PARAMS modify column PARAM_VALUE varchar(4000) character set utf8;</span><br><span class="line">修改分区字段注解：</span><br><span class="line">alter table PARTITION_PARAMS modify column PARAM_VALUE varchar(4000) character set utf8;</span><br><span class="line">alter table PARTITION_KEYS modify column PKEY_COMMENT varchar(4000) character set utf8;</span><br><span class="line">修改索引注解：</span><br><span class="line">alter table INDEX_PARAMS modify column PARAM_VALUE varchar(4000) character set utf8;</span><br></pre></td></tr></table></figure><p>这样就可以显示中文字符的，不过在hive中插入中文字符还有些问题，只能显示上传文档为中文字符和描述为中文字符的情况</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Mar 05 2021 21:11:12 GMT+0800 (GMT+08:00) --&gt;&lt;h2 id=&quot;修改my-cnf文件&quot;&gt;&lt;a href=&quot;#修改my-cnf文件&quot; class=&quot;headerlink&quot; title=&quot;修改my.cn
      
    
    </summary>
    
    
      <category term="hive" scheme="http://kiedeng.github.io/categories/hive/"/>
    
    
      <category term="默认" scheme="http://kiedeng.github.io/tags/%E9%BB%98%E8%AE%A4/"/>
    
  </entry>
  
  <entry>
    <title>mysql安装</title>
    <link href="http://kiedeng.github.io/2020/03/16/mysql%E5%AE%89%E8%A3%85/"/>
    <id>http://kiedeng.github.io/2020/03/16/mysql%E5%AE%89%E8%A3%85/</id>
    <published>2020-03-16T10:35:24.000Z</published>
    <updated>2020-03-16T11:32:24.560Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Mar 05 2021 21:11:12 GMT+0800 (GMT+08:00) --><h2 id="检查是否安装Mysql"><a href="#检查是否安装Mysql" class="headerlink" title="检查是否安装Mysql"></a>检查是否安装Mysql</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rpm -qa|grep mysql; &#x2F;&#x2F; 查询是否存在mysql</span><br><span class="line">rpm -e --nodeps mysql-libs; &#x2F;&#x2F; 卸载mysql</span><br></pre></td></tr></table></figure><blockquote><p>rpm 是一个包管理工具</p><p>-e 卸载程序</p><p>-qa 查询安装的软件</p><p>–nodeps 不验证软件包的依赖</p><p>-i ,–install 安装软件包</p><p>-v， –verbose 提供更多的详细信息输出</p><p>-h ，–hash 软件包安装的时候列出哈希标记</p></blockquote><h2 id="安装Mysql"><a href="#安装Mysql" class="headerlink" title="安装Mysql"></a>安装Mysql</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tar -xf mysql-5.7.28-1.el6.x86_64.rpm-bundle.tar &#x2F;&#x2F; 解压</span><br><span class="line">&#x2F;&#x2F; 安装</span><br><span class="line">[root@hadoop102 software]$ rpm -ivh mysql-community-common-5.7.28-1.el6.x86_64.rpm</span><br><span class="line">[root@hadoop102 software]$ rpm -ivh mysql-community-libs-5.7.28-1.el6.x86_64.rpm</span><br><span class="line">[root@hadoop102 software]$ rpm -ivh mysql-community-client-5.7.28-1.el6.x86_64.rpm</span><br><span class="line">[root@hadoop102 software]$ rpm -ivh mysql-community-server-5.7.28-1.el6.x86_64.rpm</span><br></pre></td></tr></table></figure><h2 id="修改-etc-my-cnf"><a href="#修改-etc-my-cnf" class="headerlink" title="修改/etc/my.cnf"></a>修改/etc/my.cnf</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[mysqld]</span><br><span class="line">explicit_defaults_for_timestamp&#x3D;true  &#x2F;&#x2F;显示指定默认值为timestamp类型的字段</span><br></pre></td></tr></table></figure><p>删除/etc/my.cnf文件中datadir指向的目录下的所有内容:</p><h2 id="启动Mysql"><a href="#启动Mysql" class="headerlink" title="启动Mysql"></a>启动Mysql</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 初始化</span><br><span class="line">mysqld --initialize --user&#x3D;mysql</span><br><span class="line">&#x2F;&#x2F; 查看临时密码</span><br><span class="line">cat &#x2F;var&#x2F;log&#x2F;mysqld.log </span><br><span class="line">&#x2F;&#x2F; 启动mysql服务</span><br><span class="line">service mysqld start</span><br><span class="line">&#x2F;&#x2F; 登陆mysql</span><br><span class="line"> mysql -uroot -p</span><br><span class="line">Enter password:</span><br><span class="line">&#x2F;&#x2F; 修改密码</span><br><span class="line">set password &#x3D; password(&quot;新密码&quot;)</span><br><span class="line">&#x2F;&#x2F; 修改root用户支持任意IP连接（在user表中）</span><br><span class="line">update user set host&#x3D; ‘%’ where  user &#x3D; ‘root’;</span><br><span class="line">flush privileges ; &#x2F;&#x2F; 刷新配置</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Mar 05 2021 21:11:12 GMT+0800 (GMT+08:00) --&gt;&lt;h2 id=&quot;检查是否安装Mysql&quot;&gt;&lt;a href=&quot;#检查是否安装Mysql&quot; class=&quot;headerlink&quot; title=&quot;检查是否安
      
    
    </summary>
    
    
      <category term="Linux" scheme="http://kiedeng.github.io/categories/Linux/"/>
    
    
      <category term="默认" scheme="http://kiedeng.github.io/tags/%E9%BB%98%E8%AE%A4/"/>
    
  </entry>
  
  <entry>
    <title>大数据相关单词</title>
    <link href="http://kiedeng.github.io/2020/03/16/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E5%8D%95%E8%AF%8D/"/>
    <id>http://kiedeng.github.io/2020/03/16/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E5%8D%95%E8%AF%8D/</id>
    <published>2020-03-16T10:21:50.000Z</published>
    <updated>2020-03-16T16:37:30.491Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Mar 05 2021 21:11:12 GMT+0800 (GMT+08:00) --><table><thead><tr><th>单词</th><th>翻译</th></tr></thead><tbody><tr><td>row format delimited fields terminated by “\t”</td><td>行格式分隔的字段，以“ \ t”结尾</td></tr><tr><td>external</td><td>外部</td></tr><tr><td>comment</td><td>评论</td></tr><tr><td>partitioned by</td><td>分区（分目录）</td></tr><tr><td>sorted by</td><td>排序</td></tr><tr><td>clustered by</td><td>分桶（分文件）</td></tr><tr><td>serialize</td><td>序列化</td></tr><tr><td>deserialize</td><td>反序列化</td></tr><tr><td></td><td></td></tr><tr><td></td><td></td></tr><tr><td></td><td></td></tr><tr><td></td><td></td></tr><tr><td></td><td></td></tr><tr><td></td><td></td></tr><tr><td></td><td></td></tr><tr><td></td><td></td></tr><tr><td></td><td></td></tr><tr><td></td><td></td></tr><tr><td></td><td></td></tr><tr><td></td><td></td></tr><tr><td></td><td></td></tr><tr><td></td><td></td></tr><tr><td></td><td></td></tr><tr><td></td><td></td></tr><tr><td></td><td></td></tr><tr><td></td><td></td></tr><tr><td></td><td></td></tr><tr><td></td><td></td></tr><tr><td></td><td></td></tr></tbody></table><p>create table test(</p><p>​</p><p>)</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Mar 05 2021 21:11:12 GMT+0800 (GMT+08:00) --&gt;&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;单词&lt;/th&gt;&lt;th&gt;翻译&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;row for
      
    
    </summary>
    
    
      <category term="hive" scheme="http://kiedeng.github.io/categories/hive/"/>
    
    
      <category term="默认" scheme="http://kiedeng.github.io/tags/%E9%BB%98%E8%AE%A4/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop_HA高可用</title>
    <link href="http://kiedeng.github.io/2020/03/08/Hadoop-HA%E9%AB%98%E5%8F%AF%E7%94%A8/"/>
    <id>http://kiedeng.github.io/2020/03/08/Hadoop-HA%E9%AB%98%E5%8F%AF%E7%94%A8/</id>
    <published>2020-03-08T05:52:37.000Z</published>
    <updated>2020-03-08T09:19:37.481Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Mar 05 2021 21:11:12 GMT+0800 (GMT+08:00) --><p>包括HDFS的HA和YARN的HA</p><h2 id="HDFS-HA的工作机制"><a href="#HDFS-HA的工作机制" class="headerlink" title="HDFS-HA的工作机制"></a>HDFS-HA的工作机制</h2><p>​ 通过双NameNode消除单节点故障</p><h2 id="手动故障转移"><a href="#手动故障转移" class="headerlink" title="手动故障转移"></a>手动故障转移</h2><p>配置：在opt目录下创建ha文件夹，将hadoop复制到ha文件夹下</p><p>配置hadoop-env.sh</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME&#x3D;&#x2F;opt&#x2F;module&#x2F;jdk1.8.0_144</span><br></pre></td></tr></table></figure><p>配置core-site.xml</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">&lt;!-- 把两个NameNode）的地址组装成一个集群mycluster --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;fs.defaultFS&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;hdfs:&#x2F;&#x2F;mycluster&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">   &lt;!-- 声明journalnode服务器存储目录--&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;dfs.journalnode.edits.dir&lt;&#x2F;name&gt;</span><br><span class="line">&lt;value&gt;&#x2F;opt&#x2F;ha&#x2F;hadoop-2.7.2&#x2F;data&#x2F;jn&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;!-- 指定hadoop运行时产生文件的存储目录 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;hadoop.tmp.dir&lt;&#x2F;name&gt;</span><br><span class="line">&lt;value&gt;&#x2F;opt&#x2F;ha&#x2F;hadoop-2.7.2&#x2F;data&#x2F;tmp&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br></pre></td></tr></table></figure><p>配置hdfs-site.xml</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">&lt;!-- 完全分布式集群名称 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;dfs.nameservices&lt;&#x2F;name&gt;</span><br><span class="line">&lt;value&gt;mycluster&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 集群中NameNode节点都有哪些 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;dfs.ha.namenodes.mycluster&lt;&#x2F;name&gt;</span><br><span class="line">&lt;value&gt;nn1,nn2&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- nn1的RPC通信地址 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;dfs.namenode.rpc-address.mycluster.nn1&lt;&#x2F;name&gt;</span><br><span class="line">&lt;value&gt;hadoop102:9000&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- nn2的RPC通信地址 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;dfs.namenode.rpc-address.mycluster.nn2&lt;&#x2F;name&gt;</span><br><span class="line">&lt;value&gt;hadoop103:9000&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- nn1的http通信地址 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;dfs.namenode.http-address.mycluster.nn1&lt;&#x2F;name&gt;</span><br><span class="line">&lt;value&gt;hadoop102:50070&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- nn2的http通信地址 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;dfs.namenode.http-address.mycluster.nn2&lt;&#x2F;name&gt;</span><br><span class="line">&lt;value&gt;hadoop103:50070&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 指定NameNode元数据在JournalNode上的存放位置 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;dfs.namenode.shared.edits.dir&lt;&#x2F;name&gt;</span><br><span class="line">&lt;value&gt;qjournal:&#x2F;&#x2F;hadoop102:8485;hadoop103:8485;hadoop104:8485&#x2F;mycluster&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 配置隔离机制，即同一时刻只能有一台服务器对外响应 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;dfs.ha.fencing.methods&lt;&#x2F;name&gt;</span><br><span class="line">&lt;value&gt;sshfence&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 使用隔离机制时需要ssh无秘钥登录--&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;&#x2F;name&gt;</span><br><span class="line">&lt;value&gt;&#x2F;home&#x2F;atguigu&#x2F;.ssh&#x2F;id_rsa&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;!-- 关闭权限检查--&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;dfs.permissions.enable&lt;&#x2F;name&gt;</span><br><span class="line">&lt;value&gt;false&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 访问代理类：client，mycluster，active配置失败自动切换实现方式--&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.client.failover.proxy.provider.mycluster&lt;&#x2F;name&gt;</span><br><span class="line">&lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br></pre></td></tr></table></figure><p>拷贝到其他节点</p><h3 id="启动集群"><a href="#启动集群" class="headerlink" title="启动集群"></a>启动集群</h3><ol><li>各个集群启动JournalNode节点</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin&#x2F;hadoop-daemon.sh start journalnode</span><br></pre></td></tr></table></figure><ol start="2"><li>在[nn1]上，对其格式化，并启动</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;hdfs namenode -format</span><br><span class="line">sbin&#x2F;hadoop-daemon.sh start namenode</span><br></pre></td></tr></table></figure><ol start="3"><li>在[nn2]上，同步nn1的元数据信息</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;hdfs namenode -bootstrapStandby</span><br></pre></td></tr></table></figure><ol start="4"><li>启动[nn2]</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin&#x2F;hadoop-daemon.sh start namenode</span><br></pre></td></tr></table></figure><ol start="5"><li>将[nn1]切换为Active</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;hdfs haadmin -transitionToActive nn1</span><br></pre></td></tr></table></figure><ol start="6"><li>启动datanode</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin&#x2F;hadoop-daemons.sh start datanode</span><br></pre></td></tr></table></figure><ol start="6"><li>查看是否Active</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin&#x2F;hdfs haadmin -getServiceState nn1</span><br></pre></td></tr></table></figure><h2 id="自动故障转移"><a href="#自动故障转移" class="headerlink" title="自动故障转移"></a>自动故障转移</h2><p>具体配置</p><p>（1）在hdfs-site.xml中增加</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;dfs.ha.automatic-failover.enabled&lt;&#x2F;name&gt;</span><br><span class="line">&lt;value&gt;true&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br></pre></td></tr></table></figure><p>（2）在core-site.xml文件中增加</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;ha.zookeeper.quorum&lt;&#x2F;name&gt;</span><br><span class="line">&lt;value&gt;hadoop102:2181,hadoop103:2181,hadoop104:2181&lt;&#x2F;value&gt;</span><br><span class="line">&lt;&#x2F;property&gt;</span><br></pre></td></tr></table></figure><p>启动</p><p>（1）关闭所有HDFS服务：sbin/stop-dfs.sh</p><p>（2）启动Zookeeper集群：bin/zkServer.sh start</p><p>（3）初始化HA在Zookeeper中状态：bin/hdfs zkfc -formatZK</p><p>（4）启动HDFS服务：sbin/start-dfs.sh</p><p>集群规划：</p><table><thead><tr><th>hadoop102</th><th>hadoop103</th><th>hadoop104</th></tr></thead><tbody><tr><td>NameNode</td><td>NameNode</td><td></td></tr><tr><td>ZKFC</td><td>ZKFC</td><td></td></tr><tr><td>JournalNode</td><td>JournalNode</td><td>JournalNode</td></tr><tr><td>DataNode</td><td>DataNode</td><td>DataNode</td></tr><tr><td>ZK</td><td>ZK</td><td>ZK</td></tr><tr><td></td><td>ResourceManager</td><td></td></tr><tr><td>NodeManager</td><td>NodeManager</td><td>NodeManager</td></tr></tbody></table><h2 id="YARN-HA配置"><a href="#YARN-HA配置" class="headerlink" title="YARN-HA配置"></a>YARN-HA配置</h2><p>yarn-site.xml</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!--启用resourcemanager ha--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">    <span class="comment">&lt;!--声明两台resourcemanager的地址--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.cluster-id<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>cluster-yarn1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.rm-ids<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>rm1,rm2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop103<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">    <span class="comment">&lt;!--指定zookeeper集群的地址--&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.zk-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:2181,hadoop103:2181,hadoop104:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!--启用自动恢复--&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.recovery.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> </span><br><span class="line">    <span class="comment">&lt;!--指定resourcemanager的状态信息存储在zookeeper集群--&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.store.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span>     <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p>启动YARN</p><p>（1）在hadoop102中执行：sbin/start-yarn.sh</p><p>（2）在hadoop103中执行：sbin/yarn-daemon.sh start resourcemanager</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Mar 05 2021 21:11:12 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;包括HDFS的HA和YARN的HA&lt;/p&gt;&lt;h2 id=&quot;HDFS-HA的工作机制&quot;&gt;&lt;a href=&quot;#HDFS-HA的工作机制&quot; class
      
    
    </summary>
    
    
      <category term="Hadoop" scheme="http://kiedeng.github.io/categories/Hadoop/"/>
    
    
      <category term="默认" scheme="http://kiedeng.github.io/tags/%E9%BB%98%E8%AE%A4/"/>
    
  </entry>
  
  <entry>
    <title>shell脚本文件</title>
    <link href="http://kiedeng.github.io/2020/03/08/shell%E8%84%9A%E6%9C%AC%E6%96%87%E4%BB%B6/"/>
    <id>http://kiedeng.github.io/2020/03/08/shell%E8%84%9A%E6%9C%AC%E6%96%87%E4%BB%B6/</id>
    <published>2020-03-07T16:39:20.000Z</published>
    <updated>2020-03-07T16:41:48.903Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Mar 05 2021 21:11:12 GMT+0800 (GMT+08:00) --><h2 id="myjps"><a href="#myjps" class="headerlink" title="myjps"></a>myjps</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">for i in hadoop102 hadoop103 hadoop104</span><br><span class="line">do</span><br><span class="line">    echo "************* $i Jps ***********"</span><br><span class="line">    ssh $i /opt/module/jdk1.8.0_144/bin/jps</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h2 id="zookeeper集群管理脚本"><a href="#zookeeper集群管理脚本" class="headerlink" title="zookeeper集群管理脚本"></a>zookeeper集群管理脚本</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">if [ $# -eq 0 ]</span><br><span class="line">then</span><br><span class="line">    echo "No args Input...."</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">for i in hadoop102 hadoop103 hadoop104</span><br><span class="line">do</span><br><span class="line">    case $1 in</span><br><span class="line">    "start")</span><br><span class="line">        echo "*****************Start $i Zookeeper *************"</span><br><span class="line">        ssh $i /opt/module/zookeeper-3.4.10/bin/zkServer.sh start</span><br><span class="line">    ;;</span><br><span class="line">    "stop")</span><br><span class="line">                echo "*****************Stop $i Zookeeper *************"</span><br><span class="line">                ssh $i /opt/module/zookeeper-3.4.10/bin/zkServer.sh stop</span><br><span class="line">        ;;</span><br><span class="line">    "status")</span><br><span class="line">                echo "*****************Status $i Zookeeper *************"</span><br><span class="line">                ssh $i /opt/module/zookeeper-3.4.10/bin/zkServer.sh status</span><br><span class="line">        ;;</span><br><span class="line">    *)</span><br><span class="line">        echo "Input Args Error......"</span><br><span class="line">    esac</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h2 id="文件同步脚本"><a href="#文件同步脚本" class="headerlink" title="文件同步脚本"></a>文件同步脚本</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"><span class="meta">#</span><span class="bash">1 获取输入参数个数，如果没有参数，直接退出</span></span><br><span class="line">pcount=$#</span><br><span class="line">if((pcount==0)); then</span><br><span class="line">echo no args;</span><br><span class="line">exit;</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">2 获取文件名称</span></span><br><span class="line">p1=$1</span><br><span class="line">fname=`basename $p1`</span><br><span class="line">echo fname=$fname</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">3 获取上级目录到绝对路径</span></span><br><span class="line">pdir=`cd -P $(dirname $p1); pwd`</span><br><span class="line">echo pdir=$pdir</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">4 获取当前用户名称</span></span><br><span class="line">user=`whoami`</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">5 循环</span></span><br><span class="line">for((host=103; host&lt;105; host++)); do</span><br><span class="line">        echo ------------------- hadoop$host --------------</span><br><span class="line">        rsync -rvl $pdir/$fname $user@hadoop$host:$pdir</span><br><span class="line">done</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Mar 05 2021 21:11:12 GMT+0800 (GMT+08:00) --&gt;&lt;h2 id=&quot;myjps&quot;&gt;&lt;a href=&quot;#myjps&quot; class=&quot;headerlink&quot; title=&quot;myjps&quot;&gt;&lt;/a&gt;myjps&lt;
      
    
    </summary>
    
    
      <category term="Linux" scheme="http://kiedeng.github.io/categories/Linux/"/>
    
    
      <category term="默认" scheme="http://kiedeng.github.io/tags/%E9%BB%98%E8%AE%A4/"/>
    
  </entry>
  
  <entry>
    <title>shell操作</title>
    <link href="http://kiedeng.github.io/2020/03/07/shell%E6%93%8D%E4%BD%9C/"/>
    <id>http://kiedeng.github.io/2020/03/07/shell%E6%93%8D%E4%BD%9C/</id>
    <published>2020-03-07T09:28:34.000Z</published>
    <updated>2020-03-08T05:39:36.259Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Mar 05 2021 21:11:12 GMT+0800 (GMT+08:00) --><p>更改权限：chmod 777 [sh文件]</p><h2 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h2><p>案例：创建文件，写入数据</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">cd &#x2F;home&#x2F;atguigu&#x2F;zzuli</span><br><span class="line">touch chuang.txt</span><br><span class="line">echo &quot;kangdong&quot; &gt;&gt; chuang.txt</span><br></pre></td></tr></table></figure><h2 id="Shell中的变量"><a href="#Shell中的变量" class="headerlink" title="Shell中的变量"></a>Shell中的变量</h2><h3 id="系统变量"><a href="#系统变量" class="headerlink" title="系统变量"></a>系统变量</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash">HOME,<span class="variable">$PWD</span>,<span class="variable">$SHELL</span>,<span class="variable">$USER</span>等</span></span><br></pre></td></tr></table></figure><p>全局变量：export A</p><h3 id="自定义变量"><a href="#自定义变量" class="headerlink" title="自定义变量"></a>自定义变量</h3><p>撤销变量：unset 变量</p><p>声明静态变量：readonly变量，注意：不能unset</p><h3 id="特殊变量-n"><a href="#特殊变量-n" class="headerlink" title="特殊变量:$ n"></a>特殊变量:$ n</h3><p>$n （功能描述：n为数字，$0代表该脚本名称，$1-$9代表第一到第九个参数，十以上的参数，十以上的参数需要用大括号包含，如${10}）</p><h3 id="特殊变量："><a href="#特殊变量：" class="headerlink" title="特殊变量：$"></a>特殊变量：$</h3><p>获取所有输入参数个数，常用于循环</p><h3 id="特殊变量：-、"><a href="#特殊变量：-、" class="headerlink" title="特殊变量：$ *、$ @"></a>特殊变量：$ *、$ @</h3><p>​ $ * （功能描述：这个变量代表命令行中所有的参数，$*把所有的参数看成一个整体）</p><p>​ $ @ （功能描述：这个变量也代表命令行中所有的参数，不过$@把每个参数区分对待）</p><h3 id="特殊变量：-1"><a href="#特殊变量：-1" class="headerlink" title="特殊变量：$ ?"></a>特殊变量：$ ?</h3><p>判断最后一次执行的命令的返回状态，0位成功，非0为失败</p><h3 id="运算符"><a href="#运算符" class="headerlink" title="运算符"></a>运算符</h3><ol><li><p>“$ ((运算式))”或“$[运算式]”</p></li><li><p>expr + , - , *, /, % 加，减，乘，除，取余</p></li></ol><p>注意：expr运算符间要有空格</p><h2 id="条件判断"><a href="#条件判断" class="headerlink" title="条件判断"></a>条件判断</h2><p>格式：[condition]</p><p>判断条件：</p><ol><li><p>两个整数比较</p><p>-lt 小于（less than） -le 小于或等于（less equal）</p><p>-eq等于（equal） -gt大于（greater than）</p><p>-ge大于等于（greater equal） -ne不等于（Not equal）</p></li><li><p>按照文件权限进行判断</p><p>-r 读 -w写 -x 执行（execute）</p></li><li><p>按照文件类型进行判断</p><p>-f 文件存在并且是一个常规文件</p><p>-e 文件存在 -d为目录</p></li></ol><h2 id="流程控制"><a href="#流程控制" class="headerlink" title="流程控制"></a>流程控制</h2><h3 id="1-if判断"><a href="#1-if判断" class="headerlink" title="1 if判断"></a>1 if判断</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">if [ $1 -eq &quot;2&quot; ]</span><br><span class="line">then</span><br><span class="line">        echo &quot;2&quot;</span><br><span class="line">elif [ $1 -eq &quot;3&quot; ]</span><br><span class="line">then</span><br><span class="line">        echo &quot;3&quot;</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><h3 id="2-case语句"><a href="#2-case语句" class="headerlink" title="2 case语句"></a>2 case语句</h3><p>注意事项：</p><p>1) case行尾必须为单词“in”，每一个模式匹配必须以右括号“）”结束。</p><p>2) 双分号“<strong>;;</strong>”表示命令序列结束，相当于java中的break。</p><p>3) 最后的“*）”表示默认模式，相当于java中的default。</p><p>案例：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line">case $1 in</span><br><span class="line">"1")</span><br><span class="line">        echo "1 kangdong"</span><br><span class="line">;;</span><br><span class="line">"2")</span><br><span class="line">        echo "2 kangdong"</span><br><span class="line">;;</span><br><span class="line">"3")</span><br><span class="line">        echo "3 kangdong"</span><br><span class="line">;;</span><br><span class="line">*)</span><br><span class="line">        echo "* kangdong"</span><br><span class="line">;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure><h3 id="3-for循环"><a href="#3-for循环" class="headerlink" title="3 for循环"></a>3 for循环</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#&#x2F;bin&#x2F;bash</span><br><span class="line">s&#x3D;0</span><br><span class="line">for((i&#x3D;0;i&lt;&#x3D;100;i++))</span><br><span class="line">do</span><br><span class="line">        s&#x3D;$[$s+$i]</span><br><span class="line">done</span><br><span class="line">echo $s</span><br></pre></td></tr></table></figure><h3 id="4-比较-与"><a href="#4-比较-与" class="headerlink" title="4 比较$ *与$ @"></a>4 比较$ *与$ @</h3><p>未被双引号包含时，都分开输出，当被双引号包含时，“$*”会将所有参数作为一个整体输出</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">for i in "$*"</span><br><span class="line">do</span><br><span class="line">        echo "I am $i"</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line">for i in "$@"</span><br><span class="line">do</span><br><span class="line">        echo "My name $i"</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h3 id="5-while循环"><a href="#5-while循环" class="headerlink" title="5 while循环"></a>5 while循环</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">s=0</span><br><span class="line">i=0</span><br><span class="line">while [ $i -le 100 ]</span><br><span class="line">do</span><br><span class="line">        s=$[$i+$s]</span><br><span class="line">        i=$[$i+1]</span><br><span class="line">done</span><br><span class="line">echo $s</span><br></pre></td></tr></table></figure><h2 id="read读取控制台输入"><a href="#read读取控制台输入" class="headerlink" title="read读取控制台输入"></a>read读取控制台输入</h2><p>read(选项)(参数)</p><p>​ 选项：</p><p>-p：指定读取值时的提示符；</p><p>-t：指定读取值时等待的时间（秒）。</p><p>参数</p><p>​ 变量：指定读取值的变量名</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">read -t 9 -p "输入值:" name</span><br><span class="line">echo $name</span><br></pre></td></tr></table></figure><h2 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h2><h3 id="1-系统函数"><a href="#1-系统函数" class="headerlink" title="1 系统函数"></a>1 系统函数</h3><p><strong>basename [string / pathname] [suffix]</strong> 求文件名</p><p><strong>dirname</strong> ：求文件的目录</p><h3 id="2-自定义函数"><a href="#2-自定义函数" class="headerlink" title="2 自定义函数"></a>2 自定义函数</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">function sum()</span><br><span class="line">&#123;</span><br><span class="line">        s=0</span><br><span class="line">        s=$[$1+$2]</span><br><span class="line">        echo $s</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">read -p "输入s1：" n1;</span><br><span class="line">read -p "输入s2: " n2;</span><br><span class="line"></span><br><span class="line">sum $n1 $n2</span><br></pre></td></tr></table></figure><h2 id="Shell工具"><a href="#Shell工具" class="headerlink" title="Shell工具"></a>Shell工具</h2><h3 id="cut"><a href="#cut" class="headerlink" title="cut"></a>cut</h3><p>cut [选项参数] filename</p><p>-f 列号 -d 分隔符</p><h3 id="sed"><a href="#sed" class="headerlink" title="sed"></a>sed</h3><h3 id="awk"><a href="#awk" class="headerlink" title="awk"></a>awk</h3><p>一个强大的文本分析工具，把文件逐行的读入，以空格为默认分隔符将每行切片，切开的部分再进行分析处理。</p><h3 id="sort"><a href="#sort" class="headerlink" title="sort"></a>sort</h3><h2 id="企业真实面试题（重点）"><a href="#企业真实面试题（重点）" class="headerlink" title="企业真实面试题（重点）"></a>企业真实面试题（重点）</h2><p>《未完，，待续》</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Mar 05 2021 21:11:12 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;更改权限：chmod 777 [sh文件]&lt;/p&gt;&lt;h2 id=&quot;案例&quot;&gt;&lt;a href=&quot;#案例&quot; class=&quot;headerlink&quot; ti
      
    
    </summary>
    
    
      <category term="Linux" scheme="http://kiedeng.github.io/categories/Linux/"/>
    
    
      <category term="默认" scheme="http://kiedeng.github.io/tags/%E9%BB%98%E8%AE%A4/"/>
    
  </entry>
  
  <entry>
    <title>Zookeeper</title>
    <link href="http://kiedeng.github.io/2020/03/04/Zookeeper/"/>
    <id>http://kiedeng.github.io/2020/03/04/Zookeeper/</id>
    <published>2020-03-04T05:09:50.000Z</published>
    <updated>2020-03-08T05:30:50.554Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Mar 05 2021 21:11:12 GMT+0800 (GMT+08:00) --><p>​ Zookeeper是一个开源的分布式的，为分布式应用提供协调服务的Apache项目。多作为集群提供服务的中间件。</p><p>​ Zookeeper从设计模式角度来理解，是一个基于观察者模式设计的分布式服务管理框架。</p><h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><p>​ 提供的服务包括：统一命名服务，统一配置管理，统一集群管理，服务器节点动态上下线，软负载均衡等。</p><h4 id="1-统一命名服务"><a href="#1-统一命名服务" class="headerlink" title="1 统一命名服务"></a>1 统一命名服务</h4><p>​ 在分布式环境下，经常需要对应用/服务进行统一命名，便于识别。</p><h4 id="2-统一配置管理"><a href="#2-统一配置管理" class="headerlink" title="2 统一配置管理"></a>2 统一配置管理</h4><p>​ 1）分布式环境下，配置文件同步非常常见</p><p>​ 2）配置管理可交由ZooKeeper实现</p><h4 id="3-统一集群管理"><a href="#3-统一集群管理" class="headerlink" title="3 统一集群管理"></a>3 统一集群管理</h4><p>​ 1）分布式环境下，实时掌握节点的状态是必要的</p><p>​ 2）ZooKeeper可以实现实时监控节点状态变化</p><h4 id="4-服务器动态上下线"><a href="#4-服务器动态上下线" class="headerlink" title="4 服务器动态上下线"></a>4 服务器动态上下线</h4><p>​ 客户端能实时洞察服务器上下线的变化</p><h4 id="5-软负载均衡"><a href="#5-软负载均衡" class="headerlink" title="5 软负载均衡"></a>5 软负载均衡</h4><p>​ 在Zookeeper中记录每台服务器的访问数，让访问数最少的服务器去处理最新的客户端请求</p><h2 id="Zookeeper安装"><a href="#Zookeeper安装" class="headerlink" title="Zookeeper安装"></a>Zookeeper安装</h2><h3 id="本地模式安装部署"><a href="#本地模式安装部署" class="headerlink" title="本地模式安装部署"></a>本地模式安装部署</h3><h5 id="1-安装jdk，拷贝Zookeeper，解压到指定目录"><a href="#1-安装jdk，拷贝Zookeeper，解压到指定目录" class="headerlink" title="1 安装jdk，拷贝Zookeeper，解压到指定目录"></a>1 安装jdk，拷贝Zookeeper，解压到指定目录</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 software]$ tar -zxvf zookeeper-3.4.10.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure><h5 id="2-配置修改"><a href="#2-配置修改" class="headerlink" title="2 配置修改"></a>2 配置修改</h5><ul><li>将conf路径下的zoo_sample.cfg修改为zoo.cfg</li><li>修改dataDir路径，改为：dataDir=/opt/module/zookeeper-3.4.10/zkData</li><li>创建zkDataa文件夹</li></ul><h5 id="3-操作Zookeeper"><a href="#3-操作Zookeeper" class="headerlink" title="3 操作Zookeeper"></a>3 操作Zookeeper</h5><ol><li>启动：bin/zkServer.sh start</li><li>查看进程是否启动：jps</li><li>查看状态：bin/zkServer.sh status</li><li>启动客户端：bin/zkCli.sh</li><li>退出：quit</li><li>停止：bin/zkServer.sh stop</li></ol><h2 id="四字命令"><a href="#四字命令" class="headerlink" title="四字命令"></a>四字命令</h2><table><thead><tr><th>ruok</th><th>测试服务是否处于正确状态，如果确实如此，那么服务返回 imok ,否则不做任何响应。</th></tr></thead><tbody><tr><td>conf</td><td>3.3.0版本引入的，打印出服务相关配置的详细信息</td></tr><tr><td>cons</td><td>列出所有连接到这台服务器的客户端全部会话详细信息。包括 接收/发送的包数量，会话id，操作延迟、最后的操作执行等等信息</td></tr><tr><td>crst</td><td>重置所有连接的连接和会话统计信息</td></tr><tr><td>dump</td><td>列出那些比较重要的会话和临时节点。这个命令只能在leader节点上有用</td></tr><tr><td>envi</td><td>打印出服务环境的详细信息</td></tr></tbody></table><p>命令格式：nc localhost 2181</p><p>注: 使用之前，需要先安装nc，可以使用yum方式进行安装.</p><h2 id="配置参数解读"><a href="#配置参数解读" class="headerlink" title="配置参数解读"></a>配置参数解读</h2><p>zoo.cfg参数含义：</p><ol><li>tickTime：通信心跳数，Zookeeper服务器与客户端心跳时间，单位</li><li>initLimit=10:LF初始通信时限（第一次连接的超时时间）</li><li>syncLimit=5：LF同步通信时限（最大响应时间单位）</li><li>clientPort=2181：客户端连接端口</li></ol><h2 id="Zookeeper内容原理"><a href="#Zookeeper内容原理" class="headerlink" title="Zookeeper内容原理"></a>Zookeeper内容原理</h2><h3 id="选举机制"><a href="#选举机制" class="headerlink" title="选举机制"></a>选举机制</h3><p>半数机制：集群中半数以上机器存活，集群可用。</p><p>Zookeeper虽然在配置中并没有指定Master和Slave。但是，Zookeeper工作时，是有一个节点为Leader，其他则为Follower，Leader是通过内部的选举机制临时产生的。</p><h3 id="节点类型"><a href="#节点类型" class="headerlink" title="节点类型"></a>节点类型</h3><p>持久：客户端和服务器断开连接后，创建的节点不删除</p><p>短暂：客户端和服务器断开连接后，创建的节点自己删除</p><h3 id="监听器原理"><a href="#监听器原理" class="headerlink" title="监听器原理"></a>监听器原理</h3><p>监听器原理详解：</p><ol><li>首先要有一个main（）线程</li><li>创建Zookeeper客户端，两个线程，一个负责网络连接通信（connect），一个负责监听（listener）</li><li>通过connect线程将注册的监听事件发送给Zookeeper。</li><li>在Zookeeper的注册监听器列表将注册的监听事件添加到列表中</li><li>监听数据或路径变化，就会将这个消息发送给listener线程</li><li>listener线程内部调用了process（）方法</li></ol><h3 id="写数据流程"><a href="#写数据流程" class="headerlink" title="写数据流程"></a>写数据流程</h3><ol><li>Client发送一个写请求</li><li>如果Server不是Leader，在转给Leader，请求广播给各个Server</li><li>当Leader收到大多数Server数据写成功了，就说明数据写成功了</li><li>server通知Client数据写成功了</li></ol><h2 id="Zookeeper实战"><a href="#Zookeeper实战" class="headerlink" title="Zookeeper实战"></a>Zookeeper实战</h2><h3 id="1-集群规划"><a href="#1-集群规划" class="headerlink" title="1 集群规划"></a>1 集群规划</h3><p>在hadoop102,103,104三个节点上部署Zookeeper</p><h3 id="2-解压安装"><a href="#2-解压安装" class="headerlink" title="2 解压安装"></a>2 解压安装</h3><p>（1）解压到/opt/module目录下</p><p>（2）同步到hadoop103,104</p><h3 id="3-配置服务器编号"><a href="#3-配置服务器编号" class="headerlink" title="3 配置服务器编号"></a>3 配置服务器编号</h3><p>（1）在zookeeper目录下创建zkData</p><p>（2）在zkData目录下创建一个myid的文件</p><p>（3）编写myid文件，添加编号</p><p>（4）拷贝配置好的zookeeper到其他机器上</p><h3 id="4-配置zoo-cfg文件"><a href="#4-配置zoo-cfg文件" class="headerlink" title="4 配置zoo.cfg文件"></a>4 配置zoo.cfg文件</h3><p>（1）重命名zoo_sample.cfg为zoo.cfg</p><p>（2）打开zoo.cfg文件</p><p>修改数据存储路径配置，添加配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#######################cluster##########################</span><br><span class="line">server.2&#x3D;hadoop102:2888:3888</span><br><span class="line">server.3&#x3D;hadoop103:2888:3888</span><br><span class="line">server.4&#x3D;hadoop104:2888:3888</span><br></pre></td></tr></table></figure><p>（3）同步zoo.cfg配置文件</p><p>（4）配置参数解读： server.A=B:C:D</p><p>A是一个数字，代表这个是几号服务器</p><p>B是这个服务器的ip地址</p><p>C是这个服务器与集群中的Leader服务器交换信息的端口</p><p>D是集群服务器挂了，此端口执行服务器相互通信端口</p><h3 id="5-集群操作"><a href="#5-集群操作" class="headerlink" title="5 集群操作"></a>5 集群操作</h3><p>（1）分别启动Zookeeper：bin/zkServer.sh start</p><p>（2）查看状态：bin/zkServer.sh status</p><h2 id="客户端命令行操作"><a href="#客户端命令行操作" class="headerlink" title="客户端命令行操作"></a>客户端命令行操作</h2><table><thead><tr><th>命令基本语法</th><th>功能描述</th></tr></thead><tbody><tr><td>help</td><td>显示所有操作命令</td></tr><tr><td>ls path [watch]</td><td>使用 ls 命令来查看当前znode中所包含的内容</td></tr><tr><td>ls2 path [watch]</td><td>查看当前节点数据并能看到更新次数等数据</td></tr><tr><td>create</td><td>普通创建 -s 含有序列 -e 临时（重启或者超时消失）</td></tr><tr><td>get path [watch]</td><td>获得节点的值</td></tr><tr><td>set</td><td>设置节点的具体值</td></tr><tr><td>stat</td><td>查看节点状态</td></tr><tr><td>delete</td><td>删除节点</td></tr><tr><td>rmr</td><td>递归删除节点</td></tr></tbody></table><ol><li>启动客户端：bin/zkCli.sh</li><li>创短暂节点：create -e /sanguo “zhouyu”</li><li>创建带序号的节点：create -s /sanguo “kang”</li><li>监听节点数据：get /sang watch</li><li>监听节点数目：ls /sanguo watch</li><li>删除节点：delete</li><li>rmr /san</li><li>查看节点状态：stat /san</li></ol><h2 id="API应用"><a href="#API应用" class="headerlink" title="API应用"></a>API应用</h2><p>pom文件</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">version</span>&gt;</span>RELEASE<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.logging.log4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>log4j-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">version</span>&gt;</span>2.8.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.zookeeper/zookeeper --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.zookeeper<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>zookeeper<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">version</span>&gt;</span>3.4.10<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure><p>log4j.properties文件</p><p>需要在项目的src/main/resources目录下，新建一个文件，命名为“log4j.properties”，在文件中填入</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">log4j.rootLogger=INFO, stdout  </span><br><span class="line">log4j.appender.stdout=org.apache.log4j.ConsoleAppender  </span><br><span class="line">log4j.appender.stdout.layout=org.apache.log4j.PatternLayout  </span><br><span class="line">log4j.appender.stdout.layout.ConversionPattern=%d %p [%c] - %m%n  </span><br><span class="line">log4j.appender.logfile=org.apache.log4j.FileAppender  </span><br><span class="line">log4j.appender.logfile.File=target/spring.log  </span><br><span class="line">log4j.appender.logfile.layout=org.apache.log4j.PatternLayout  </span><br><span class="line">log4j.appender.logfile.layout.ConversionPattern=%d %p [%c] - %m%n</span><br></pre></td></tr></table></figure><h3 id="创建Zookeeper客户端"><a href="#创建Zookeeper客户端" class="headerlink" title="创建Zookeeper客户端"></a>创建Zookeeper客户端</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> String connectString =</span><br><span class="line"> <span class="string">"hadoop102:2181,hadoop103:2181,hadoop104:2181"</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> sessionTimeout = <span class="number">2000</span>;</span><br><span class="line"><span class="keyword">private</span> ZooKeeper zkClient = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Before</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">zkClient = <span class="keyword">new</span> ZooKeeper(connectString, sessionTimeout, <span class="keyword">new</span> Watcher() &#123;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(WatchedEvent event)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 收到事件通知后的回调函数（用户的业务逻辑）</span></span><br><span class="line">System.out.println(event.getType() + <span class="string">"--"</span> + event.getPath());</span><br><span class="line"></span><br><span class="line"><span class="comment">// 再次启动监听</span></span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">zkClient.getChildren(<span class="string">"/"</span>, <span class="keyword">true</span>);</span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="创建子节点"><a href="#创建子节点" class="headerlink" title="创建子节点"></a>创建子节点</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建子节点</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">create</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 参数1：要创建的节点的路径； 参数2：节点数据 ； 参数3：节点权限 ；参数4：节点的类型</span></span><br><span class="line">String nodeCreated = zkClient.create(<span class="string">"/atguigu"</span>, <span class="string">"jinlian"</span>.getBytes(), Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="获取子节点并监听节点变化"><a href="#获取子节点并监听节点变化" class="headerlink" title="获取子节点并监听节点变化"></a>获取子节点并监听节点变化</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取子节点</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">getChildren</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">List&lt;String&gt; children = zkClient.getChildren(<span class="string">"/"</span>, <span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (String child : children) &#123;</span><br><span class="line">System.out.println(child);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 延时阻塞</span></span><br><span class="line">Thread.sleep(Long.MAX_VALUE);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="判断Znode是否存在"><a href="#判断Znode是否存在" class="headerlink" title="判断Znode是否存在"></a>判断Znode是否存在</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 判断znode是否存在</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">exist</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">Stat stat = zkClient.exists(<span class="string">"/eclipse"</span>, <span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line">System.out.println(stat == <span class="keyword">null</span> ? <span class="string">"not exist"</span> : <span class="string">"exist"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="监听服务器节点动态上下线案例"><a href="#监听服务器节点动态上下线案例" class="headerlink" title="监听服务器节点动态上下线案例"></a>监听服务器节点动态上下线案例</h3><p>需求：某分布式系统中，主节点可以有多台，可以动态上下线，任意一台客户端都能实时感知到主节点服务器的上下线。</p><ol><li><p>先在集群上创建/servers节点</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 10] create /servers "servers"</span><br><span class="line">Created /servers</span><br></pre></td></tr></table></figure></li><li><p>服务器端注册代码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.zookeeper1;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.CreateMode;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.KeeperException;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.WatchedEvent;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.Watcher;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.ZooDefs.Ids;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.ZooKeeper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DistributeServer</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">DistributeServer server = <span class="keyword">new</span> DistributeServer();</span><br><span class="line"><span class="comment">// 1 连接zookeepeer集群</span></span><br><span class="line">server.getConnect();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2 注册节点</span></span><br><span class="line">server.regist(args[<span class="number">0</span>]);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 3 业务逻辑处理</span></span><br><span class="line">server.business();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">business</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">Thread.sleep(Long.MAX_VALUE);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">regist</span><span class="params">(String hostname)</span> <span class="keyword">throws</span> KeeperException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">String path = zkClient.create(<span class="string">"/servers/server"</span>, hostname.getBytes(), Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL_SEQUENTIAL);</span><br><span class="line">System.out.println(hostname +<span class="string">"is online!!"</span>);</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> String connectString=<span class="string">"hadoop102:2181,hadoop103:2181,hadoop104:2181"</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">int</span> sessionTimeout=<span class="number">2000</span>;</span><br><span class="line"><span class="keyword">private</span> ZooKeeper zkClient;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">getConnect</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line"></span><br><span class="line">zkClient=<span class="keyword">new</span> ZooKeeper(connectString, sessionTimeout, <span class="keyword">new</span> Watcher() &#123;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(WatchedEvent arg0)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">&#125;);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>客户端代码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.zookeeper1;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.KeeperException;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.WatchedEvent;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.Watcher;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.ZooKeeper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DistributeClient</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1 获取zookeeper集群连接</span></span><br><span class="line">DistributeClient client = <span class="keyword">new</span> DistributeClient();</span><br><span class="line">client.getConnect();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2 注册监听</span></span><br><span class="line">client.getChlidren();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 3 业务逻辑处理</span></span><br><span class="line">client.business();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">business</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">Thread.sleep(Long.MAX_VALUE);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">getChlidren</span><span class="params">()</span> <span class="keyword">throws</span> KeeperException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">List&lt;String&gt; children = zkClient.getChildren(<span class="string">"/servers"</span>, <span class="keyword">true</span>);</span><br><span class="line">ArrayList&lt;String&gt; hosts = <span class="keyword">new</span> ArrayList&lt;String&gt;();</span><br><span class="line"><span class="keyword">for</span> (String child : children) &#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">byte</span>[] data = zkClient.getData(<span class="string">"/servers/"</span>+child, <span class="keyword">false</span>, <span class="keyword">null</span>);</span><br><span class="line">hosts.add(<span class="keyword">new</span> String(data));</span><br><span class="line">&#125;</span><br><span class="line">System.out.println(hosts);</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> String connectString=<span class="string">"hadoop102:2181,hadoop103:2181,hadoop104:2181"</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">int</span> sessionTimeout=<span class="number">2000</span>;</span><br><span class="line"><span class="keyword">private</span> ZooKeeper zkClient;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">getConnect</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">zkClient = <span class="keyword">new</span> ZooKeeper(connectString, sessionTimeout, <span class="keyword">new</span> Watcher() &#123;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(WatchedEvent event)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">getChlidren();</span><br><span class="line">&#125; <span class="keyword">catch</span> (KeeperException e) &#123;</span><br><span class="line"><span class="comment">// TODO Auto-generated catch block</span></span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line"><span class="comment">// TODO Auto-generated catch block</span></span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125; </span><br><span class="line">&#125;</span><br><span class="line">&#125;);</span><br><span class="line">&#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line"><span class="comment">// TODO Auto-generated catch block</span></span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Mar 05 2021 21:11:12 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;​ Zookeeper是一个开源的分布式的，为分布式应用提供协调服务的Apache项目。多作为集群提供服务的中间件。&lt;/p&gt;&lt;p&gt;​ Zooke
      
    
    </summary>
    
    
      <category term="Zookeeper" scheme="http://kiedeng.github.io/categories/Zookeeper/"/>
    
    
      <category term="默认" scheme="http://kiedeng.github.io/tags/%E9%BB%98%E8%AE%A4/"/>
    
  </entry>
  
  <entry>
    <title>数据压缩</title>
    <link href="http://kiedeng.github.io/2020/03/01/%E6%95%B0%E6%8D%AE%E5%8E%8B%E7%BC%A9/"/>
    <id>http://kiedeng.github.io/2020/03/01/%E6%95%B0%E6%8D%AE%E5%8E%8B%E7%BC%A9/</id>
    <published>2020-03-01T04:39:39.000Z</published>
    <updated>2020-03-01T09:04:22.605Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Mar 05 2021 21:11:12 GMT+0800 (GMT+08:00) --><h2 id="1-概念："><a href="#1-概念：" class="headerlink" title="1 概念："></a>1 概念：</h2><p>​ 压缩技术能够有效减少底层存储系统读写字节数。在运行MR程序是，I/O操作，网络数据传输，Shuffle和Merge要花大量的时间</p><p>​ 压缩是提高Hadoop运行效率的一种优化策略</p><p>​ 注：运行密集型的job，少用压缩；IO密集型的job，多用压缩</p><h2 id="2-MR支持的压缩编码"><a href="#2-MR支持的压缩编码" class="headerlink" title="2 MR支持的压缩编码"></a>2 MR支持的压缩编码</h2><table><thead><tr><th>压缩格式</th><th>hadoop自带？</th><th>算法</th><th>文件扩展名</th><th>是否可切分</th><th>换成压缩格式后，原来的程序是否需要修改</th></tr></thead><tbody><tr><td>DEFLATE</td><td>是，直接使用</td><td>DEFLATE</td><td>.deflate</td><td>否</td><td>和文本处理一样，不需要修改</td></tr><tr><td>Gzip</td><td>是，直接使用</td><td>DEFLATE</td><td>.gz</td><td>否</td><td>和文本处理一样，不需要修改</td></tr><tr><td>bzip2</td><td>是，直接使用</td><td>bzip2</td><td>.bz2</td><td>是</td><td>和文本处理一样，不需要修改</td></tr><tr><td>LZO</td><td>否，需要安装</td><td>LZO</td><td>.lzo</td><td>是</td><td>需要建索引，还需要指定输入格式</td></tr><tr><td>Snappy</td><td>否，需要安装</td><td>Snappy</td><td>.snappy</td><td>否</td><td>和文本处理一样，不需要修改</td></tr></tbody></table><p>Hadoop引入了编码/解码器，如：</p><table><thead><tr><th>压缩格式</th><th>对应的编码/解码器</th></tr></thead><tbody><tr><td>DEFLATE</td><td>org.apache.hadoop.io.compress.DefaultCodec</td></tr><tr><td>gzip</td><td>org.apache.hadoop.io.compress.GzipCodec</td></tr><tr><td>bzip2</td><td>org.apache.hadoop.io.compress.BZip2Codec</td></tr><tr><td>LZO</td><td>com.hadoop.compression.lzo.LzopCodec</td></tr><tr><td>Snappy</td><td>org.apache.hadoop.io.compress.SnappyCodec</td></tr></tbody></table><h2 id="3-压缩方式选择"><a href="#3-压缩方式选择" class="headerlink" title="3 压缩方式选择"></a>3 压缩方式选择</h2><h3 id="Gzip压缩"><a href="#Gzip压缩" class="headerlink" title="Gzip压缩"></a>Gzip压缩</h3><p>优点：压缩率比较高，压缩速度比较快，本身支持，在应用中处理Gzip格式的文件和直接处理文本一样，大部分Linux系统自带；</p><p>缺点：不支持Split</p><p>应用场景：一个块大小内的数据，比如一天或者一个小时的日志信息</p><h3 id="Bzip2压缩"><a href="#Bzip2压缩" class="headerlink" title="Bzip2压缩"></a>Bzip2压缩</h3><p>优点：支持Split，具有很高的压缩率，比Gzip压缩率要高，自带，使用方便</p><p>缺点：压缩/解压速度比较慢</p><p>应用场景：适合对速度要求不高，但需要很高压缩率的时候；</p><h3 id="Lzo压缩"><a href="#Lzo压缩" class="headerlink" title="Lzo压缩"></a>Lzo压缩</h3><p>优点：压缩/解压速度比较快，合理的压缩率；支持Split,是Hadoop中最流行的压缩格式；</p><p>缺点：压缩率比Gzip低一些；需要安装，为了支持Split需要建索引，还需要指令InputFormat为Lzo格式</p><p>应用场景：一个很大的文件，压缩之后还大于200M以上的可以考虑，而且单个文件越大，Lzo优点越明显</p><h3 id="Snappy压缩"><a href="#Snappy压缩" class="headerlink" title="Snappy压缩"></a>Snappy压缩</h3><p>优点：高速压缩速度和合理的压缩率</p><p>缺点：不支持Split</p><p>应用场景：Map输出数据比较大的时候，作为Map到Reduce的中间数据的压缩格式；或者MapReduce的输出和另外一个MapReduce的输入</p><h2 id="4-压缩位置选择"><a href="#4-压缩位置选择" class="headerlink" title="4 压缩位置选择"></a>4 压缩位置选择</h2><p>1 输入端采用压缩</p><p>2 Mapper输出采用压缩</p><p>3 Reduce输出采用压缩</p><h2 id="5-压缩参数配置"><a href="#5-压缩参数配置" class="headerlink" title="5 压缩参数配置"></a>5 压缩参数配置</h2><table><thead><tr><th>参数</th><th>默认值</th><th>阶段</th><th>建议</th></tr></thead><tbody><tr><td>io.compression.codecs （在core-site.xml中配置）</td><td>org.apache.hadoop.io.compress.DefaultCodec, org.apache.hadoop.io.compress.GzipCodec, org.apache.hadoop.io.compress.BZip2Codec</td><td>输入压缩</td><td>Hadoop使用文件扩展名判断是否支持某种编解码器</td></tr><tr><td>mapreduce.map.output.compress（在mapred-site.xml中配置）</td><td>false</td><td>mapper输出</td><td>这个参数设为true启用压缩</td></tr><tr><td>mapreduce.map.output.compress.codec（在mapred-site.xml中配置）</td><td>org.apache.hadoop.io.compress.DefaultCodec</td><td>mapper输出</td><td>企业多使用LZO或Snappy编解码器在此阶段压缩数据</td></tr><tr><td>mapreduce.output.fileoutputformat.compress（在mapred-site.xml中配置）</td><td>false</td><td>reducer输出</td><td>这个参数设为true启用压缩</td></tr><tr><td>mapreduce.output.fileoutputformat.compress.codec（在mapred-site.xml中配置）</td><td>org.apache.hadoop.io.compress. DefaultCodec</td><td>reducer输出</td><td>使用标准工具或者编解码器，如gzip和bzip2</td></tr><tr><td>mapreduce.output.fileoutputformat.compress.type（在mapred-site.xml中配置）</td><td>RECORD</td><td>reducer输出</td><td>SequenceFile输出使用的压缩类型：NONE和BLOCK</td></tr></tbody></table><h2 id="6-压缩案例"><a href="#6-压缩案例" class="headerlink" title="6 压缩案例"></a>6 压缩案例</h2><h3 id="压缩解压案例"><a href="#压缩解压案例" class="headerlink" title="压缩解压案例"></a>压缩解压案例</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mapreduce.compress;</span><br><span class="line"><span class="keyword">import</span> java.io.File;</span><br><span class="line"><span class="keyword">import</span> java.io.FileInputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.FileNotFoundException;</span><br><span class="line"><span class="keyword">import</span> java.io.FileOutputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IOUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.compress.CompressionCodec;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.compress.CompressionCodecFactory;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.compress.CompressionInputStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.compress.CompressionOutputStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.util.ReflectionUtils;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestCompress</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">compress(<span class="string">"e:/hello.txt"</span>,<span class="string">"org.apache.hadoop.io.compress.BZip2Codec"</span>);</span><br><span class="line"><span class="comment">//decompress("e:/hello.txt.bz2");</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1、压缩</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">compress</span><span class="params">(String filename, String method)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// （1）获取输入流</span></span><br><span class="line">FileInputStream fis = <span class="keyword">new</span> FileInputStream(<span class="keyword">new</span> File(filename));</span><br><span class="line"></span><br><span class="line">Class codecClass = Class.forName(method);</span><br><span class="line"></span><br><span class="line">CompressionCodec codec = (CompressionCodec) ReflectionUtils.newInstance(codecClass, <span class="keyword">new</span> Configuration());</span><br><span class="line"></span><br><span class="line"><span class="comment">// （2）获取输出流</span></span><br><span class="line">FileOutputStream fos = <span class="keyword">new</span> FileOutputStream(<span class="keyword">new</span> File(filename + codec.getDefaultExtension()));</span><br><span class="line">CompressionOutputStream cos = codec.createOutputStream(fos);</span><br><span class="line"></span><br><span class="line"><span class="comment">// （3）流的对拷</span></span><br><span class="line">IOUtils.copyBytes(fis, cos, <span class="number">1024</span>*<span class="number">1024</span>*<span class="number">5</span>, <span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// （4）关闭资源</span></span><br><span class="line">cos.close();</span><br><span class="line">fos.close();</span><br><span class="line">fis.close();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2、解压缩</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">decompress</span><span class="params">(String filename)</span> <span class="keyword">throws</span> FileNotFoundException, IOException </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// （0）校验是否能解压缩</span></span><br><span class="line">CompressionCodecFactory factory = <span class="keyword">new</span> CompressionCodecFactory(<span class="keyword">new</span> Configuration());</span><br><span class="line"></span><br><span class="line">CompressionCodec codec = factory.getCodec(<span class="keyword">new</span> Path(filename));</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (codec == <span class="keyword">null</span>) &#123;</span><br><span class="line">System.out.println(<span class="string">"cannot find codec for file "</span> + filename);</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// （1）获取输入流</span></span><br><span class="line">CompressionInputStream cis = codec.createInputStream(<span class="keyword">new</span> FileInputStream(<span class="keyword">new</span> File(filename)));</span><br><span class="line"></span><br><span class="line"><span class="comment">// （2）获取输出流</span></span><br><span class="line">FileOutputStream fos = <span class="keyword">new</span> FileOutputStream(<span class="keyword">new</span> File(filename + <span class="string">".decoded"</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// （3）流的对拷</span></span><br><span class="line">IOUtils.copyBytes(cis, fos, <span class="number">1024</span>*<span class="number">1024</span>*<span class="number">5</span>, <span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// （4）关闭资源</span></span><br><span class="line">cis.close();</span><br><span class="line">fos.close();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Map输出端采用压缩"><a href="#Map输出端采用压缩" class="headerlink" title="Map输出端采用压缩"></a>Map输出端采用压缩</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 在Driver添加</span></span><br><span class="line"><span class="comment">// 开启map端输出压缩</span></span><br><span class="line">configuration.setBoolean(<span class="string">"mapreduce.map.output.compress"</span>, <span class="keyword">true</span>);</span><br><span class="line"><span class="comment">// 设置map端输出压缩方式</span></span><br><span class="line">configuration.setClass(<span class="string">"mapreduce.map.output.compress.codec"</span>, BZip2Codec<span class="class">.<span class="keyword">class</span>, <span class="title">CompressionCodec</span>.<span class="title">class</span>)</span>;</span><br></pre></td></tr></table></figure><h3 id="Reduce输出采用压缩"><a href="#Reduce输出采用压缩" class="headerlink" title="Reduce输出采用压缩"></a>Reduce输出采用压缩</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 设置reduce端输出压缩开启</span></span><br><span class="line">FileOutputFormat.setCompressOutput(job, <span class="keyword">true</span>);</span><br><span class="line"><span class="comment">// 设置压缩的方式</span></span><br><span class="line">FileOutputFormat.setOutputCompressorClass(job, BZip2Codec<span class="class">.<span class="keyword">class</span>)</span>;</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Mar 05 2021 21:11:12 GMT+0800 (GMT+08:00) --&gt;&lt;h2 id=&quot;1-概念：&quot;&gt;&lt;a href=&quot;#1-概念：&quot; class=&quot;headerlink&quot; title=&quot;1 概念：&quot;&gt;&lt;/a&gt;1 概念：&lt;
      
    
    </summary>
    
    
      <category term="Hadoop" scheme="http://kiedeng.github.io/categories/Hadoop/"/>
    
    
      <category term="默认" scheme="http://kiedeng.github.io/tags/%E9%BB%98%E8%AE%A4/"/>
    
  </entry>
  
  <entry>
    <title>MapReduce框架原理</title>
    <link href="http://kiedeng.github.io/2020/02/29/MapReduce%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86/"/>
    <id>http://kiedeng.github.io/2020/02/29/MapReduce%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86/</id>
    <published>2020-02-29T09:08:56.000Z</published>
    <updated>2020-02-29T13:57:55.988Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Mar 05 2021 21:11:12 GMT+0800 (GMT+08:00) --><ul><li>总结MapReduce框架原理</li></ul><h2 id="1-InputFotmat数据输入"><a href="#1-InputFotmat数据输入" class="headerlink" title="1 InputFotmat数据输入"></a>1 InputFotmat数据输入</h2><p>待写</p><h2 id="2-MapReduce工作流程"><a href="#2-MapReduce工作流程" class="headerlink" title="2 MapReduce工作流程"></a>2 MapReduce工作流程</h2><p>待写</p><h2 id="3-Shuffle机制"><a href="#3-Shuffle机制" class="headerlink" title="3 Shuffle机制"></a>3 Shuffle机制</h2><h3 id="3-1-Shuffle机制介绍"><a href="#3-1-Shuffle机制介绍" class="headerlink" title="3.1 Shuffle机制介绍"></a>3.1 Shuffle机制介绍</h3><p>Map方法之后，Reduce方法之前的数据称之为Shuffle</p><p>3.2 主要功能</p><p>Partition分区，WritableComparable排序，Combiner合并，GroupingComparator分组（辅助排序）</p><h2 id="4-MapTask工作机制"><a href="#4-MapTask工作机制" class="headerlink" title="4 MapTask工作机制"></a>4 MapTask工作机制</h2><p>​ （1）Read阶段：MapTask通过用户编写的RecordReader，从输入InputSplit中解析出一个个key/value。</p><p>​ （2）Map阶段：该节点主要是将解析出的key/value交给用户编写map()函数处理，并产生一系列新的key/value。</p><p>​ （3）Collect收集阶段：在用户编写map()函数中，当数据处理完成后，一般会调用OutputCollector.collect()输出结果。在该函数内部，它会将生成的key/value分区（调用Partitioner），并写入一个环形内存缓冲区中。</p><p>​ （4）Spill阶段：即“溢写”，当环形缓冲区满后，MapReduce会将数据写到本地磁盘上，生成一个临时文件。需要注意的是，将数据写入本地磁盘之前，先要对数据进行一次本地排序，并在必要时对数据进行合并、压缩等操作。</p><p>​ 溢写阶段详情：</p><p>​ 步骤1：利用快速排序算法对缓存区内的数据进行排序，排序方式是，先按照分区编号Partition进行排序，然后按照key进行排序。这样，经过排序后，数据以分区为单位聚集在一起，且同一分区内所有数据按照key有序。</p><p>​ 步骤2：按照分区编号由小到大依次将每个分区中的数据写入任务工作目录下的临时文件output/spillN.out（N表示当前溢写次数）中。如果用户设置了Combiner，则写入文件之前，对每个分区中的数据进行一次聚集操作。</p><p>​ 步骤3：将分区数据的元信息写到内存索引数据结构SpillRecord中，其中每个分区的元信息包括在临时文件中的偏移量、压缩前数据大小和压缩后数据大小。如果当前内存索引大小超过1MB，则将内存索引写到文件output/spillN.out.index中。</p><p>​ （5）Combine阶段：当所有数据处理完成后，MapTask对所有临时文件进行一次合并，以确保最终只会生成一个数据文件。</p><p>​ 当所有数据处理完后，MapTask会将所有临时文件合并成一个大文件，并保存到文件output/file.out中，同时生成相应的索引文件output/file.out.index。</p><p>​ 在进行文件合并过程中，MapTask以分区为单位进行合并。对于某个分区，它将采用多轮递归合并的方式。每轮合并io.sort.factor（默认10）个文件，并将产生的文件重新加入待合并列表中，对文件排序后，重复以上过程，直到最终得到一个大文件。</p><p>​ 让每个MapTask最终只生成一个数据文件，可避免同时打开大量文件和同时读取大量小文件产生的随机读取带来的开销。</p><h2 id="5-RedeceTask工作机制"><a href="#5-RedeceTask工作机制" class="headerlink" title="5 RedeceTask工作机制"></a>5 RedeceTask工作机制</h2><p>​ （1）Copy阶段：ReduceTask从各个MapTask上远程拷贝一片数据，并针对某一片数据，如果其大小超过一定阈值，则写到磁盘上，否则直接放到内存中。</p><p>​ （2）Merge阶段：在远程拷贝数据的同时，ReduceTask启动了两个后台线程对内存和磁盘上的文件进行合并，以防止内存使用过多或磁盘上文件过多。</p><p>​ （3）Sort阶段：按照MapReduce语义，用户编写reduce()函数输入数据是按key进行聚集的一组数据。为了将key相同的数据聚在一起，Hadoop采用了基于排序的策略。由于各个MapTask已经实现对自己的处理结果进行了局部排序，因此，ReduceTask只需对所有数据进行一次归并排序即可。</p><p>​ （4）Reduce阶段：reduce()函数将计算结果写到HDFS上。</p><h2 id="6-OutputFormat数据输出"><a href="#6-OutputFormat数据输出" class="headerlink" title="6 OutputFormat数据输出"></a>6 OutputFormat数据输出</h2><p>​ OutputFormat是MapReduce输出的基类，所有实现MapReduce输出都实现了OutputFormat接口。</p><p>下面我们介绍几种常见的OutputFormat实现类。</p><p>​ 1.文本输出TextOutputFormat默认的输出格式是TextOutputFormat，它把每条记录写为文本行。它的键和值可以是任意类型，因为TextOutputFormat调用toString0方法把它们转换为字符串。</p><p>​ 2.SequenceFileOutputFormat将SequenceFileOutputFormat输出作为后续MapReduce任务的输入，这便是一种好的输出格式，因为它的格式紧凑，很容易被压缩。</p><p>​ 3.自定义OutputFormat根据用户需求，自定义实现输出。</p><h3 id="6-1-自定义OutputFomat步骤"><a href="#6-1-自定义OutputFomat步骤" class="headerlink" title="6.1 自定义OutputFomat步骤"></a>6.1 自定义OutputFomat步骤</h3><p>​ （1）自定义一个类继承FileOutputFormat。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">package com.atguigu.mapreduce.outputformat;</span><br><span class="line">import java.io.IOException;</span><br><span class="line">import org.apache.hadoop.io.NullWritable;</span><br><span class="line">import org.apache.hadoop.io.Text;</span><br><span class="line">import org.apache.hadoop.mapreduce.RecordWriter;</span><br><span class="line">import org.apache.hadoop.mapreduce.TaskAttemptContext;</span><br><span class="line">import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line">public class FilterOutputFormat extends FileOutputFormat&lt;Text, NullWritable&gt;&#123;</span><br><span class="line"></span><br><span class="line">@Override</span><br><span class="line">public RecordWriter&lt;Text, NullWritable&gt; getRecordWriter(TaskAttemptContext job)throws IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 创建一个RecordWriter</span><br><span class="line">return new FilterRecordWriter(job);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>​ （2）改写RecordWriter，具体改写输出数据的方法write。</p><p>​ <strong>RecordWriter格式：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">package com.atguigu.mapreduce.outputformat;</span><br><span class="line">import java.io.IOException;</span><br><span class="line">import org.apache.hadoop.fs.FSDataOutputStream;</span><br><span class="line">import org.apache.hadoop.fs.FileSystem;</span><br><span class="line">import org.apache.hadoop.fs.Path;</span><br><span class="line">import org.apache.hadoop.io.NullWritable;</span><br><span class="line">import org.apache.hadoop.io.Text;</span><br><span class="line">import org.apache.hadoop.mapreduce.RecordWriter;</span><br><span class="line">import org.apache.hadoop.mapreduce.TaskAttemptContext;</span><br><span class="line"></span><br><span class="line">public class FilterRecordWriter extends RecordWriter&lt;Text, NullWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line">FSDataOutputStream atguiguOut &#x3D; null;</span><br><span class="line">FSDataOutputStream otherOut &#x3D; null;</span><br><span class="line"></span><br><span class="line">public FilterRecordWriter(TaskAttemptContext job) &#123;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 1 获取文件系统</span><br><span class="line">FileSystem fs;</span><br><span class="line"></span><br><span class="line">try &#123;</span><br><span class="line">fs &#x3D; FileSystem.get(job.getConfiguration());</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 2 创建输出文件路径</span><br><span class="line">Path atguiguPath &#x3D; new Path(&quot;e:&#x2F;atguigu.log&quot;);</span><br><span class="line">Path otherPath &#x3D; new Path(&quot;e:&#x2F;other.log&quot;);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 3 创建输出流</span><br><span class="line">atguiguOut &#x3D; fs.create(atguiguPath);</span><br><span class="line">otherOut &#x3D; fs.create(otherPath);</span><br><span class="line">&#125; catch (IOException e) &#123;</span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@Override</span><br><span class="line">public void write(Text key, NullWritable value) throws IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 判断是否包含“atguigu”输出到不同文件</span><br><span class="line">if (key.toString().contains(&quot;atguigu&quot;)) &#123;</span><br><span class="line">atguiguOut.write(key.toString().getBytes());</span><br><span class="line">&#125; else &#123;</span><br><span class="line">otherOut.write(key.toString().getBytes());</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@Override</span><br><span class="line">public void close(TaskAttemptContext context) throws IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 关闭资源</span><br><span class="line">IOUtils.closeStream(atguiguOut);</span><br><span class="line">IOUtils.closeStream(otherOut);&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意：记得将自定义输出格式设置到job中</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 要将自定义的输出格式组件设置到job中</span></span><br><span class="line">job.setOutputFormatClass(FilterOutputFormat<span class="class">.<span class="keyword">class</span>)</span>;</span><br></pre></td></tr></table></figure><h2 id="7-Join多种应用"><a href="#7-Join多种应用" class="headerlink" title="7 Join多种应用"></a>7 Join多种应用</h2><h3 id="7-1-工作原理"><a href="#7-1-工作原理" class="headerlink" title="7.1 工作原理"></a>7.1 工作原理</h3><p>​ Map端的主要工作：为来自不同表或文件的key/value对，打标签以区别不同来源的记录。然后用连接字段作为key，其余部分和新加的标志作为value，最后进行输出。</p><p>​ Reduce端的主要工作：在Reduce端以连接字段作为key的分组已经完成，我们只需要在每一个分组当中将那些来源于不同文件的记录（在Map阶段已经打标志分开，最后进行合并就ok了。</p><h3 id="7-2-Reduce-join"><a href="#7-2-Reduce-join" class="headerlink" title="7.2 Reduce join"></a>7.2 Reduce join</h3><p>​ 在Mapper阶段使得连接属性为key，其余属性为value（自定义bean对象，记得序列化），再用一个标记属性标记来自于哪个文件</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mapreduce.table;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileSplit;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TableMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">TableBean</span>&gt;</span>&#123;</span><br><span class="line"></span><br><span class="line">String name;</span><br><span class="line">TableBean bean = <span class="keyword">new</span> TableBean();</span><br><span class="line">Text k = <span class="keyword">new</span> Text();</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">setup</span><span class="params">(Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1 获取输入文件切片</span></span><br><span class="line">FileSplit split = (FileSplit) context.getInputSplit();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2 获取输入文件名称</span></span><br><span class="line">name = split.getPath().getName();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1 获取输入数据</span></span><br><span class="line">String line = value.toString();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2 不同文件分别处理</span></span><br><span class="line"><span class="keyword">if</span> (name.startsWith(<span class="string">"order"</span>)) &#123;<span class="comment">// 订单表处理</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 2.1 切割</span></span><br><span class="line">String[] fields = line.split(<span class="string">"\t"</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2.2 封装bean对象</span></span><br><span class="line">bean.setOrder_id(fields[<span class="number">0</span>]);</span><br><span class="line">bean.setP_id(fields[<span class="number">1</span>]);</span><br><span class="line">bean.setAmount(Integer.parseInt(fields[<span class="number">2</span>]));</span><br><span class="line">bean.setPname(<span class="string">""</span>);</span><br><span class="line">bean.setFlag(<span class="string">"order"</span>);</span><br><span class="line"></span><br><span class="line">k.set(fields[<span class="number">1</span>]);</span><br><span class="line">&#125;<span class="keyword">else</span> &#123;<span class="comment">// 产品表处理</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 2.3 切割</span></span><br><span class="line">String[] fields = line.split(<span class="string">"\t"</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2.4 封装bean对象</span></span><br><span class="line">bean.setP_id(fields[<span class="number">0</span>]);</span><br><span class="line">bean.setPname(fields[<span class="number">1</span>]);</span><br><span class="line">bean.setFlag(<span class="string">"pd"</span>);</span><br><span class="line">bean.setAmount(<span class="number">0</span>);</span><br><span class="line">bean.setOrder_id(<span class="string">""</span>);</span><br><span class="line"></span><br><span class="line">k.set(fields[<span class="number">0</span>]);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 3 写出</span></span><br><span class="line">context.write(k, bean);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>​ 在Reduce阶段，输出连接成功的bean对象</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mapreduce.table;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.beanutils.BeanUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TableReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">TableBean</span>, <span class="title">TableBean</span>, <span class="title">NullWritable</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;TableBean&gt; values, Context context)</span><span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1准备存储订单的集合</span></span><br><span class="line">ArrayList&lt;TableBean&gt; orderBeans = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2 准备bean对象</span></span><br><span class="line">TableBean pdBean = <span class="keyword">new</span> TableBean();</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (TableBean bean : values) &#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (<span class="string">"order"</span>.equals(bean.getFlag())) &#123;<span class="comment">// 订单表</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 拷贝传递过来的每条订单数据到集合中</span></span><br><span class="line">TableBean orderBean = <span class="keyword">new</span> TableBean();</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">BeanUtils.copyProperties(orderBean, bean);</span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">orderBeans.add(orderBean);</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;<span class="comment">// 产品表</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line"><span class="comment">// 拷贝传递过来的产品表到内存中</span></span><br><span class="line">BeanUtils.copyProperties(pdBean, bean);</span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 3 表的拼接</span></span><br><span class="line"><span class="keyword">for</span>(TableBean bean:orderBeans)&#123;</span><br><span class="line"></span><br><span class="line">bean.setPname (pdBean.getPname());</span><br><span class="line"></span><br><span class="line"><span class="comment">// 4 数据写出去</span></span><br><span class="line">context.write(bean, NullWritable.get());</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>缺点：这种方式中，合并的操作是在Reduce阶段完成，Reduce端的处理压力太大，Map节点的运算负载则很低，资源利用率不高，且在Reduce阶段极易产生数据倾斜。</p><h3 id="map-join"><a href="#map-join" class="headerlink" title="map join"></a>map join</h3><p>使用场景：Map Join适用于一张表十分小、一张表很大的场景。</p><p>具体办法：采用DistributedCache</p><p>​ （1）在Mapper的setup阶段，将文件读取到缓存集合中。</p><p>​ （2）在驱动函数中加载缓存。</p><p>​ // 缓存普通文件到Task运行节点。</p><p>​ job.addCacheFile(new URI(“file://e:/cache/pd.txt”));</p><p>注：简单说就是把一个小表用map表示，用大表的连接属性直接映射出小表的属性</p><p><strong>对于驱动模块Driver来说</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 6 加载缓存数据</span><br><span class="line">job.addCacheFile(new URI(&quot;file:&#x2F;&#x2F;&#x2F;e:&#x2F;input&#x2F;inputcache&#x2F;pd.txt&quot;));</span><br><span class="line">&#x2F;&#x2F; 7 Map端Join的逻辑不需要Reduce阶段，设置reduceTask数量为0</span><br><span class="line">job.setNumReduceTasks(0);</span><br></pre></td></tr></table></figure><p>对于mapper来说，先在map前读取缓存数据</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> test;</span><br><span class="line"><span class="keyword">import</span> java.io.BufferedReader;</span><br><span class="line"><span class="keyword">import</span> java.io.FileInputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.io.InputStreamReader;</span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.lang.StringUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DistributedCacheMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">NullWritable</span>&gt;</span>&#123;</span><br><span class="line"></span><br><span class="line">Map&lt;String, String&gt; pdMap = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">setup</span><span class="params">(Mapper&lt;LongWritable, Text, Text, NullWritable&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1 获取缓存的文件</span></span><br><span class="line">URI[] cacheFiles = context.getCacheFiles();</span><br><span class="line">String path = cacheFiles[<span class="number">0</span>].getPath().toString();</span><br><span class="line"></span><br><span class="line">BufferedReader reader = <span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> InputStreamReader(<span class="keyword">new</span> FileInputStream(path), <span class="string">"UTF-8"</span>));</span><br><span class="line"></span><br><span class="line">String line;</span><br><span class="line"><span class="keyword">while</span>(StringUtils.isNotEmpty(line = reader.readLine()))&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2 切割</span></span><br><span class="line">String[] fields = line.split(<span class="string">"\t"</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 3 缓存数据到集合</span></span><br><span class="line">pdMap.put(fields[<span class="number">0</span>], fields[<span class="number">1</span>]);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 4 关流</span></span><br><span class="line">reader.close();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Text k = <span class="keyword">new</span> Text();</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1 获取一行</span></span><br><span class="line">String line = value.toString();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2 截取</span></span><br><span class="line">String[] fields = line.split(<span class="string">"\t"</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 3 获取产品id</span></span><br><span class="line">String pId = fields[<span class="number">1</span>];</span><br><span class="line"></span><br><span class="line"><span class="comment">// 4 获取商品名称</span></span><br><span class="line">String pdName = pdMap.get(pId);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 5 拼接</span></span><br><span class="line">k.set(line + <span class="string">"\t"</span>+ pdName);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 6 写出</span></span><br><span class="line">context.write(k, NullWritable.get());</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="8-计数器应用与数据清洗（ETL）"><a href="#8-计数器应用与数据清洗（ETL）" class="headerlink" title="8 计数器应用与数据清洗（ETL）"></a>8 计数器应用与数据清洗（ETL）</h2><p>​ Hadoop为每个作业维护若干内置计数器，以描述多项指标。例如，某些计数器记录已处理的字节数和记录数，使用户可监控已处理的输入数据量和已产生的输出数据量。</p><p>使用方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">context.getCounter(<span class="string">"map"</span>,<span class="string">"失败"</span>).increment(<span class="number">1</span>);</span><br></pre></td></tr></table></figure><h2 id="9-MapRedece开发总结"><a href="#9-MapRedece开发总结" class="headerlink" title="9 MapRedece开发总结"></a>9 MapRedece开发总结</h2><h4 id="1-输入数据接口：InputFormat"><a href="#1-输入数据接口：InputFormat" class="headerlink" title="1. 输入数据接口：InputFormat"></a>1. 输入数据接口：InputFormat</h4><p>（1）默认使用的实现类是：TextInputFormat</p><p>（2）TextInputFormat的功能逻辑是：一次读一行文本，然后将该行的起始偏移量作为key，行内容作为value返回。</p><p>（3）KeyValueTextlnputFomat每一行均为一条记录，被分隔符分割为key，value。默认分隔符是tab（\t）。<br>（4）NlinelnputFormat按照指定的行数N来划分切片。</p><p>（5）CombineTextlnputFormat可以把多个小文件合并成一个切片处理，提高处理效率。</p><p>（6）用户还可以自定义ImputFormat。</p><h4 id="2-逻辑处理接口：Mapper"><a href="#2-逻辑处理接口：Mapper" class="headerlink" title="2.逻辑处理接口：Mapper"></a>2.逻辑处理接口：Mapper</h4><p>用户根据业务需求实现其中三个方法：map）setup）cleanup）</p><h4 id="3-Partitioner分区"><a href="#3-Partitioner分区" class="headerlink" title="3.Partitioner分区"></a>3.Partitioner分区</h4><p>（1）有默认实现HashPartitioner，逻辑是根据key的哈希值和numReduces来返回一个分区号；key hashCode（）&amp;Integer.MAXVALUE%<br>numReduces</p><p>（2）如果业务上有特别的需求，可以自定义分区。</p><h4 id="4-Comparable排序"><a href="#4-Comparable排序" class="headerlink" title="4.Comparable排序"></a>4.Comparable排序</h4><p>（1）当我们用自定义的对象作为key来输出时，就必须要实现WritableComparable接口，重写其中的compareTo0方法。</p><p>（2）部分排序：对最终输出的每一个文件进行内部排序。</p><p>（3）全排序：对所有数据进行排序，通常只有一个Reduce。</p><p>（4）二次排序：排序的条件有两个。</p><h4 id="5-Combiner合并"><a href="#5-Combiner合并" class="headerlink" title="5.Combiner合并"></a>5.Combiner合并</h4><p>Combiner合并可以提高程序执行效率，减少I0传输。但是使用时必须不能影响原有的业务处理结果。</p><h4 id="6-Reduce端分组：GroupingComparator"><a href="#6-Reduce端分组：GroupingComparator" class="headerlink" title="6.Reduce端分组：GroupingComparator"></a>6.Reduce端分组：GroupingComparator</h4><p>在Reduce端对key进行分组。应用于：在接收的key为bean对象时，想让一个或几个字段相同（全部字段比较不相同）的key进入到同一个reduce方法时，可以采用分组排序。</p><h4 id="7-逻辑处理接口："><a href="#7-逻辑处理接口：" class="headerlink" title="7.逻辑处理接口："></a>7.逻辑处理接口：</h4><p>Reducer用户根据业务需求实现其中三个方法：reduce();setup();cleanup()</p><h4 id="8-输出数据接口：OutputFormat"><a href="#8-输出数据接口：OutputFormat" class="headerlink" title="8.输出数据接口：OutputFormat"></a>8.输出数据接口：OutputFormat</h4><p>（1）默认实现类是TextOutputFormat，功能逻辑是：将每一个KV对，向目标文本文件输出一行。</p><p>（2）将SequenceFileOutputFormat输出作为后续MapReduce任务的输入，这便是一种好的输出格式，因为它的格式紧凑，很容易被压缩。</p><p>（3）用户还可以自定义OutputFormat。</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Mar 05 2021 21:11:12 GMT+0800 (GMT+08:00) --&gt;&lt;ul&gt;&lt;li&gt;总结MapReduce框架原理&lt;/li&gt;&lt;/ul&gt;&lt;h2 id=&quot;1-InputFotmat数据输入&quot;&gt;&lt;a href=&quot;#1-Inp
      
    
    </summary>
    
    
      <category term="Hadoop" scheme="http://kiedeng.github.io/categories/Hadoop/"/>
    
    
      <category term="默认" scheme="http://kiedeng.github.io/tags/%E9%BB%98%E8%AE%A4/"/>
    
  </entry>
  
</feed>
