<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hexo</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://kiedeng.github.io/"/>
  <updated>2020-03-07T16:41:48.903Z</updated>
  <id>http://kiedeng.github.io/</id>
  
  <author>
    <name>John Doe</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>shell脚本文件</title>
    <link href="http://kiedeng.github.io/2020/03/08/shell%E8%84%9A%E6%9C%AC%E6%96%87%E4%BB%B6/"/>
    <id>http://kiedeng.github.io/2020/03/08/shell%E8%84%9A%E6%9C%AC%E6%96%87%E4%BB%B6/</id>
    <published>2020-03-07T16:39:20.000Z</published>
    <updated>2020-03-07T16:41:48.903Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun Mar 08 2020 13:43:08 GMT+0800 (GMT+08:00) --><h2 id="myjps"><a href="#myjps" class="headerlink" title="myjps"></a>myjps</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">for i in hadoop102 hadoop103 hadoop104</span><br><span class="line">do</span><br><span class="line">    echo "************* $i Jps ***********"</span><br><span class="line">    ssh $i /opt/module/jdk1.8.0_144/bin/jps</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h2 id="zookeeper集群管理脚本"><a href="#zookeeper集群管理脚本" class="headerlink" title="zookeeper集群管理脚本"></a>zookeeper集群管理脚本</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">if [ $# -eq 0 ]</span><br><span class="line">then</span><br><span class="line">    echo "No args Input...."</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">for i in hadoop102 hadoop103 hadoop104</span><br><span class="line">do</span><br><span class="line">    case $1 in</span><br><span class="line">    "start")</span><br><span class="line">        echo "*****************Start $i Zookeeper *************"</span><br><span class="line">        ssh $i /opt/module/zookeeper-3.4.10/bin/zkServer.sh start</span><br><span class="line">    ;;</span><br><span class="line">    "stop")</span><br><span class="line">                echo "*****************Stop $i Zookeeper *************"</span><br><span class="line">                ssh $i /opt/module/zookeeper-3.4.10/bin/zkServer.sh stop</span><br><span class="line">        ;;</span><br><span class="line">    "status")</span><br><span class="line">                echo "*****************Status $i Zookeeper *************"</span><br><span class="line">                ssh $i /opt/module/zookeeper-3.4.10/bin/zkServer.sh status</span><br><span class="line">        ;;</span><br><span class="line">    *)</span><br><span class="line">        echo "Input Args Error......"</span><br><span class="line">    esac</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h2 id="文件同步脚本"><a href="#文件同步脚本" class="headerlink" title="文件同步脚本"></a>文件同步脚本</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"><span class="meta">#</span><span class="bash">1 获取输入参数个数，如果没有参数，直接退出</span></span><br><span class="line">pcount=$#</span><br><span class="line">if((pcount==0)); then</span><br><span class="line">echo no args;</span><br><span class="line">exit;</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">2 获取文件名称</span></span><br><span class="line">p1=$1</span><br><span class="line">fname=`basename $p1`</span><br><span class="line">echo fname=$fname</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">3 获取上级目录到绝对路径</span></span><br><span class="line">pdir=`cd -P $(dirname $p1); pwd`</span><br><span class="line">echo pdir=$pdir</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">4 获取当前用户名称</span></span><br><span class="line">user=`whoami`</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">5 循环</span></span><br><span class="line">for((host=103; host&lt;105; host++)); do</span><br><span class="line">        echo ------------------- hadoop$host --------------</span><br><span class="line">        rsync -rvl $pdir/$fname $user@hadoop$host:$pdir</span><br><span class="line">done</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sun Mar 08 2020 13:43:08 GMT+0800 (GMT+08:00) --&gt;&lt;h2 id=&quot;myjps&quot;&gt;&lt;a href=&quot;#myjps&quot; class=&quot;headerlink&quot; title=&quot;myjps&quot;&gt;&lt;/a&gt;myjps&lt;
      
    
    </summary>
    
    
      <category term="Linux" scheme="http://kiedeng.github.io/categories/Linux/"/>
    
    
      <category term="默认" scheme="http://kiedeng.github.io/tags/%E9%BB%98%E8%AE%A4/"/>
    
  </entry>
  
  <entry>
    <title>shell操作</title>
    <link href="http://kiedeng.github.io/2020/03/07/shell%E6%93%8D%E4%BD%9C/"/>
    <id>http://kiedeng.github.io/2020/03/07/shell%E6%93%8D%E4%BD%9C/</id>
    <published>2020-03-07T09:28:34.000Z</published>
    <updated>2020-03-08T05:39:36.259Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun Mar 08 2020 13:43:08 GMT+0800 (GMT+08:00) --><p>更改权限：chmod 777 [sh文件]</p><h2 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h2><p>案例：创建文件，写入数据</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">cd &#x2F;home&#x2F;atguigu&#x2F;zzuli</span><br><span class="line">touch chuang.txt</span><br><span class="line">echo &quot;kangdong&quot; &gt;&gt; chuang.txt</span><br></pre></td></tr></table></figure><h2 id="Shell中的变量"><a href="#Shell中的变量" class="headerlink" title="Shell中的变量"></a>Shell中的变量</h2><h3 id="系统变量"><a href="#系统变量" class="headerlink" title="系统变量"></a>系统变量</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash">HOME,<span class="variable">$PWD</span>,<span class="variable">$SHELL</span>,<span class="variable">$USER</span>等</span></span><br></pre></td></tr></table></figure><p>全局变量：export A</p><h3 id="自定义变量"><a href="#自定义变量" class="headerlink" title="自定义变量"></a>自定义变量</h3><p>撤销变量：unset 变量</p><p>声明静态变量：readonly变量，注意：不能unset</p><h3 id="特殊变量-n"><a href="#特殊变量-n" class="headerlink" title="特殊变量:$ n"></a>特殊变量:$ n</h3><p>$n （功能描述：n为数字，$0代表该脚本名称，$1-$9代表第一到第九个参数，十以上的参数，十以上的参数需要用大括号包含，如${10}）</p><h3 id="特殊变量："><a href="#特殊变量：" class="headerlink" title="特殊变量：$"></a>特殊变量：$</h3><p>获取所有输入参数个数，常用于循环</p><h3 id="特殊变量：-、"><a href="#特殊变量：-、" class="headerlink" title="特殊变量：$ *、$ @"></a>特殊变量：$ *、$ @</h3><p>​ $ * （功能描述：这个变量代表命令行中所有的参数，$*把所有的参数看成一个整体）</p><p>​ $ @ （功能描述：这个变量也代表命令行中所有的参数，不过$@把每个参数区分对待）</p><h3 id="特殊变量：-1"><a href="#特殊变量：-1" class="headerlink" title="特殊变量：$ ?"></a>特殊变量：$ ?</h3><p>判断最后一次执行的命令的返回状态，0位成功，非0为失败</p><h3 id="运算符"><a href="#运算符" class="headerlink" title="运算符"></a>运算符</h3><ol><li><p>“$ ((运算式))”或“$[运算式]”</p></li><li><p>expr + , - , *, /, % 加，减，乘，除，取余</p></li></ol><p>注意：expr运算符间要有空格</p><h2 id="条件判断"><a href="#条件判断" class="headerlink" title="条件判断"></a>条件判断</h2><p>格式：[condition]</p><p>判断条件：</p><ol><li><p>两个整数比较</p><p>-lt 小于（less than） -le 小于或等于（less equal）</p><p>-eq等于（equal） -gt大于（greater than）</p><p>-ge大于等于（greater equal） -ne不等于（Not equal）</p></li><li><p>按照文件权限进行判断</p><p>-r 读 -w写 -x 执行（execute）</p></li><li><p>按照文件类型进行判断</p><p>-f 文件存在并且是一个常规文件</p><p>-e 文件存在 -d为目录</p></li></ol><h2 id="流程控制"><a href="#流程控制" class="headerlink" title="流程控制"></a>流程控制</h2><h3 id="1-if判断"><a href="#1-if判断" class="headerlink" title="1 if判断"></a>1 if判断</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">if [ $1 -eq &quot;2&quot; ]</span><br><span class="line">then</span><br><span class="line">        echo &quot;2&quot;</span><br><span class="line">elif [ $1 -eq &quot;3&quot; ]</span><br><span class="line">then</span><br><span class="line">        echo &quot;3&quot;</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><h3 id="2-case语句"><a href="#2-case语句" class="headerlink" title="2 case语句"></a>2 case语句</h3><p>注意事项：</p><p>1) case行尾必须为单词“in”，每一个模式匹配必须以右括号“）”结束。</p><p>2) 双分号“<strong>;;</strong>”表示命令序列结束，相当于java中的break。</p><p>3) 最后的“*）”表示默认模式，相当于java中的default。</p><p>案例：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line">case $1 in</span><br><span class="line">"1")</span><br><span class="line">        echo "1 kangdong"</span><br><span class="line">;;</span><br><span class="line">"2")</span><br><span class="line">        echo "2 kangdong"</span><br><span class="line">;;</span><br><span class="line">"3")</span><br><span class="line">        echo "3 kangdong"</span><br><span class="line">;;</span><br><span class="line">*)</span><br><span class="line">        echo "* kangdong"</span><br><span class="line">;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure><h3 id="3-for循环"><a href="#3-for循环" class="headerlink" title="3 for循环"></a>3 for循环</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#&#x2F;bin&#x2F;bash</span><br><span class="line">s&#x3D;0</span><br><span class="line">for((i&#x3D;0;i&lt;&#x3D;100;i++))</span><br><span class="line">do</span><br><span class="line">        s&#x3D;$[$s+$i]</span><br><span class="line">done</span><br><span class="line">echo $s</span><br></pre></td></tr></table></figure><h3 id="4-比较-与"><a href="#4-比较-与" class="headerlink" title="4 比较$ *与$ @"></a>4 比较$ *与$ @</h3><p>未被双引号包含时，都分开输出，当被双引号包含时，“$*”会将所有参数作为一个整体输出</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">for i in "$*"</span><br><span class="line">do</span><br><span class="line">        echo "I am $i"</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line">for i in "$@"</span><br><span class="line">do</span><br><span class="line">        echo "My name $i"</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h3 id="5-while循环"><a href="#5-while循环" class="headerlink" title="5 while循环"></a>5 while循环</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">s=0</span><br><span class="line">i=0</span><br><span class="line">while [ $i -le 100 ]</span><br><span class="line">do</span><br><span class="line">        s=$[$i+$s]</span><br><span class="line">        i=$[$i+1]</span><br><span class="line">done</span><br><span class="line">echo $s</span><br></pre></td></tr></table></figure><h2 id="read读取控制台输入"><a href="#read读取控制台输入" class="headerlink" title="read读取控制台输入"></a>read读取控制台输入</h2><p>read(选项)(参数)</p><p>​ 选项：</p><p>-p：指定读取值时的提示符；</p><p>-t：指定读取值时等待的时间（秒）。</p><p>参数</p><p>​ 变量：指定读取值的变量名</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">read -t 9 -p "输入值:" name</span><br><span class="line">echo $name</span><br></pre></td></tr></table></figure><h2 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h2><h3 id="1-系统函数"><a href="#1-系统函数" class="headerlink" title="1 系统函数"></a>1 系统函数</h3><p><strong>basename [string / pathname] [suffix]</strong> 求文件名</p><p><strong>dirname</strong> ：求文件的目录</p><h3 id="2-自定义函数"><a href="#2-自定义函数" class="headerlink" title="2 自定义函数"></a>2 自定义函数</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">function sum()</span><br><span class="line">&#123;</span><br><span class="line">        s=0</span><br><span class="line">        s=$[$1+$2]</span><br><span class="line">        echo $s</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">read -p "输入s1：" n1;</span><br><span class="line">read -p "输入s2: " n2;</span><br><span class="line"></span><br><span class="line">sum $n1 $n2</span><br></pre></td></tr></table></figure><h2 id="Shell工具"><a href="#Shell工具" class="headerlink" title="Shell工具"></a>Shell工具</h2><h3 id="cut"><a href="#cut" class="headerlink" title="cut"></a>cut</h3><p>cut [选项参数] filename</p><p>-f 列号 -d 分隔符</p><h3 id="sed"><a href="#sed" class="headerlink" title="sed"></a>sed</h3><h3 id="awk"><a href="#awk" class="headerlink" title="awk"></a>awk</h3><p>一个强大的文本分析工具，把文件逐行的读入，以空格为默认分隔符将每行切片，切开的部分再进行分析处理。</p><h3 id="sort"><a href="#sort" class="headerlink" title="sort"></a>sort</h3><h2 id="企业真实面试题（重点）"><a href="#企业真实面试题（重点）" class="headerlink" title="企业真实面试题（重点）"></a>企业真实面试题（重点）</h2><p>《未完，，待续》</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sun Mar 08 2020 13:43:08 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;更改权限：chmod 777 [sh文件]&lt;/p&gt;&lt;h2 id=&quot;案例&quot;&gt;&lt;a href=&quot;#案例&quot; class=&quot;headerlink&quot; ti
      
    
    </summary>
    
    
      <category term="Linux" scheme="http://kiedeng.github.io/categories/Linux/"/>
    
    
      <category term="默认" scheme="http://kiedeng.github.io/tags/%E9%BB%98%E8%AE%A4/"/>
    
  </entry>
  
  <entry>
    <title>Zookeeper</title>
    <link href="http://kiedeng.github.io/2020/03/04/Zookeeper/"/>
    <id>http://kiedeng.github.io/2020/03/04/Zookeeper/</id>
    <published>2020-03-04T05:09:50.000Z</published>
    <updated>2020-03-08T05:30:50.554Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun Mar 08 2020 13:43:08 GMT+0800 (GMT+08:00) --><p>​ Zookeeper是一个开源的分布式的，为分布式应用提供协调服务的Apache项目。多作为集群提供服务的中间件。</p><p>​ Zookeeper从设计模式角度来理解，是一个基于观察者模式设计的分布式服务管理框架。</p><h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><p>​ 提供的服务包括：统一命名服务，统一配置管理，统一集群管理，服务器节点动态上下线，软负载均衡等。</p><h4 id="1-统一命名服务"><a href="#1-统一命名服务" class="headerlink" title="1 统一命名服务"></a>1 统一命名服务</h4><p>​ 在分布式环境下，经常需要对应用/服务进行统一命名，便于识别。</p><h4 id="2-统一配置管理"><a href="#2-统一配置管理" class="headerlink" title="2 统一配置管理"></a>2 统一配置管理</h4><p>​ 1）分布式环境下，配置文件同步非常常见</p><p>​ 2）配置管理可交由ZooKeeper实现</p><h4 id="3-统一集群管理"><a href="#3-统一集群管理" class="headerlink" title="3 统一集群管理"></a>3 统一集群管理</h4><p>​ 1）分布式环境下，实时掌握节点的状态是必要的</p><p>​ 2）ZooKeeper可以实现实时监控节点状态变化</p><h4 id="4-服务器动态上下线"><a href="#4-服务器动态上下线" class="headerlink" title="4 服务器动态上下线"></a>4 服务器动态上下线</h4><p>​ 客户端能实时洞察服务器上下线的变化</p><h4 id="5-软负载均衡"><a href="#5-软负载均衡" class="headerlink" title="5 软负载均衡"></a>5 软负载均衡</h4><p>​ 在Zookeeper中记录每台服务器的访问数，让访问数最少的服务器去处理最新的客户端请求</p><h2 id="Zookeeper安装"><a href="#Zookeeper安装" class="headerlink" title="Zookeeper安装"></a>Zookeeper安装</h2><h3 id="本地模式安装部署"><a href="#本地模式安装部署" class="headerlink" title="本地模式安装部署"></a>本地模式安装部署</h3><h5 id="1-安装jdk，拷贝Zookeeper，解压到指定目录"><a href="#1-安装jdk，拷贝Zookeeper，解压到指定目录" class="headerlink" title="1 安装jdk，拷贝Zookeeper，解压到指定目录"></a>1 安装jdk，拷贝Zookeeper，解压到指定目录</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 software]$ tar -zxvf zookeeper-3.4.10.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure><h5 id="2-配置修改"><a href="#2-配置修改" class="headerlink" title="2 配置修改"></a>2 配置修改</h5><ul><li>将conf路径下的zoo_sample.cfg修改为zoo.cfg</li><li>修改dataDir路径，改为：dataDir=/opt/module/zookeeper-3.4.10/zkData</li><li>创建zkDataa文件夹</li></ul><h5 id="3-操作Zookeeper"><a href="#3-操作Zookeeper" class="headerlink" title="3 操作Zookeeper"></a>3 操作Zookeeper</h5><ol><li>启动：bin/zkServer.sh start</li><li>查看进程是否启动：jps</li><li>查看状态：bin/zkServer.sh status</li><li>启动客户端：bin/zkCli.sh</li><li>退出：quit</li><li>停止：bin/zkServer.sh stop</li></ol><h2 id="四字命令"><a href="#四字命令" class="headerlink" title="四字命令"></a>四字命令</h2><table><thead><tr><th>ruok</th><th>测试服务是否处于正确状态，如果确实如此，那么服务返回 imok ,否则不做任何响应。</th></tr></thead><tbody><tr><td>conf</td><td>3.3.0版本引入的，打印出服务相关配置的详细信息</td></tr><tr><td>cons</td><td>列出所有连接到这台服务器的客户端全部会话详细信息。包括 接收/发送的包数量，会话id，操作延迟、最后的操作执行等等信息</td></tr><tr><td>crst</td><td>重置所有连接的连接和会话统计信息</td></tr><tr><td>dump</td><td>列出那些比较重要的会话和临时节点。这个命令只能在leader节点上有用</td></tr><tr><td>envi</td><td>打印出服务环境的详细信息</td></tr></tbody></table><p>命令格式：nc localhost 2181</p><p>注: 使用之前，需要先安装nc，可以使用yum方式进行安装.</p><h2 id="配置参数解读"><a href="#配置参数解读" class="headerlink" title="配置参数解读"></a>配置参数解读</h2><p>zoo.cfg参数含义：</p><ol><li>tickTime：通信心跳数，Zookeeper服务器与客户端心跳时间，单位</li><li>initLimit=10:LF初始通信时限（第一次连接的超时时间）</li><li>syncLimit=5：LF同步通信时限（最大响应时间单位）</li><li>clientPort=2181：客户端连接端口</li></ol><h2 id="Zookeeper内容原理"><a href="#Zookeeper内容原理" class="headerlink" title="Zookeeper内容原理"></a>Zookeeper内容原理</h2><h3 id="选举机制"><a href="#选举机制" class="headerlink" title="选举机制"></a>选举机制</h3><p>半数机制：集群中半数以上机器存活，集群可用。</p><p>Zookeeper虽然在配置中并没有指定Master和Slave。但是，Zookeeper工作时，是有一个节点为Leader，其他则为Follower，Leader是通过内部的选举机制临时产生的。</p><h3 id="节点类型"><a href="#节点类型" class="headerlink" title="节点类型"></a>节点类型</h3><p>持久：客户端和服务器断开连接后，创建的节点不删除</p><p>短暂：客户端和服务器断开连接后，创建的节点自己删除</p><h3 id="监听器原理"><a href="#监听器原理" class="headerlink" title="监听器原理"></a>监听器原理</h3><p>监听器原理详解：</p><ol><li>首先要有一个main（）线程</li><li>创建Zookeeper客户端，两个线程，一个负责网络连接通信（connect），一个负责监听（listener）</li><li>通过connect线程将注册的监听事件发送给Zookeeper。</li><li>在Zookeeper的注册监听器列表将注册的监听事件添加到列表中</li><li>监听数据或路径变化，就会将这个消息发送给listener线程</li><li>listener线程内部调用了process（）方法</li></ol><h3 id="写数据流程"><a href="#写数据流程" class="headerlink" title="写数据流程"></a>写数据流程</h3><ol><li>Client发送一个写请求</li><li>如果Server不是Leader，在转给Leader，请求广播给各个Server</li><li>当Leader收到大多数Server数据写成功了，就说明数据写成功了</li><li>server通知Client数据写成功了</li></ol><h2 id="Zookeeper实战"><a href="#Zookeeper实战" class="headerlink" title="Zookeeper实战"></a>Zookeeper实战</h2><h3 id="1-集群规划"><a href="#1-集群规划" class="headerlink" title="1 集群规划"></a>1 集群规划</h3><p>在hadoop102,103,104三个节点上部署Zookeeper</p><h3 id="2-解压安装"><a href="#2-解压安装" class="headerlink" title="2 解压安装"></a>2 解压安装</h3><p>（1）解压到/opt/module目录下</p><p>（2）同步到hadoop103,104</p><h3 id="3-配置服务器编号"><a href="#3-配置服务器编号" class="headerlink" title="3 配置服务器编号"></a>3 配置服务器编号</h3><p>（1）在zookeeper目录下创建zkData</p><p>（2）在zkData目录下创建一个myid的文件</p><p>（3）编写myid文件，添加编号</p><p>（4）拷贝配置好的zookeeper到其他机器上</p><h3 id="4-配置zoo-cfg文件"><a href="#4-配置zoo-cfg文件" class="headerlink" title="4 配置zoo.cfg文件"></a>4 配置zoo.cfg文件</h3><p>（1）重命名zoo_sample.cfg为zoo.cfg</p><p>（2）打开zoo.cfg文件</p><p>修改数据存储路径配置，添加配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#######################cluster##########################</span><br><span class="line">server.2&#x3D;hadoop102:2888:3888</span><br><span class="line">server.3&#x3D;hadoop103:2888:3888</span><br><span class="line">server.4&#x3D;hadoop104:2888:3888</span><br></pre></td></tr></table></figure><p>（3）同步zoo.cfg配置文件</p><p>（4）配置参数解读： server.A=B:C:D</p><p>A是一个数字，代表这个是几号服务器</p><p>B是这个服务器的ip地址</p><p>C是这个服务器与集群中的Leader服务器交换信息的端口</p><p>D是集群服务器挂了，此端口执行服务器相互通信端口</p><h3 id="5-集群操作"><a href="#5-集群操作" class="headerlink" title="5 集群操作"></a>5 集群操作</h3><p>（1）分别启动Zookeeper：bin/zkServer.sh start</p><p>（2）查看状态：bin/zkServer.sh status</p><h2 id="客户端命令行操作"><a href="#客户端命令行操作" class="headerlink" title="客户端命令行操作"></a>客户端命令行操作</h2><table><thead><tr><th>命令基本语法</th><th>功能描述</th></tr></thead><tbody><tr><td>help</td><td>显示所有操作命令</td></tr><tr><td>ls path [watch]</td><td>使用 ls 命令来查看当前znode中所包含的内容</td></tr><tr><td>ls2 path [watch]</td><td>查看当前节点数据并能看到更新次数等数据</td></tr><tr><td>create</td><td>普通创建 -s 含有序列 -e 临时（重启或者超时消失）</td></tr><tr><td>get path [watch]</td><td>获得节点的值</td></tr><tr><td>set</td><td>设置节点的具体值</td></tr><tr><td>stat</td><td>查看节点状态</td></tr><tr><td>delete</td><td>删除节点</td></tr><tr><td>rmr</td><td>递归删除节点</td></tr></tbody></table><ol><li>启动客户端：bin/zkCli.sh</li><li>创短暂节点：create -e /sanguo “zhouyu”</li><li>创建带序号的节点：create -s /sanguo “kang”</li><li>监听节点数据：get /sang watch</li><li>监听节点数目：ls /sanguo watch</li><li>删除节点：delete</li><li>rmr /san</li><li>查看节点状态：stat /san</li></ol><h2 id="API应用"><a href="#API应用" class="headerlink" title="API应用"></a>API应用</h2><p>pom文件</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">version</span>&gt;</span>RELEASE<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.logging.log4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>log4j-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">version</span>&gt;</span>2.8.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.zookeeper/zookeeper --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.zookeeper<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>zookeeper<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">version</span>&gt;</span>3.4.10<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure><p>log4j.properties文件</p><p>需要在项目的src/main/resources目录下，新建一个文件，命名为“log4j.properties”，在文件中填入</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">log4j.rootLogger=INFO, stdout  </span><br><span class="line">log4j.appender.stdout=org.apache.log4j.ConsoleAppender  </span><br><span class="line">log4j.appender.stdout.layout=org.apache.log4j.PatternLayout  </span><br><span class="line">log4j.appender.stdout.layout.ConversionPattern=%d %p [%c] - %m%n  </span><br><span class="line">log4j.appender.logfile=org.apache.log4j.FileAppender  </span><br><span class="line">log4j.appender.logfile.File=target/spring.log  </span><br><span class="line">log4j.appender.logfile.layout=org.apache.log4j.PatternLayout  </span><br><span class="line">log4j.appender.logfile.layout.ConversionPattern=%d %p [%c] - %m%n</span><br></pre></td></tr></table></figure><h3 id="创建Zookeeper客户端"><a href="#创建Zookeeper客户端" class="headerlink" title="创建Zookeeper客户端"></a>创建Zookeeper客户端</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> String connectString =</span><br><span class="line"> <span class="string">"hadoop102:2181,hadoop103:2181,hadoop104:2181"</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> sessionTimeout = <span class="number">2000</span>;</span><br><span class="line"><span class="keyword">private</span> ZooKeeper zkClient = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Before</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">zkClient = <span class="keyword">new</span> ZooKeeper(connectString, sessionTimeout, <span class="keyword">new</span> Watcher() &#123;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(WatchedEvent event)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 收到事件通知后的回调函数（用户的业务逻辑）</span></span><br><span class="line">System.out.println(event.getType() + <span class="string">"--"</span> + event.getPath());</span><br><span class="line"></span><br><span class="line"><span class="comment">// 再次启动监听</span></span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">zkClient.getChildren(<span class="string">"/"</span>, <span class="keyword">true</span>);</span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="创建子节点"><a href="#创建子节点" class="headerlink" title="创建子节点"></a>创建子节点</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建子节点</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">create</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 参数1：要创建的节点的路径； 参数2：节点数据 ； 参数3：节点权限 ；参数4：节点的类型</span></span><br><span class="line">String nodeCreated = zkClient.create(<span class="string">"/atguigu"</span>, <span class="string">"jinlian"</span>.getBytes(), Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="获取子节点并监听节点变化"><a href="#获取子节点并监听节点变化" class="headerlink" title="获取子节点并监听节点变化"></a>获取子节点并监听节点变化</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取子节点</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">getChildren</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">List&lt;String&gt; children = zkClient.getChildren(<span class="string">"/"</span>, <span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (String child : children) &#123;</span><br><span class="line">System.out.println(child);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 延时阻塞</span></span><br><span class="line">Thread.sleep(Long.MAX_VALUE);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="判断Znode是否存在"><a href="#判断Znode是否存在" class="headerlink" title="判断Znode是否存在"></a>判断Znode是否存在</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 判断znode是否存在</span></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">exist</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">Stat stat = zkClient.exists(<span class="string">"/eclipse"</span>, <span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line">System.out.println(stat == <span class="keyword">null</span> ? <span class="string">"not exist"</span> : <span class="string">"exist"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="监听服务器节点动态上下线案例"><a href="#监听服务器节点动态上下线案例" class="headerlink" title="监听服务器节点动态上下线案例"></a>监听服务器节点动态上下线案例</h3><p>需求：某分布式系统中，主节点可以有多台，可以动态上下线，任意一台客户端都能实时感知到主节点服务器的上下线。</p><ol><li><p>先在集群上创建/servers节点</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 10] create /servers "servers"</span><br><span class="line">Created /servers</span><br></pre></td></tr></table></figure></li><li><p>服务器端注册代码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.zookeeper1;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.CreateMode;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.KeeperException;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.WatchedEvent;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.Watcher;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.ZooDefs.Ids;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.ZooKeeper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DistributeServer</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">DistributeServer server = <span class="keyword">new</span> DistributeServer();</span><br><span class="line"><span class="comment">// 1 连接zookeepeer集群</span></span><br><span class="line">server.getConnect();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2 注册节点</span></span><br><span class="line">server.regist(args[<span class="number">0</span>]);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 3 业务逻辑处理</span></span><br><span class="line">server.business();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">business</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">Thread.sleep(Long.MAX_VALUE);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">regist</span><span class="params">(String hostname)</span> <span class="keyword">throws</span> KeeperException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">String path = zkClient.create(<span class="string">"/servers/server"</span>, hostname.getBytes(), Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL_SEQUENTIAL);</span><br><span class="line">System.out.println(hostname +<span class="string">"is online!!"</span>);</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> String connectString=<span class="string">"hadoop102:2181,hadoop103:2181,hadoop104:2181"</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">int</span> sessionTimeout=<span class="number">2000</span>;</span><br><span class="line"><span class="keyword">private</span> ZooKeeper zkClient;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">getConnect</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line"></span><br><span class="line">zkClient=<span class="keyword">new</span> ZooKeeper(connectString, sessionTimeout, <span class="keyword">new</span> Watcher() &#123;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(WatchedEvent arg0)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">&#125;);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>客户端代码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.zookeeper1;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.KeeperException;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.WatchedEvent;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.Watcher;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.ZooKeeper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DistributeClient</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1 获取zookeeper集群连接</span></span><br><span class="line">DistributeClient client = <span class="keyword">new</span> DistributeClient();</span><br><span class="line">client.getConnect();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2 注册监听</span></span><br><span class="line">client.getChlidren();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 3 业务逻辑处理</span></span><br><span class="line">client.business();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">business</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">Thread.sleep(Long.MAX_VALUE);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">getChlidren</span><span class="params">()</span> <span class="keyword">throws</span> KeeperException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">List&lt;String&gt; children = zkClient.getChildren(<span class="string">"/servers"</span>, <span class="keyword">true</span>);</span><br><span class="line">ArrayList&lt;String&gt; hosts = <span class="keyword">new</span> ArrayList&lt;String&gt;();</span><br><span class="line"><span class="keyword">for</span> (String child : children) &#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">byte</span>[] data = zkClient.getData(<span class="string">"/servers/"</span>+child, <span class="keyword">false</span>, <span class="keyword">null</span>);</span><br><span class="line">hosts.add(<span class="keyword">new</span> String(data));</span><br><span class="line">&#125;</span><br><span class="line">System.out.println(hosts);</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> String connectString=<span class="string">"hadoop102:2181,hadoop103:2181,hadoop104:2181"</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">int</span> sessionTimeout=<span class="number">2000</span>;</span><br><span class="line"><span class="keyword">private</span> ZooKeeper zkClient;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">getConnect</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">zkClient = <span class="keyword">new</span> ZooKeeper(connectString, sessionTimeout, <span class="keyword">new</span> Watcher() &#123;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(WatchedEvent event)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">getChlidren();</span><br><span class="line">&#125; <span class="keyword">catch</span> (KeeperException e) &#123;</span><br><span class="line"><span class="comment">// TODO Auto-generated catch block</span></span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line"><span class="comment">// TODO Auto-generated catch block</span></span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125; </span><br><span class="line">&#125;</span><br><span class="line">&#125;);</span><br><span class="line">&#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line"><span class="comment">// TODO Auto-generated catch block</span></span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sun Mar 08 2020 13:43:08 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;​ Zookeeper是一个开源的分布式的，为分布式应用提供协调服务的Apache项目。多作为集群提供服务的中间件。&lt;/p&gt;&lt;p&gt;​ Zooke
      
    
    </summary>
    
    
      <category term="Zookeeper" scheme="http://kiedeng.github.io/categories/Zookeeper/"/>
    
    
      <category term="默认" scheme="http://kiedeng.github.io/tags/%E9%BB%98%E8%AE%A4/"/>
    
  </entry>
  
  <entry>
    <title>数据压缩</title>
    <link href="http://kiedeng.github.io/2020/03/01/%E6%95%B0%E6%8D%AE%E5%8E%8B%E7%BC%A9/"/>
    <id>http://kiedeng.github.io/2020/03/01/%E6%95%B0%E6%8D%AE%E5%8E%8B%E7%BC%A9/</id>
    <published>2020-03-01T04:39:39.000Z</published>
    <updated>2020-03-01T09:04:22.605Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun Mar 08 2020 13:43:08 GMT+0800 (GMT+08:00) --><h2 id="1-概念："><a href="#1-概念：" class="headerlink" title="1 概念："></a>1 概念：</h2><p>​ 压缩技术能够有效减少底层存储系统读写字节数。在运行MR程序是，I/O操作，网络数据传输，Shuffle和Merge要花大量的时间</p><p>​ 压缩是提高Hadoop运行效率的一种优化策略</p><p>​ 注：运行密集型的job，少用压缩；IO密集型的job，多用压缩</p><h2 id="2-MR支持的压缩编码"><a href="#2-MR支持的压缩编码" class="headerlink" title="2 MR支持的压缩编码"></a>2 MR支持的压缩编码</h2><table><thead><tr><th>压缩格式</th><th>hadoop自带？</th><th>算法</th><th>文件扩展名</th><th>是否可切分</th><th>换成压缩格式后，原来的程序是否需要修改</th></tr></thead><tbody><tr><td>DEFLATE</td><td>是，直接使用</td><td>DEFLATE</td><td>.deflate</td><td>否</td><td>和文本处理一样，不需要修改</td></tr><tr><td>Gzip</td><td>是，直接使用</td><td>DEFLATE</td><td>.gz</td><td>否</td><td>和文本处理一样，不需要修改</td></tr><tr><td>bzip2</td><td>是，直接使用</td><td>bzip2</td><td>.bz2</td><td>是</td><td>和文本处理一样，不需要修改</td></tr><tr><td>LZO</td><td>否，需要安装</td><td>LZO</td><td>.lzo</td><td>是</td><td>需要建索引，还需要指定输入格式</td></tr><tr><td>Snappy</td><td>否，需要安装</td><td>Snappy</td><td>.snappy</td><td>否</td><td>和文本处理一样，不需要修改</td></tr></tbody></table><p>Hadoop引入了编码/解码器，如：</p><table><thead><tr><th>压缩格式</th><th>对应的编码/解码器</th></tr></thead><tbody><tr><td>DEFLATE</td><td>org.apache.hadoop.io.compress.DefaultCodec</td></tr><tr><td>gzip</td><td>org.apache.hadoop.io.compress.GzipCodec</td></tr><tr><td>bzip2</td><td>org.apache.hadoop.io.compress.BZip2Codec</td></tr><tr><td>LZO</td><td>com.hadoop.compression.lzo.LzopCodec</td></tr><tr><td>Snappy</td><td>org.apache.hadoop.io.compress.SnappyCodec</td></tr></tbody></table><h2 id="3-压缩方式选择"><a href="#3-压缩方式选择" class="headerlink" title="3 压缩方式选择"></a>3 压缩方式选择</h2><h3 id="Gzip压缩"><a href="#Gzip压缩" class="headerlink" title="Gzip压缩"></a>Gzip压缩</h3><p>优点：压缩率比较高，压缩速度比较快，本身支持，在应用中处理Gzip格式的文件和直接处理文本一样，大部分Linux系统自带；</p><p>缺点：不支持Split</p><p>应用场景：一个块大小内的数据，比如一天或者一个小时的日志信息</p><h3 id="Bzip2压缩"><a href="#Bzip2压缩" class="headerlink" title="Bzip2压缩"></a>Bzip2压缩</h3><p>优点：支持Split，具有很高的压缩率，比Gzip压缩率要高，自带，使用方便</p><p>缺点：压缩/解压速度比较慢</p><p>应用场景：适合对速度要求不高，但需要很高压缩率的时候；</p><h3 id="Lzo压缩"><a href="#Lzo压缩" class="headerlink" title="Lzo压缩"></a>Lzo压缩</h3><p>优点：压缩/解压速度比较快，合理的压缩率；支持Split,是Hadoop中最流行的压缩格式；</p><p>缺点：压缩率比Gzip低一些；需要安装，为了支持Split需要建索引，还需要指令InputFormat为Lzo格式</p><p>应用场景：一个很大的文件，压缩之后还大于200M以上的可以考虑，而且单个文件越大，Lzo优点越明显</p><h3 id="Snappy压缩"><a href="#Snappy压缩" class="headerlink" title="Snappy压缩"></a>Snappy压缩</h3><p>优点：高速压缩速度和合理的压缩率</p><p>缺点：不支持Split</p><p>应用场景：Map输出数据比较大的时候，作为Map到Reduce的中间数据的压缩格式；或者MapReduce的输出和另外一个MapReduce的输入</p><h2 id="4-压缩位置选择"><a href="#4-压缩位置选择" class="headerlink" title="4 压缩位置选择"></a>4 压缩位置选择</h2><p>1 输入端采用压缩</p><p>2 Mapper输出采用压缩</p><p>3 Reduce输出采用压缩</p><h2 id="5-压缩参数配置"><a href="#5-压缩参数配置" class="headerlink" title="5 压缩参数配置"></a>5 压缩参数配置</h2><table><thead><tr><th>参数</th><th>默认值</th><th>阶段</th><th>建议</th></tr></thead><tbody><tr><td>io.compression.codecs （在core-site.xml中配置）</td><td>org.apache.hadoop.io.compress.DefaultCodec, org.apache.hadoop.io.compress.GzipCodec, org.apache.hadoop.io.compress.BZip2Codec</td><td>输入压缩</td><td>Hadoop使用文件扩展名判断是否支持某种编解码器</td></tr><tr><td>mapreduce.map.output.compress（在mapred-site.xml中配置）</td><td>false</td><td>mapper输出</td><td>这个参数设为true启用压缩</td></tr><tr><td>mapreduce.map.output.compress.codec（在mapred-site.xml中配置）</td><td>org.apache.hadoop.io.compress.DefaultCodec</td><td>mapper输出</td><td>企业多使用LZO或Snappy编解码器在此阶段压缩数据</td></tr><tr><td>mapreduce.output.fileoutputformat.compress（在mapred-site.xml中配置）</td><td>false</td><td>reducer输出</td><td>这个参数设为true启用压缩</td></tr><tr><td>mapreduce.output.fileoutputformat.compress.codec（在mapred-site.xml中配置）</td><td>org.apache.hadoop.io.compress. DefaultCodec</td><td>reducer输出</td><td>使用标准工具或者编解码器，如gzip和bzip2</td></tr><tr><td>mapreduce.output.fileoutputformat.compress.type（在mapred-site.xml中配置）</td><td>RECORD</td><td>reducer输出</td><td>SequenceFile输出使用的压缩类型：NONE和BLOCK</td></tr></tbody></table><h2 id="6-压缩案例"><a href="#6-压缩案例" class="headerlink" title="6 压缩案例"></a>6 压缩案例</h2><h3 id="压缩解压案例"><a href="#压缩解压案例" class="headerlink" title="压缩解压案例"></a>压缩解压案例</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mapreduce.compress;</span><br><span class="line"><span class="keyword">import</span> java.io.File;</span><br><span class="line"><span class="keyword">import</span> java.io.FileInputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.FileNotFoundException;</span><br><span class="line"><span class="keyword">import</span> java.io.FileOutputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IOUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.compress.CompressionCodec;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.compress.CompressionCodecFactory;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.compress.CompressionInputStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.compress.CompressionOutputStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.util.ReflectionUtils;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestCompress</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">compress(<span class="string">"e:/hello.txt"</span>,<span class="string">"org.apache.hadoop.io.compress.BZip2Codec"</span>);</span><br><span class="line"><span class="comment">//decompress("e:/hello.txt.bz2");</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1、压缩</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">compress</span><span class="params">(String filename, String method)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// （1）获取输入流</span></span><br><span class="line">FileInputStream fis = <span class="keyword">new</span> FileInputStream(<span class="keyword">new</span> File(filename));</span><br><span class="line"></span><br><span class="line">Class codecClass = Class.forName(method);</span><br><span class="line"></span><br><span class="line">CompressionCodec codec = (CompressionCodec) ReflectionUtils.newInstance(codecClass, <span class="keyword">new</span> Configuration());</span><br><span class="line"></span><br><span class="line"><span class="comment">// （2）获取输出流</span></span><br><span class="line">FileOutputStream fos = <span class="keyword">new</span> FileOutputStream(<span class="keyword">new</span> File(filename + codec.getDefaultExtension()));</span><br><span class="line">CompressionOutputStream cos = codec.createOutputStream(fos);</span><br><span class="line"></span><br><span class="line"><span class="comment">// （3）流的对拷</span></span><br><span class="line">IOUtils.copyBytes(fis, cos, <span class="number">1024</span>*<span class="number">1024</span>*<span class="number">5</span>, <span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// （4）关闭资源</span></span><br><span class="line">cos.close();</span><br><span class="line">fos.close();</span><br><span class="line">fis.close();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2、解压缩</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">decompress</span><span class="params">(String filename)</span> <span class="keyword">throws</span> FileNotFoundException, IOException </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// （0）校验是否能解压缩</span></span><br><span class="line">CompressionCodecFactory factory = <span class="keyword">new</span> CompressionCodecFactory(<span class="keyword">new</span> Configuration());</span><br><span class="line"></span><br><span class="line">CompressionCodec codec = factory.getCodec(<span class="keyword">new</span> Path(filename));</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (codec == <span class="keyword">null</span>) &#123;</span><br><span class="line">System.out.println(<span class="string">"cannot find codec for file "</span> + filename);</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// （1）获取输入流</span></span><br><span class="line">CompressionInputStream cis = codec.createInputStream(<span class="keyword">new</span> FileInputStream(<span class="keyword">new</span> File(filename)));</span><br><span class="line"></span><br><span class="line"><span class="comment">// （2）获取输出流</span></span><br><span class="line">FileOutputStream fos = <span class="keyword">new</span> FileOutputStream(<span class="keyword">new</span> File(filename + <span class="string">".decoded"</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// （3）流的对拷</span></span><br><span class="line">IOUtils.copyBytes(cis, fos, <span class="number">1024</span>*<span class="number">1024</span>*<span class="number">5</span>, <span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// （4）关闭资源</span></span><br><span class="line">cis.close();</span><br><span class="line">fos.close();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Map输出端采用压缩"><a href="#Map输出端采用压缩" class="headerlink" title="Map输出端采用压缩"></a>Map输出端采用压缩</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 在Driver添加</span></span><br><span class="line"><span class="comment">// 开启map端输出压缩</span></span><br><span class="line">configuration.setBoolean(<span class="string">"mapreduce.map.output.compress"</span>, <span class="keyword">true</span>);</span><br><span class="line"><span class="comment">// 设置map端输出压缩方式</span></span><br><span class="line">configuration.setClass(<span class="string">"mapreduce.map.output.compress.codec"</span>, BZip2Codec<span class="class">.<span class="keyword">class</span>, <span class="title">CompressionCodec</span>.<span class="title">class</span>)</span>;</span><br></pre></td></tr></table></figure><h3 id="Reduce输出采用压缩"><a href="#Reduce输出采用压缩" class="headerlink" title="Reduce输出采用压缩"></a>Reduce输出采用压缩</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 设置reduce端输出压缩开启</span></span><br><span class="line">FileOutputFormat.setCompressOutput(job, <span class="keyword">true</span>);</span><br><span class="line"><span class="comment">// 设置压缩的方式</span></span><br><span class="line">FileOutputFormat.setOutputCompressorClass(job, BZip2Codec<span class="class">.<span class="keyword">class</span>)</span>;</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sun Mar 08 2020 13:43:08 GMT+0800 (GMT+08:00) --&gt;&lt;h2 id=&quot;1-概念：&quot;&gt;&lt;a href=&quot;#1-概念：&quot; class=&quot;headerlink&quot; title=&quot;1 概念：&quot;&gt;&lt;/a&gt;1 概念：&lt;
      
    
    </summary>
    
    
      <category term="Hadoop" scheme="http://kiedeng.github.io/categories/Hadoop/"/>
    
    
      <category term="默认" scheme="http://kiedeng.github.io/tags/%E9%BB%98%E8%AE%A4/"/>
    
  </entry>
  
  <entry>
    <title>MapReduce框架原理</title>
    <link href="http://kiedeng.github.io/2020/02/29/MapReduce%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86/"/>
    <id>http://kiedeng.github.io/2020/02/29/MapReduce%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86/</id>
    <published>2020-02-29T09:08:56.000Z</published>
    <updated>2020-02-29T13:57:55.988Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun Mar 08 2020 13:43:08 GMT+0800 (GMT+08:00) --><ul><li>总结MapReduce框架原理</li></ul><h2 id="1-InputFotmat数据输入"><a href="#1-InputFotmat数据输入" class="headerlink" title="1 InputFotmat数据输入"></a>1 InputFotmat数据输入</h2><p>待写</p><h2 id="2-MapReduce工作流程"><a href="#2-MapReduce工作流程" class="headerlink" title="2 MapReduce工作流程"></a>2 MapReduce工作流程</h2><p>待写</p><h2 id="3-Shuffle机制"><a href="#3-Shuffle机制" class="headerlink" title="3 Shuffle机制"></a>3 Shuffle机制</h2><h3 id="3-1-Shuffle机制介绍"><a href="#3-1-Shuffle机制介绍" class="headerlink" title="3.1 Shuffle机制介绍"></a>3.1 Shuffle机制介绍</h3><p>Map方法之后，Reduce方法之前的数据称之为Shuffle</p><p>3.2 主要功能</p><p>Partition分区，WritableComparable排序，Combiner合并，GroupingComparator分组（辅助排序）</p><h2 id="4-MapTask工作机制"><a href="#4-MapTask工作机制" class="headerlink" title="4 MapTask工作机制"></a>4 MapTask工作机制</h2><p>​ （1）Read阶段：MapTask通过用户编写的RecordReader，从输入InputSplit中解析出一个个key/value。</p><p>​ （2）Map阶段：该节点主要是将解析出的key/value交给用户编写map()函数处理，并产生一系列新的key/value。</p><p>​ （3）Collect收集阶段：在用户编写map()函数中，当数据处理完成后，一般会调用OutputCollector.collect()输出结果。在该函数内部，它会将生成的key/value分区（调用Partitioner），并写入一个环形内存缓冲区中。</p><p>​ （4）Spill阶段：即“溢写”，当环形缓冲区满后，MapReduce会将数据写到本地磁盘上，生成一个临时文件。需要注意的是，将数据写入本地磁盘之前，先要对数据进行一次本地排序，并在必要时对数据进行合并、压缩等操作。</p><p>​ 溢写阶段详情：</p><p>​ 步骤1：利用快速排序算法对缓存区内的数据进行排序，排序方式是，先按照分区编号Partition进行排序，然后按照key进行排序。这样，经过排序后，数据以分区为单位聚集在一起，且同一分区内所有数据按照key有序。</p><p>​ 步骤2：按照分区编号由小到大依次将每个分区中的数据写入任务工作目录下的临时文件output/spillN.out（N表示当前溢写次数）中。如果用户设置了Combiner，则写入文件之前，对每个分区中的数据进行一次聚集操作。</p><p>​ 步骤3：将分区数据的元信息写到内存索引数据结构SpillRecord中，其中每个分区的元信息包括在临时文件中的偏移量、压缩前数据大小和压缩后数据大小。如果当前内存索引大小超过1MB，则将内存索引写到文件output/spillN.out.index中。</p><p>​ （5）Combine阶段：当所有数据处理完成后，MapTask对所有临时文件进行一次合并，以确保最终只会生成一个数据文件。</p><p>​ 当所有数据处理完后，MapTask会将所有临时文件合并成一个大文件，并保存到文件output/file.out中，同时生成相应的索引文件output/file.out.index。</p><p>​ 在进行文件合并过程中，MapTask以分区为单位进行合并。对于某个分区，它将采用多轮递归合并的方式。每轮合并io.sort.factor（默认10）个文件，并将产生的文件重新加入待合并列表中，对文件排序后，重复以上过程，直到最终得到一个大文件。</p><p>​ 让每个MapTask最终只生成一个数据文件，可避免同时打开大量文件和同时读取大量小文件产生的随机读取带来的开销。</p><h2 id="5-RedeceTask工作机制"><a href="#5-RedeceTask工作机制" class="headerlink" title="5 RedeceTask工作机制"></a>5 RedeceTask工作机制</h2><p>​ （1）Copy阶段：ReduceTask从各个MapTask上远程拷贝一片数据，并针对某一片数据，如果其大小超过一定阈值，则写到磁盘上，否则直接放到内存中。</p><p>​ （2）Merge阶段：在远程拷贝数据的同时，ReduceTask启动了两个后台线程对内存和磁盘上的文件进行合并，以防止内存使用过多或磁盘上文件过多。</p><p>​ （3）Sort阶段：按照MapReduce语义，用户编写reduce()函数输入数据是按key进行聚集的一组数据。为了将key相同的数据聚在一起，Hadoop采用了基于排序的策略。由于各个MapTask已经实现对自己的处理结果进行了局部排序，因此，ReduceTask只需对所有数据进行一次归并排序即可。</p><p>​ （4）Reduce阶段：reduce()函数将计算结果写到HDFS上。</p><h2 id="6-OutputFormat数据输出"><a href="#6-OutputFormat数据输出" class="headerlink" title="6 OutputFormat数据输出"></a>6 OutputFormat数据输出</h2><p>​ OutputFormat是MapReduce输出的基类，所有实现MapReduce输出都实现了OutputFormat接口。</p><p>下面我们介绍几种常见的OutputFormat实现类。</p><p>​ 1.文本输出TextOutputFormat默认的输出格式是TextOutputFormat，它把每条记录写为文本行。它的键和值可以是任意类型，因为TextOutputFormat调用toString0方法把它们转换为字符串。</p><p>​ 2.SequenceFileOutputFormat将SequenceFileOutputFormat输出作为后续MapReduce任务的输入，这便是一种好的输出格式，因为它的格式紧凑，很容易被压缩。</p><p>​ 3.自定义OutputFormat根据用户需求，自定义实现输出。</p><h3 id="6-1-自定义OutputFomat步骤"><a href="#6-1-自定义OutputFomat步骤" class="headerlink" title="6.1 自定义OutputFomat步骤"></a>6.1 自定义OutputFomat步骤</h3><p>​ （1）自定义一个类继承FileOutputFormat。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">package com.atguigu.mapreduce.outputformat;</span><br><span class="line">import java.io.IOException;</span><br><span class="line">import org.apache.hadoop.io.NullWritable;</span><br><span class="line">import org.apache.hadoop.io.Text;</span><br><span class="line">import org.apache.hadoop.mapreduce.RecordWriter;</span><br><span class="line">import org.apache.hadoop.mapreduce.TaskAttemptContext;</span><br><span class="line">import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line">public class FilterOutputFormat extends FileOutputFormat&lt;Text, NullWritable&gt;&#123;</span><br><span class="line"></span><br><span class="line">@Override</span><br><span class="line">public RecordWriter&lt;Text, NullWritable&gt; getRecordWriter(TaskAttemptContext job)throws IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 创建一个RecordWriter</span><br><span class="line">return new FilterRecordWriter(job);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>​ （2）改写RecordWriter，具体改写输出数据的方法write。</p><p>​ <strong>RecordWriter格式：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">package com.atguigu.mapreduce.outputformat;</span><br><span class="line">import java.io.IOException;</span><br><span class="line">import org.apache.hadoop.fs.FSDataOutputStream;</span><br><span class="line">import org.apache.hadoop.fs.FileSystem;</span><br><span class="line">import org.apache.hadoop.fs.Path;</span><br><span class="line">import org.apache.hadoop.io.NullWritable;</span><br><span class="line">import org.apache.hadoop.io.Text;</span><br><span class="line">import org.apache.hadoop.mapreduce.RecordWriter;</span><br><span class="line">import org.apache.hadoop.mapreduce.TaskAttemptContext;</span><br><span class="line"></span><br><span class="line">public class FilterRecordWriter extends RecordWriter&lt;Text, NullWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line">FSDataOutputStream atguiguOut &#x3D; null;</span><br><span class="line">FSDataOutputStream otherOut &#x3D; null;</span><br><span class="line"></span><br><span class="line">public FilterRecordWriter(TaskAttemptContext job) &#123;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 1 获取文件系统</span><br><span class="line">FileSystem fs;</span><br><span class="line"></span><br><span class="line">try &#123;</span><br><span class="line">fs &#x3D; FileSystem.get(job.getConfiguration());</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 2 创建输出文件路径</span><br><span class="line">Path atguiguPath &#x3D; new Path(&quot;e:&#x2F;atguigu.log&quot;);</span><br><span class="line">Path otherPath &#x3D; new Path(&quot;e:&#x2F;other.log&quot;);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 3 创建输出流</span><br><span class="line">atguiguOut &#x3D; fs.create(atguiguPath);</span><br><span class="line">otherOut &#x3D; fs.create(otherPath);</span><br><span class="line">&#125; catch (IOException e) &#123;</span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@Override</span><br><span class="line">public void write(Text key, NullWritable value) throws IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 判断是否包含“atguigu”输出到不同文件</span><br><span class="line">if (key.toString().contains(&quot;atguigu&quot;)) &#123;</span><br><span class="line">atguiguOut.write(key.toString().getBytes());</span><br><span class="line">&#125; else &#123;</span><br><span class="line">otherOut.write(key.toString().getBytes());</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@Override</span><br><span class="line">public void close(TaskAttemptContext context) throws IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 关闭资源</span><br><span class="line">IOUtils.closeStream(atguiguOut);</span><br><span class="line">IOUtils.closeStream(otherOut);&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意：记得将自定义输出格式设置到job中</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 要将自定义的输出格式组件设置到job中</span></span><br><span class="line">job.setOutputFormatClass(FilterOutputFormat<span class="class">.<span class="keyword">class</span>)</span>;</span><br></pre></td></tr></table></figure><h2 id="7-Join多种应用"><a href="#7-Join多种应用" class="headerlink" title="7 Join多种应用"></a>7 Join多种应用</h2><h3 id="7-1-工作原理"><a href="#7-1-工作原理" class="headerlink" title="7.1 工作原理"></a>7.1 工作原理</h3><p>​ Map端的主要工作：为来自不同表或文件的key/value对，打标签以区别不同来源的记录。然后用连接字段作为key，其余部分和新加的标志作为value，最后进行输出。</p><p>​ Reduce端的主要工作：在Reduce端以连接字段作为key的分组已经完成，我们只需要在每一个分组当中将那些来源于不同文件的记录（在Map阶段已经打标志分开，最后进行合并就ok了。</p><h3 id="7-2-Reduce-join"><a href="#7-2-Reduce-join" class="headerlink" title="7.2 Reduce join"></a>7.2 Reduce join</h3><p>​ 在Mapper阶段使得连接属性为key，其余属性为value（自定义bean对象，记得序列化），再用一个标记属性标记来自于哪个文件</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mapreduce.table;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileSplit;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TableMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">TableBean</span>&gt;</span>&#123;</span><br><span class="line"></span><br><span class="line">String name;</span><br><span class="line">TableBean bean = <span class="keyword">new</span> TableBean();</span><br><span class="line">Text k = <span class="keyword">new</span> Text();</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">setup</span><span class="params">(Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1 获取输入文件切片</span></span><br><span class="line">FileSplit split = (FileSplit) context.getInputSplit();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2 获取输入文件名称</span></span><br><span class="line">name = split.getPath().getName();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1 获取输入数据</span></span><br><span class="line">String line = value.toString();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2 不同文件分别处理</span></span><br><span class="line"><span class="keyword">if</span> (name.startsWith(<span class="string">"order"</span>)) &#123;<span class="comment">// 订单表处理</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 2.1 切割</span></span><br><span class="line">String[] fields = line.split(<span class="string">"\t"</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2.2 封装bean对象</span></span><br><span class="line">bean.setOrder_id(fields[<span class="number">0</span>]);</span><br><span class="line">bean.setP_id(fields[<span class="number">1</span>]);</span><br><span class="line">bean.setAmount(Integer.parseInt(fields[<span class="number">2</span>]));</span><br><span class="line">bean.setPname(<span class="string">""</span>);</span><br><span class="line">bean.setFlag(<span class="string">"order"</span>);</span><br><span class="line"></span><br><span class="line">k.set(fields[<span class="number">1</span>]);</span><br><span class="line">&#125;<span class="keyword">else</span> &#123;<span class="comment">// 产品表处理</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 2.3 切割</span></span><br><span class="line">String[] fields = line.split(<span class="string">"\t"</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2.4 封装bean对象</span></span><br><span class="line">bean.setP_id(fields[<span class="number">0</span>]);</span><br><span class="line">bean.setPname(fields[<span class="number">1</span>]);</span><br><span class="line">bean.setFlag(<span class="string">"pd"</span>);</span><br><span class="line">bean.setAmount(<span class="number">0</span>);</span><br><span class="line">bean.setOrder_id(<span class="string">""</span>);</span><br><span class="line"></span><br><span class="line">k.set(fields[<span class="number">0</span>]);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 3 写出</span></span><br><span class="line">context.write(k, bean);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>​ 在Reduce阶段，输出连接成功的bean对象</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mapreduce.table;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.beanutils.BeanUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TableReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">TableBean</span>, <span class="title">TableBean</span>, <span class="title">NullWritable</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;TableBean&gt; values, Context context)</span><span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1准备存储订单的集合</span></span><br><span class="line">ArrayList&lt;TableBean&gt; orderBeans = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2 准备bean对象</span></span><br><span class="line">TableBean pdBean = <span class="keyword">new</span> TableBean();</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (TableBean bean : values) &#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (<span class="string">"order"</span>.equals(bean.getFlag())) &#123;<span class="comment">// 订单表</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 拷贝传递过来的每条订单数据到集合中</span></span><br><span class="line">TableBean orderBean = <span class="keyword">new</span> TableBean();</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">BeanUtils.copyProperties(orderBean, bean);</span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">orderBeans.add(orderBean);</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;<span class="comment">// 产品表</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line"><span class="comment">// 拷贝传递过来的产品表到内存中</span></span><br><span class="line">BeanUtils.copyProperties(pdBean, bean);</span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 3 表的拼接</span></span><br><span class="line"><span class="keyword">for</span>(TableBean bean:orderBeans)&#123;</span><br><span class="line"></span><br><span class="line">bean.setPname (pdBean.getPname());</span><br><span class="line"></span><br><span class="line"><span class="comment">// 4 数据写出去</span></span><br><span class="line">context.write(bean, NullWritable.get());</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>缺点：这种方式中，合并的操作是在Reduce阶段完成，Reduce端的处理压力太大，Map节点的运算负载则很低，资源利用率不高，且在Reduce阶段极易产生数据倾斜。</p><h3 id="map-join"><a href="#map-join" class="headerlink" title="map join"></a>map join</h3><p>使用场景：Map Join适用于一张表十分小、一张表很大的场景。</p><p>具体办法：采用DistributedCache</p><p>​ （1）在Mapper的setup阶段，将文件读取到缓存集合中。</p><p>​ （2）在驱动函数中加载缓存。</p><p>​ // 缓存普通文件到Task运行节点。</p><p>​ job.addCacheFile(new URI(“file://e:/cache/pd.txt”));</p><p>注：简单说就是把一个小表用map表示，用大表的连接属性直接映射出小表的属性</p><p><strong>对于驱动模块Driver来说</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 6 加载缓存数据</span><br><span class="line">job.addCacheFile(new URI(&quot;file:&#x2F;&#x2F;&#x2F;e:&#x2F;input&#x2F;inputcache&#x2F;pd.txt&quot;));</span><br><span class="line">&#x2F;&#x2F; 7 Map端Join的逻辑不需要Reduce阶段，设置reduceTask数量为0</span><br><span class="line">job.setNumReduceTasks(0);</span><br></pre></td></tr></table></figure><p>对于mapper来说，先在map前读取缓存数据</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> test;</span><br><span class="line"><span class="keyword">import</span> java.io.BufferedReader;</span><br><span class="line"><span class="keyword">import</span> java.io.FileInputStream;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.io.InputStreamReader;</span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.lang.StringUtils;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DistributedCacheMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">NullWritable</span>&gt;</span>&#123;</span><br><span class="line"></span><br><span class="line">Map&lt;String, String&gt; pdMap = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">setup</span><span class="params">(Mapper&lt;LongWritable, Text, Text, NullWritable&gt;.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1 获取缓存的文件</span></span><br><span class="line">URI[] cacheFiles = context.getCacheFiles();</span><br><span class="line">String path = cacheFiles[<span class="number">0</span>].getPath().toString();</span><br><span class="line"></span><br><span class="line">BufferedReader reader = <span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> InputStreamReader(<span class="keyword">new</span> FileInputStream(path), <span class="string">"UTF-8"</span>));</span><br><span class="line"></span><br><span class="line">String line;</span><br><span class="line"><span class="keyword">while</span>(StringUtils.isNotEmpty(line = reader.readLine()))&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2 切割</span></span><br><span class="line">String[] fields = line.split(<span class="string">"\t"</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 3 缓存数据到集合</span></span><br><span class="line">pdMap.put(fields[<span class="number">0</span>], fields[<span class="number">1</span>]);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 4 关流</span></span><br><span class="line">reader.close();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Text k = <span class="keyword">new</span> Text();</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1 获取一行</span></span><br><span class="line">String line = value.toString();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2 截取</span></span><br><span class="line">String[] fields = line.split(<span class="string">"\t"</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 3 获取产品id</span></span><br><span class="line">String pId = fields[<span class="number">1</span>];</span><br><span class="line"></span><br><span class="line"><span class="comment">// 4 获取商品名称</span></span><br><span class="line">String pdName = pdMap.get(pId);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 5 拼接</span></span><br><span class="line">k.set(line + <span class="string">"\t"</span>+ pdName);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 6 写出</span></span><br><span class="line">context.write(k, NullWritable.get());</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="8-计数器应用与数据清洗（ETL）"><a href="#8-计数器应用与数据清洗（ETL）" class="headerlink" title="8 计数器应用与数据清洗（ETL）"></a>8 计数器应用与数据清洗（ETL）</h2><p>​ Hadoop为每个作业维护若干内置计数器，以描述多项指标。例如，某些计数器记录已处理的字节数和记录数，使用户可监控已处理的输入数据量和已产生的输出数据量。</p><p>使用方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">context.getCounter(<span class="string">"map"</span>,<span class="string">"失败"</span>).increment(<span class="number">1</span>);</span><br></pre></td></tr></table></figure><h2 id="9-MapRedece开发总结"><a href="#9-MapRedece开发总结" class="headerlink" title="9 MapRedece开发总结"></a>9 MapRedece开发总结</h2><h4 id="1-输入数据接口：InputFormat"><a href="#1-输入数据接口：InputFormat" class="headerlink" title="1. 输入数据接口：InputFormat"></a>1. 输入数据接口：InputFormat</h4><p>（1）默认使用的实现类是：TextInputFormat</p><p>（2）TextInputFormat的功能逻辑是：一次读一行文本，然后将该行的起始偏移量作为key，行内容作为value返回。</p><p>（3）KeyValueTextlnputFomat每一行均为一条记录，被分隔符分割为key，value。默认分隔符是tab（\t）。<br>（4）NlinelnputFormat按照指定的行数N来划分切片。</p><p>（5）CombineTextlnputFormat可以把多个小文件合并成一个切片处理，提高处理效率。</p><p>（6）用户还可以自定义ImputFormat。</p><h4 id="2-逻辑处理接口：Mapper"><a href="#2-逻辑处理接口：Mapper" class="headerlink" title="2.逻辑处理接口：Mapper"></a>2.逻辑处理接口：Mapper</h4><p>用户根据业务需求实现其中三个方法：map）setup）cleanup）</p><h4 id="3-Partitioner分区"><a href="#3-Partitioner分区" class="headerlink" title="3.Partitioner分区"></a>3.Partitioner分区</h4><p>（1）有默认实现HashPartitioner，逻辑是根据key的哈希值和numReduces来返回一个分区号；key hashCode（）&amp;Integer.MAXVALUE%<br>numReduces</p><p>（2）如果业务上有特别的需求，可以自定义分区。</p><h4 id="4-Comparable排序"><a href="#4-Comparable排序" class="headerlink" title="4.Comparable排序"></a>4.Comparable排序</h4><p>（1）当我们用自定义的对象作为key来输出时，就必须要实现WritableComparable接口，重写其中的compareTo0方法。</p><p>（2）部分排序：对最终输出的每一个文件进行内部排序。</p><p>（3）全排序：对所有数据进行排序，通常只有一个Reduce。</p><p>（4）二次排序：排序的条件有两个。</p><h4 id="5-Combiner合并"><a href="#5-Combiner合并" class="headerlink" title="5.Combiner合并"></a>5.Combiner合并</h4><p>Combiner合并可以提高程序执行效率，减少I0传输。但是使用时必须不能影响原有的业务处理结果。</p><h4 id="6-Reduce端分组：GroupingComparator"><a href="#6-Reduce端分组：GroupingComparator" class="headerlink" title="6.Reduce端分组：GroupingComparator"></a>6.Reduce端分组：GroupingComparator</h4><p>在Reduce端对key进行分组。应用于：在接收的key为bean对象时，想让一个或几个字段相同（全部字段比较不相同）的key进入到同一个reduce方法时，可以采用分组排序。</p><h4 id="7-逻辑处理接口："><a href="#7-逻辑处理接口：" class="headerlink" title="7.逻辑处理接口："></a>7.逻辑处理接口：</h4><p>Reducer用户根据业务需求实现其中三个方法：reduce();setup();cleanup()</p><h4 id="8-输出数据接口：OutputFormat"><a href="#8-输出数据接口：OutputFormat" class="headerlink" title="8.输出数据接口：OutputFormat"></a>8.输出数据接口：OutputFormat</h4><p>（1）默认实现类是TextOutputFormat，功能逻辑是：将每一个KV对，向目标文本文件输出一行。</p><p>（2）将SequenceFileOutputFormat输出作为后续MapReduce任务的输入，这便是一种好的输出格式，因为它的格式紧凑，很容易被压缩。</p><p>（3）用户还可以自定义OutputFormat。</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sun Mar 08 2020 13:43:08 GMT+0800 (GMT+08:00) --&gt;&lt;ul&gt;&lt;li&gt;总结MapReduce框架原理&lt;/li&gt;&lt;/ul&gt;&lt;h2 id=&quot;1-InputFotmat数据输入&quot;&gt;&lt;a href=&quot;#1-Inp
      
    
    </summary>
    
    
      <category term="Hadoop" scheme="http://kiedeng.github.io/categories/Hadoop/"/>
    
    
      <category term="默认" scheme="http://kiedeng.github.io/tags/%E9%BB%98%E8%AE%A4/"/>
    
  </entry>
  
  <entry>
    <title>bean对象没有序列化</title>
    <link href="http://kiedeng.github.io/2020/02/29/bean%E5%AF%B9%E8%B1%A1%E6%B2%A1%E6%9C%89%E5%BA%8F%E5%88%97%E5%8C%96/"/>
    <id>http://kiedeng.github.io/2020/02/29/bean%E5%AF%B9%E8%B1%A1%E6%B2%A1%E6%9C%89%E5%BA%8F%E5%88%97%E5%8C%96/</id>
    <published>2020-02-29T08:39:08.000Z</published>
    <updated>2020-02-29T08:54:00.899Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun Mar 08 2020 13:43:08 GMT+0800 (GMT+08:00) --><p>在使用bean对象进行数据传输的过程中，一定要注意序列化，不然将出现map输出收集器的错误</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2020</span>-<span class="number">02</span>-<span class="number">29</span> <span class="number">16</span>:<span class="number">36</span>:<span class="number">31</span>,<span class="number">063</span> WARN [org.apache.hadoop.mapred.MapTask] - Unable to initialize MapOutputCollector org.apache.hadoop.mapred.MapTask$MapOutputBuffer</span><br><span class="line">java.lang.NullPointerException</span><br><span class="line">at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:<span class="number">1011</span>)</span><br><span class="line">at org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:<span class="number">402</span>)</span><br><span class="line">at org.apache.hadoop.mapred.MapTask.access$<span class="number">100</span>(MapTask.java:<span class="number">81</span>)</span><br><span class="line">at org.apache.hadoop.mapred.MapTask$NewOutputCollector.&lt;init&gt;(MapTask.java:<span class="number">698</span>)</span><br><span class="line">at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:<span class="number">770</span>)</span><br><span class="line">at org.apache.hadoop.mapred.MapTask.run(MapTask.java:<span class="number">341</span>)</span><br><span class="line">at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:<span class="number">243</span>)</span><br><span class="line">at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:<span class="number">511</span>)</span><br><span class="line">at java.util.concurrent.FutureTask.run(FutureTask.java:<span class="number">266</span>)</span><br><span class="line">at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:<span class="number">1142</span>)</span><br><span class="line">at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:<span class="number">617</span>)</span><br><span class="line">at java.lang.Thread.run(Thread.java:<span class="number">748</span>)</span><br></pre></td></tr></table></figure><p>出错位置：Reduce Join案例</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sun Mar 08 2020 13:43:08 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;在使用bean对象进行数据传输的过程中，一定要注意序列化，不然将出现map输出收集器的错误&lt;/p&gt;&lt;figure class=&quot;highligh
      
    
    </summary>
    
    
      <category term="常见错误" scheme="http://kiedeng.github.io/categories/%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF/"/>
    
    
      <category term="默认" scheme="http://kiedeng.github.io/tags/%E9%BB%98%E8%AE%A4/"/>
    
  </entry>
  
  <entry>
    <title>MapReduce流程图</title>
    <link href="http://kiedeng.github.io/2020/02/28/MapReduce%E6%B5%81%E7%A8%8B%E5%9B%BE/"/>
    <id>http://kiedeng.github.io/2020/02/28/MapReduce%E6%B5%81%E7%A8%8B%E5%9B%BE/</id>
    <published>2020-02-28T14:22:07.000Z</published>
    <updated>2020-02-28T16:11:22.122Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun Mar 08 2020 13:43:08 GMT+0800 (GMT+08:00) --><p><img src="https://kiedeng.site/usr/uploads/2020/02/4020856592.png" alt="核心思想"><br><img src="https://kiedeng.site/usr/uploads/2020/02/806542197.png" alt="Job提交流程"><br><img src="https://kiedeng.site/usr/uploads/2020/02/3955227225.jpg" alt="MapReduce详细流程"><br><img src="https://kiedeng.site/usr/uploads/2020/02/3289256044.jpg" alt="详细流程（2）"><br><img src="https://kiedeng.site/usr/uploads/2020/02/1050609538.jpg" alt="Shuffle机制"><br><img src="https://kiedeng.site/usr/uploads/2020/02/233752543.jpg" alt="MapTask工作机制"><br><img src="https://kiedeng.site/usr/uploads/2020/02/3775099059.jpg" alt="ReduceTask工作机制"><br><img src="https://kiedeng.site/usr/uploads/2020/02/3200426443.jpg" alt="YARN工作机制"></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sun Mar 08 2020 13:43:08 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;&lt;img src=&quot;https://kiedeng.site/usr/uploads/2020/02/4020856592.png&quot; alt=&quot;
      
    
    </summary>
    
    
      <category term="Hadoop" scheme="http://kiedeng.github.io/categories/Hadoop/"/>
    
    
      <category term="默认" scheme="http://kiedeng.github.io/tags/%E9%BB%98%E8%AE%A4/"/>
    
  </entry>
  
  <entry>
    <title>文档资料</title>
    <link href="http://kiedeng.github.io/2020/02/28/%E6%96%87%E6%A1%A3%E8%B5%84%E6%96%99/"/>
    <id>http://kiedeng.github.io/2020/02/28/%E6%96%87%E6%A1%A3%E8%B5%84%E6%96%99/</id>
    <published>2020-02-28T12:58:31.000Z</published>
    <updated>2020-02-28T14:57:22.875Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun Mar 08 2020 13:43:08 GMT+0800 (GMT+08:00) --><p>HDFS:</p><p><a href="https://books.kiedeng.site/hadoop/hdfs.pdf" target="_blank" rel="noopener">https://books.kiedeng.site/hadoop/hdfs.pdf</a></p><p>MapReduce:</p><p><a href="https://books.kiedeng.site/hadoop/mapreduce.pdf" target="_blank" rel="noopener">https://books.kiedeng.site/hadoop/mapreduce.pdf</a></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sun Mar 08 2020 13:43:08 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;HDFS:&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://books.kiedeng.site/hadoop/hdfs.pdf&quot; target=
      
    
    </summary>
    
    
      <category term="工具" scheme="http://kiedeng.github.io/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="默认" scheme="http://kiedeng.github.io/tags/%E9%BB%98%E8%AE%A4/"/>
    
  </entry>
  
  <entry>
    <title>在线预览文件pdfJS</title>
    <link href="http://kiedeng.github.io/2020/02/28/%E5%9C%A8%E7%BA%BF%E9%A2%84%E8%A7%88%E6%96%87%E4%BB%B6pdfJS/"/>
    <id>http://kiedeng.github.io/2020/02/28/%E5%9C%A8%E7%BA%BF%E9%A2%84%E8%A7%88%E6%96%87%E4%BB%B6pdfJS/</id>
    <published>2020-02-28T12:31:38.000Z</published>
    <updated>2020-02-28T12:53:52.987Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun Mar 08 2020 13:43:08 GMT+0800 (GMT+08:00) --><h3 id="1-下载pdf-js插件"><a href="#1-下载pdf-js插件" class="headerlink" title="1 下载pdf.js插件"></a>1 下载pdf.js插件</h3><p>地址: <a href="http://mozilla.github.io/pdf.js/" target="_blank" rel="noopener">http://mozilla.github.io/pdf.js/</a></p><p>下载的时候选择Stable（稳定版），下载完成以后进行解压，</p><h3 id="2-部署"><a href="#2-部署" class="headerlink" title="2 部署"></a>2 部署</h3><p>在tomcat的webapps文件夹下新建一个目录比如books，进解压的文件传入。</p><p>运行tomcat即可以进行访问</p><p><a href="http://localhost:8080/books/web/viewer.html" target="_blank" rel="noopener">http://localhost:8080/books/web/viewer.html</a></p><h3 id="3-添加文档"><a href="#3-添加文档" class="headerlink" title="3 添加文档"></a>3 添加文档</h3><p>访问自己需要访问的pdf文档，就可以先在books下新建一个目录，比如hadoop，将自己的1.pdf文档放入hadoop目录下，就可以通过<a href="http://localhost:8080/books/hadoop/1.pdf" target="_blank" rel="noopener">http://localhost:8080/books/hadoop/1.pdf</a>访问。</p><h3 id="4-云服务器"><a href="#4-云服务器" class="headerlink" title="4 云服务器"></a>4 云服务器</h3><p>将localhost换成服务器的ip或者域名即可</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sun Mar 08 2020 13:43:08 GMT+0800 (GMT+08:00) --&gt;&lt;h3 id=&quot;1-下载pdf-js插件&quot;&gt;&lt;a href=&quot;#1-下载pdf-js插件&quot; class=&quot;headerlink&quot; title=&quot;1 下
      
    
    </summary>
    
    
      <category term="Tomcat" scheme="http://kiedeng.github.io/categories/Tomcat/"/>
    
    
      <category term="默认" scheme="http://kiedeng.github.io/tags/%E9%BB%98%E8%AE%A4/"/>
    
  </entry>
  
  <entry>
    <title>GroupingComparator错误</title>
    <link href="http://kiedeng.github.io/2020/02/28/GroupingComparator%E9%94%99%E8%AF%AF/"/>
    <id>http://kiedeng.github.io/2020/02/28/GroupingComparator%E9%94%99%E8%AF%AF/</id>
    <published>2020-02-28T10:43:08.000Z</published>
    <updated>2020-02-28T11:00:25.025Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun Mar 08 2020 13:43:08 GMT+0800 (GMT+08:00) --><p>在进行重写的时候千万要小心，一不小心就会导致出错，注意参数！</p><p>错误处：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">public int compare(Object a, Object b) &#123;</span><br><span class="line">&#x2F;&#x2F; TODO Auto-generated method stub</span><br><span class="line">return super.compare(a, b);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>改正：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">public int compare(WritableComparable a, WritableComparable b) &#123;</span><br><span class="line">&#x2F;&#x2F; 要求只要id相同，就认为是相同的key</span><br><span class="line">OrderBean aBean &#x3D; (OrderBean) a;</span><br><span class="line">OrderBean bBean &#x3D; (OrderBean) b;</span><br><span class="line">int result;</span><br><span class="line">if (aBean.getOrder_id() &gt; bBean.getOrder_id()) &#123;</span><br><span class="line">result &#x3D; 1;</span><br><span class="line">&#125;else if(aBean.getOrder_id() &lt; bBean.getOrder_id())&#123;</span><br><span class="line">result &#x3D; -1;</span><br><span class="line">&#125;else &#123;</span><br><span class="line">result &#x3D; 0;</span><br><span class="line">&#125;</span><br><span class="line">return result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>出错案例：统计order的top1</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sun Mar 08 2020 13:43:08 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;在进行重写的时候千万要小心，一不小心就会导致出错，注意参数！&lt;/p&gt;&lt;p&gt;错误处：&lt;/p&gt;&lt;figure class=&quot;highlight pl
      
    
    </summary>
    
    
      <category term="Hadoop" scheme="http://kiedeng.github.io/categories/Hadoop/"/>
    
    
      <category term="默认" scheme="http://kiedeng.github.io/tags/%E9%BB%98%E8%AE%A4/"/>
    
  </entry>
  
  <entry>
    <title>typora与typecho的问题</title>
    <link href="http://kiedeng.github.io/2020/02/27/typora%E4%B8%8Etypecho%E7%9A%84%E9%97%AE%E9%A2%98/"/>
    <id>http://kiedeng.github.io/2020/02/27/typora%E4%B8%8Etypecho%E7%9A%84%E9%97%AE%E9%A2%98/</id>
    <published>2020-02-27T15:59:39.000Z</published>
    <updated>2020-02-27T16:38:41.704Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun Mar 08 2020 13:43:08 GMT+0800 (GMT+08:00) --><h3 id="标题问题"><a href="#标题问题" class="headerlink" title="标题问题"></a>标题问题</h3><p>​ 为了能使typecho的“文章目录”能够正确的显示，在typora设置的标题必须是连续的；</p><p>比如：#</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sun Mar 08 2020 13:43:08 GMT+0800 (GMT+08:00) --&gt;&lt;h3 id=&quot;标题问题&quot;&gt;&lt;a href=&quot;#标题问题&quot; class=&quot;headerlink&quot; title=&quot;标题问题&quot;&gt;&lt;/a&gt;标题问题&lt;/h3&gt;
      
    
    </summary>
    
    
      <category term="未分类" scheme="http://kiedeng.github.io/categories/%E6%9C%AA%E5%88%86%E7%B1%BB/"/>
    
    
      <category term="默认" scheme="http://kiedeng.github.io/tags/%E9%BB%98%E8%AE%A4/"/>
    
  </entry>
  
  <entry>
    <title>Combiner合并</title>
    <link href="http://kiedeng.github.io/2020/02/27/Combiner%E5%90%88%E5%B9%B6/"/>
    <id>http://kiedeng.github.io/2020/02/27/Combiner%E5%90%88%E5%B9%B6/</id>
    <published>2020-02-27T09:47:40.000Z</published>
    <updated>2020-02-27T09:47:40.129Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Thu Feb 27 2020 18:40:43 GMT+0800 (GMT+08:00) --><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Thu Feb 27 2020 18:40:43 GMT+0800 (GMT+08:00) --&gt;&lt;!-- rebuild by neat --&gt;
      
    
    </summary>
    
    
      <category term="未分类" scheme="http://kiedeng.github.io/categories/%E6%9C%AA%E5%88%86%E7%B1%BB/"/>
    
    
      <category term="默认" scheme="http://kiedeng.github.io/tags/%E9%BB%98%E8%AE%A4/"/>
    
  </entry>
  
  <entry>
    <title>map值类型不匹配</title>
    <link href="http://kiedeng.github.io/2020/02/27/map%E5%80%BC%E7%B1%BB%E5%9E%8B%E4%B8%8D%E5%8C%B9%E9%85%8D/"/>
    <id>http://kiedeng.github.io/2020/02/27/map%E5%80%BC%E7%B1%BB%E5%9E%8B%E4%B8%8D%E5%8C%B9%E9%85%8D/</id>
    <published>2020-02-27T07:48:50.000Z</published>
    <updated>2020-02-27T08:47:02.567Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Thu Feb 27 2020 18:40:43 GMT+0800 (GMT+08:00) --><p>map值类型不匹配</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">java.lang.Exception: java.io.IOException: Type mismatch in value from map: expected com.atguigu.mr.sort.FlowBean, received org.apache.hadoop.io.Text</span><br><span class="line">at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:<span class="number">462</span>)</span><br><span class="line">at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:<span class="number">522</span>)</span><br></pre></td></tr></table></figure><p>错误位置：进行排序案例的时候发生的错误</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">job.setMapOutputKeyClass(FlowBean<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">job.setMapOutputValueClass(FlowBean<span class="class">.<span class="keyword">class</span>)</span>;<span class="comment">//应该为Text.class</span></span><br></pre></td></tr></table></figure><blockquote><p>注：写Driver驱动的时候，要特别注意类型错误问题</p><p>因为不太懂这方面的错，所以</p></blockquote><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Thu Feb 27 2020 18:40:43 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;map值类型不匹配&lt;/p&gt;&lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter
      
    
    </summary>
    
    
      <category term="常见错误" scheme="http://kiedeng.github.io/categories/%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF/"/>
    
    
      <category term="默认" scheme="http://kiedeng.github.io/tags/%E9%BB%98%E8%AE%A4/"/>
    
  </entry>
  
  <entry>
    <title>WritableComparable排序</title>
    <link href="http://kiedeng.github.io/2020/02/27/WritableComparable%E6%8E%92%E5%BA%8F/"/>
    <id>http://kiedeng.github.io/2020/02/27/WritableComparable%E6%8E%92%E5%BA%8F/</id>
    <published>2020-02-27T04:37:15.000Z</published>
    <updated>2020-02-28T07:01:59.398Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun Mar 08 2020 13:43:08 GMT+0800 (GMT+08:00) --><h3 id="排序的分类"><a href="#排序的分类" class="headerlink" title="排序的分类"></a>排序的分类</h3><ol><li><p>部分排序</p><ul><li>MapReduce根据输入记录的键对数据集排序，保证输出的每个文件内部有序</li></ul></li><li><p>全排序</p><ul><li>最终输出结果为一个文件，且文件内部有序</li></ul></li><li><p>辅助排序：（GroupingComparator分组)</p><ul><li>在Reduece端对key进行分组。应用于key为bean对象时，想让一个或几个字段相同的key 进入到同一个reduce方法时，可以采用分组排序</li></ul></li><li><p>二次排序</p><ul><li>在自定义排序过程中，如果compareTo中的判断添加为两个即为二次排序</li></ul></li></ol><h3 id="自定义排序WritableComparable"><a href="#自定义排序WritableComparable" class="headerlink" title="自定义排序WritableComparable"></a>自定义排序WritableComparable</h3><p>1.原理分析</p><p>​ bean对象作为key传输，需要实现WritableComparable接口重写compareTo方法，就可以实现排序</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">public int compareTo(FlowBean o) &#123;</span><br><span class="line">int result;</span><br><span class="line">&#x2F;&#x2F; 按照总流量大小，倒序排列</span><br><span class="line">if (sumFlow &gt; bean.getSumFlow()) &#123;</span><br><span class="line">result &#x3D; -1;</span><br><span class="line">&#125;else if (sumFlow &lt; bean.getSumFlow()) &#123;</span><br><span class="line">result &#x3D; 1;</span><br><span class="line">&#125;else &#123;</span><br><span class="line">result &#x3D; 0;</span><br><span class="line">&#125; </span><br><span class="line">return result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="WritableComparable排序案例实操（全排序）"><a href="#WritableComparable排序案例实操（全排序）" class="headerlink" title="WritableComparable排序案例实操（全排序）"></a>WritableComparable排序案例实操（全排序）</h3><ol><li><p>需求：对总流量进行排序</p></li><li><p>代码实现</p><p>使用以前的Flowcount就可以实现，代码就可以实现，略</p></li></ol><h3 id="排序案例（区内排序）"><a href="#排序案例（区内排序）" class="headerlink" title="排序案例（区内排序）"></a>排序案例（区内排序）</h3><p>需求：要求每个省份手机号输出的文件中按照总流量内部排序</p><p>注意点：区间排序中，需要添加的是自定义的Patitioner分区类与在驱动类中添加分区类，设置Reducetask个数</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mapreduce.sort;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Partitioner;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProvincePartitioner</span> <span class="keyword">extends</span> <span class="title">Partitioner</span>&lt;<span class="title">FlowBean</span>, <span class="title">Text</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getPartition</span><span class="params">(FlowBean key, Text value, <span class="keyword">int</span> numPartitions)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1 获取手机号码前三位</span></span><br><span class="line">String preNum = value.toString().substring(<span class="number">0</span>, <span class="number">3</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> partition = <span class="number">4</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2 根据手机号归属地设置分区</span></span><br><span class="line"><span class="keyword">if</span> (<span class="string">"136"</span>.equals(preNum)) &#123;</span><br><span class="line">partition = <span class="number">0</span>;</span><br><span class="line">&#125;<span class="keyword">else</span> <span class="keyword">if</span> (<span class="string">"137"</span>.equals(preNum)) &#123;</span><br><span class="line">partition = <span class="number">1</span>;</span><br><span class="line">&#125;<span class="keyword">else</span> <span class="keyword">if</span> (<span class="string">"138"</span>.equals(preNum)) &#123;</span><br><span class="line">partition = <span class="number">2</span>;</span><br><span class="line">&#125;<span class="keyword">else</span> <span class="keyword">if</span> (<span class="string">"139"</span>.equals(preNum)) &#123;</span><br><span class="line">partition = <span class="number">3</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> partition;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 加载自定义分区类</span></span><br><span class="line">job.setPartitionerClass(ProvincePartitioner<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"><span class="comment">// 设置Reducetask个数</span></span><br><span class="line">job.setNumReduceTasks(<span class="number">5</span>);</span><br></pre></td></tr></table></figure><h3 id="GroupingComparator分组（辅助排序）"><a href="#GroupingComparator分组（辅助排序）" class="headerlink" title="GroupingComparator分组（辅助排序）"></a>GroupingComparator分组（辅助排序）</h3><p>对Reduce阶段的数据根据某一个或几个字段进行分组</p><ol><li><p>自定义继承WritableComparator</p></li><li><p>重写compare()方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compare</span><span class="params">(WritableComparable a, WritableComparable b)</span> </span>&#123;</span><br><span class="line"><span class="comment">// 比较的业务逻辑</span></span><br><span class="line"><span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>创建一个构造将比较对象的类传给父类</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="title">OrderGroupingComparator</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">super</span>(OrderBean<span class="class">.<span class="keyword">class</span>, <span class="title">true</span>)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h3 id="GroupingComparator分组案例实操"><a href="#GroupingComparator分组案例实操" class="headerlink" title="GroupingComparator分组案例实操"></a>GroupingComparator分组案例实操</h3><ol><li><p>需求：有如下订单数据；</p><ol><li>表4-2 订单数据</li></ol><table><thead><tr><th>订单id</th><th>商品id</th><th>成交金额</th></tr></thead><tbody><tr><td>0000001</td><td>Pdt_01</td><td>222.8</td></tr><tr><td></td><td>Pdt_02</td><td>33.8</td></tr><tr><td>0000002</td><td>Pdt_03</td><td>522.8</td></tr><tr><td></td><td>Pdt_04</td><td>122.4</td></tr><tr><td></td><td>Pdt_05</td><td>722.4</td></tr><tr><td>0000003</td><td>Pdt_06</td><td>232.8</td></tr><tr><td></td><td>Pdt_02</td><td>33.8</td></tr></tbody></table><ol start="2"><li><p>现在需要求出每一个订单中最贵的商品。</p><blockquote><p><em>期望输出数据*</em></p><p>1 222.8</p><p>2 722.4</p><p>3 232.8</p></blockquote></li></ol></li><li><p>需求分析</p><ol><li>利用“订单id和成交金额”作为key，可以将Map阶段读取到的所有订单数据按照id升序排序，如果id相同按照金额降序排序，发送到Reduce</li><li>在Reduce端利用groupComparator将订单id相同的kv合成为组，然后取第一个即是该订单中最贵商品</li></ol></li><li><p>代码实现</p><ol><li><p>定义订单信息OrderBean类</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mapreduce.order;</span><br><span class="line"><span class="keyword">import</span> java.io.DataInput;</span><br><span class="line"><span class="keyword">import</span> java.io.DataOutput;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.WritableComparable;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OrderBean</span> <span class="keyword">implements</span> <span class="title">WritableComparable</span>&lt;<span class="title">OrderBean</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">int</span> order_id; <span class="comment">// 订单id号</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">double</span> price; <span class="comment">// 价格</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">OrderBean</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">super</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">OrderBean</span><span class="params">(<span class="keyword">int</span> order_id, <span class="keyword">double</span> price)</span> </span>&#123;</span><br><span class="line"><span class="keyword">super</span>();</span><br><span class="line"><span class="keyword">this</span>.order_id = order_id;</span><br><span class="line"><span class="keyword">this</span>.price = price;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(DataOutput out)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">out.writeInt(order_id);</span><br><span class="line">out.writeDouble(price);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">readFields</span><span class="params">(DataInput in)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">order_id = in.readInt();</span><br><span class="line">price = in.readDouble();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> order_id + <span class="string">"\t"</span> + price;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getOrder_id</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> order_id;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setOrder_id</span><span class="params">(<span class="keyword">int</span> order_id)</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.order_id = order_id;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">getPrice</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> price;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setPrice</span><span class="params">(<span class="keyword">double</span> price)</span> </span>&#123;</span><br><span class="line"><span class="keyword">this</span>.price = price;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 二次排序</span></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compareTo</span><span class="params">(OrderBean o)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> result;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (order_id &gt; o.getOrder_id()) &#123;</span><br><span class="line">result = <span class="number">1</span>;</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (order_id &lt; o.getOrder_id()) &#123;</span><br><span class="line">result = -<span class="number">1</span>;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"><span class="comment">// 价格倒序排序</span></span><br><span class="line">result = price &gt; o.getPrice() ? -<span class="number">1</span> : <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>编写OrderSortMapper类</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mapreduce.order;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OrderMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">OrderBean</span>, <span class="title">NullWritable</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">OrderBean k = <span class="keyword">new</span> OrderBean();</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1 获取一行</span></span><br><span class="line">String line = value.toString();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2 截取</span></span><br><span class="line">String[] fields = line.split(<span class="string">"\t"</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 3 封装对象</span></span><br><span class="line">k.setOrder_id(Integer.parseInt(fields[<span class="number">0</span>]));</span><br><span class="line">k.setPrice(Double.parseDouble(fields[<span class="number">2</span>]));</span><br><span class="line"></span><br><span class="line"><span class="comment">// 4 写出</span></span><br><span class="line">context.write(k, NullWritable.get());</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>编写OrderSortGroupingComparator类</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mapreduce.order;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.WritableComparable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.WritableComparator;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OrderGroupingComparator</span> <span class="keyword">extends</span> <span class="title">WritableComparator</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="title">OrderGroupingComparator</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">super</span>(OrderBean<span class="class">.<span class="keyword">class</span>, <span class="title">true</span>)</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compare</span><span class="params">(WritableComparable a, WritableComparable b)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">OrderBean aBean = (OrderBean) a;</span><br><span class="line">OrderBean bBean = (OrderBean) b;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> result;</span><br><span class="line"><span class="keyword">if</span> (aBean.getOrder_id() &gt; bBean.getOrder_id()) &#123;</span><br><span class="line">result = <span class="number">1</span>;</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (aBean.getOrder_id() &lt; bBean.getOrder_id()) &#123;</span><br><span class="line">result = -<span class="number">1</span>;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">result = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>编写OrderSortReducer类</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mapreduce.order;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OrderReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">OrderBean</span>, <span class="title">NullWritable</span>, <span class="title">OrderBean</span>, <span class="title">NullWritable</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(OrderBean key, Iterable&lt;NullWritable&gt; values, Context context)</span><span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">context.write(key, NullWritable.get());</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>编写OrderSortDriver类</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mapreduce.order;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OrderDriver</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception, IOException </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输入输出路径需要根据自己电脑上实际的输入输出路径设置</span></span><br><span class="line">args  = <span class="keyword">new</span> String[]&#123;<span class="string">"e:/input/inputorder"</span> , <span class="string">"e:/output1"</span>&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1 获取配置信息</span></span><br><span class="line">Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">Job job = Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2 设置jar包加载路径</span></span><br><span class="line">job.setJarByClass(OrderDriver<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 3 加载map/reduce类</span></span><br><span class="line">job.setMapperClass(OrderMapper<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">job.setReducerClass(OrderReducer<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 4 设置map输出数据key和value类型</span></span><br><span class="line">job.setMapOutputKeyClass(OrderBean<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">job.setMapOutputValueClass(NullWritable<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 5 设置最终输出数据的key和value类型</span></span><br><span class="line">job.setOutputKeyClass(OrderBean<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">job.setOutputValueClass(NullWritable<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 6 设置输入数据和输出数据路径</span></span><br><span class="line">FileInputFormat.setInputPaths(job, <span class="keyword">new</span> Path(args[<span class="number">0</span>]));</span><br><span class="line">FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(args[<span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line"><span class="comment">// 8 设置reduce端的分组</span></span><br><span class="line">job.setGroupingComparatorClass(OrderGroupingComparator<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 7 提交</span></span><br><span class="line"><span class="keyword">boolean</span> result = job.waitForCompletion(<span class="keyword">true</span>);</span><br><span class="line">System.exit(result ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol></li></ol><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sun Mar 08 2020 13:43:08 GMT+0800 (GMT+08:00) --&gt;&lt;h3 id=&quot;排序的分类&quot;&gt;&lt;a href=&quot;#排序的分类&quot; class=&quot;headerlink&quot; title=&quot;排序的分类&quot;&gt;&lt;/a&gt;排序的分类&lt;
      
    
    </summary>
    
    
      <category term="Hadoop" scheme="http://kiedeng.github.io/categories/Hadoop/"/>
    
    
      <category term="默认" scheme="http://kiedeng.github.io/tags/%E9%BB%98%E8%AE%A4/"/>
    
  </entry>
  
  <entry>
    <title>Partition分区</title>
    <link href="http://kiedeng.github.io/2020/02/26/Partition%E5%88%86%E5%8C%BA/"/>
    <id>http://kiedeng.github.io/2020/02/26/Partition%E5%88%86%E5%8C%BA/</id>
    <published>2020-02-26T15:51:54.000Z</published>
    <updated>2020-02-26T16:46:55.670Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Thu Feb 27 2020 18:40:43 GMT+0800 (GMT+08:00) --><p><strong>问题引出</strong>：将结果按照条件输出到不同文件（分区）中</p><p>默认的分区是根据key的hashCode对ReduceTasks个数取模得到的。</p><h3 id="自定义Partitioner步骤"><a href="#自定义Partitioner步骤" class="headerlink" title="自定义Partitioner步骤"></a>自定义Partitioner步骤</h3><ol><li><p>自定义继承Partitioner,重写getPartition()方法</p></li><li><p>在job驱动中，设置自定义Partitioner</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">job.setPatitionerClass(CustonPartitioner.class)</span><br></pre></td></tr></table></figure></li><li><p>自定义Partition后，要根据自定义Partition的逻辑设置相对应的ReduceTask</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">job.setNumReduceTasd();</span><br></pre></td></tr></table></figure></li><li><p>分区总结</p><blockquote><p>（1）如果Reduce Task的数量&gt;getPartition的结果数，则会多产生几个空的输出文件part-r-000xx；</p><p>（2）如果1&lt;ReduceTask的数量&lt;getPartition的结果数，则有一部分分区数据无处安放，会Exception；<br>（3）如果ReduceTask的数量=1，则不管MapTask端输出多少个分区文件，最终结果都交给这一个Reduce Task，最终也就只会产生一个结果文件part-r-00000；<br>（4）分区号必须从零开始，逐一累加。</p></blockquote></li></ol><h3 id="Partition案例实操"><a href="#Partition案例实操" class="headerlink" title="Partition案例实操"></a>Partition案例实操</h3><p>题目：将统计结果按照手机归属地不同省份输出到不同文件中（分区）</p><ul><li><p>添加分区类</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.atguigu.mapreduce.flowsum;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Partitioner;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProvincePartitioner</span> <span class="keyword">extends</span> <span class="title">Partitioner</span>&lt;<span class="title">Text</span>, <span class="title">FlowBean</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getPartition</span><span class="params">(Text key, FlowBean value, <span class="keyword">int</span> numPartitions)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1 获取电话号码的前三位</span></span><br><span class="line">String preNum = key.toString().substring(<span class="number">0</span>, <span class="number">3</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> partition = <span class="number">4</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2 判断是哪个省</span></span><br><span class="line"><span class="keyword">if</span> (<span class="string">"136"</span>.equals(preNum)) &#123;</span><br><span class="line">partition = <span class="number">0</span>;</span><br><span class="line">&#125;<span class="keyword">else</span> <span class="keyword">if</span> (<span class="string">"137"</span>.equals(preNum)) &#123;</span><br><span class="line">partition = <span class="number">1</span>;</span><br><span class="line">&#125;<span class="keyword">else</span> <span class="keyword">if</span> (<span class="string">"138"</span>.equals(preNum)) &#123;</span><br><span class="line">partition = <span class="number">2</span>;</span><br><span class="line">&#125;<span class="keyword">else</span> <span class="keyword">if</span> (<span class="string">"139"</span>.equals(preNum)) &#123;</span><br><span class="line">partition = <span class="number">3</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> partition;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>在驱动函数中增加自定义数据分区设置和ReduceTask设置</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 8 指定自定义数据分区</span></span><br><span class="line">job.setPartitionerClass(ProvincePartitioner<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"><span class="comment">// 9 同时指定相应数量的reduce task</span></span><br><span class="line">job.setNumReduceTasks(<span class="number">5</span>);</span><br></pre></td></tr></table></figure></li></ul><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Thu Feb 27 2020 18:40:43 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;&lt;strong&gt;问题引出&lt;/strong&gt;：将结果按照条件输出到不同文件（分区）中&lt;/p&gt;&lt;p&gt;默认的分区是根据key的hashCode对Red
      
    
    </summary>
    
    
      <category term="Hadoop" scheme="http://kiedeng.github.io/categories/Hadoop/"/>
    
    
      <category term="默认" scheme="http://kiedeng.github.io/tags/%E9%BB%98%E8%AE%A4/"/>
    
  </entry>
  
  <entry>
    <title>Text导包错误</title>
    <link href="http://kiedeng.github.io/2020/02/26/Text%E5%AF%BC%E5%8C%85%E9%94%99%E8%AF%AF/"/>
    <id>http://kiedeng.github.io/2020/02/26/Text%E5%AF%BC%E5%8C%85%E9%94%99%E8%AF%AF/</id>
    <published>2020-02-26T05:52:34.000Z</published>
    <updated>2020-02-26T05:58:21.071Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Thu Feb 27 2020 18:40:43 GMT+0800 (GMT+08:00) --><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">java.lang.ClassCastException: class com.sun.jersey.core.impl.provider.entity.XMLJAXBElementProvider$Text</span><br><span class="line">at java.lang.Class.asSubclass(Class.java:3404)</span><br><span class="line">at org.apache.hadoop.mapred.JobConf.getOutputKeyComparator(JobConf.java:887)</span><br><span class="line">at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.init(MapTask.java:1004)</span><br><span class="line">at org.apache.hadoop.mapred.MapTask.createSortingCollector(MapTask.java:402)</span><br><span class="line">at org.apache.hadoop.mapred.MapTask.access$100(MapTask.java:81)</span><br><span class="line">at org.apache.hadoop.mapred.MapTask$NewOutputCollector.<span class="tag">&lt;<span class="name">init</span>&gt;</span>(MapTask.java:698)</span><br><span class="line">at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:770)</span><br><span class="line">at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)</span><br><span class="line">at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)</span><br><span class="line">at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)</span><br><span class="line">at java.util.concurrent.FutureTask.run(FutureTask.java:266)</span><br><span class="line">at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)</span><br><span class="line">at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)</span><br><span class="line">at java.lang.Thread.run(Thread.java:748)</span><br></pre></td></tr></table></figure><p>错误的导入了Text包，</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">错误：</span><br><span class="line"><span class="keyword">import</span> com.sun.jersey.core.impl.provider.entity.XMLJAXBElementProvider.Text;</span><br><span class="line">正确的包：</span><br><span class="line">    <span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br></pre></td></tr></table></figure><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Thu Feb 27 2020 18:40:43 GMT+0800 (GMT+08:00) --&gt;&lt;figure class=&quot;highlight xml&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span clas
      
    
    </summary>
    
    
      <category term="常见错误" scheme="http://kiedeng.github.io/categories/%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF/"/>
    
    
      <category term="默认" scheme="http://kiedeng.github.io/tags/%E9%BB%98%E8%AE%A4/"/>
    
  </entry>
  
  <entry>
    <title>LeetCode计划表</title>
    <link href="http://kiedeng.github.io/2020/02/21/LeetCode%E8%AE%A1%E5%88%92%E8%A1%A8/"/>
    <id>http://kiedeng.github.io/2020/02/21/LeetCode%E8%AE%A1%E5%88%92%E8%A1%A8/</id>
    <published>2020-02-21T05:26:42.000Z</published>
    <updated>2020-02-21T05:33:01.684Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Thu Feb 27 2020 18:40:43 GMT+0800 (GMT+08:00) --><table><thead><tr><th>题目序号</th><th>题目名称</th><th>总结</th></tr></thead><tbody><tr><td>1</td><td>Two Sum</td><td></td></tr><tr><td>4</td><td>Median of Two Sorted Arrays</td><td></td></tr><tr><td>11</td><td>Container With Most Water</td><td></td></tr><tr><td>17</td><td>Letter Combinations of a Phone Number</td><td></td></tr><tr><td>21</td><td>Merge Two Sorted Lists</td><td></td></tr><tr><td>23</td><td>Merge k Sorted Lists</td><td></td></tr><tr><td>37</td><td>Sudoku Solver</td><td></td></tr><tr><td>39</td><td>Combination Sum</td><td></td></tr><tr><td>40</td><td>Combination Sum II</td><td></td></tr><tr><td>51</td><td>N-Queens</td><td></td></tr><tr><td>53</td><td>Maximum Subarray</td><td></td></tr><tr><td>56</td><td>Merge Intervals</td><td></td></tr><tr><td>57</td><td>Insert Interval</td><td></td></tr><tr><td>62</td><td>Unique Paths</td><td></td></tr><tr><td>63</td><td>Unique Paths II</td><td></td></tr><tr><td>64</td><td>Minimum Path Sum</td><td></td></tr><tr><td>69</td><td>sqrt(x)</td><td></td></tr><tr><td>70</td><td>Climbing Stairs</td><td></td></tr><tr><td>72</td><td>Edit Distance</td><td></td></tr><tr><td>78</td><td>Subsets</td><td></td></tr><tr><td>79</td><td>Word Search</td><td></td></tr><tr><td>91</td><td>Decode Ways</td><td></td></tr><tr><td>98</td><td>Validate Binary Search Tree</td><td></td></tr><tr><td>100</td><td>Same Tree</td><td></td></tr><tr><td>102</td><td>Binary Tree Level Order Traversal</td><td></td></tr><tr><td>110</td><td>Balanced Binary Tree</td><td></td></tr><tr><td>112</td><td>Path Sum</td><td></td></tr><tr><td>113</td><td>Path Sum II</td><td></td></tr><tr><td>115</td><td>Distinct Subsequences</td><td></td></tr><tr><td>120</td><td>Triangle</td><td></td></tr><tr><td>121</td><td>Best Time to Buy and Sell Stock</td><td></td></tr><tr><td>124</td><td>Binary Tree Maximum Path Sum</td><td></td></tr><tr><td>126</td><td>Word Ladder II</td><td></td></tr><tr><td>127</td><td>Word Ladder</td><td></td></tr><tr><td>128</td><td>Longest Consecutive Sequence</td><td></td></tr><tr><td>139</td><td>Word Break (revisit)</td><td></td></tr><tr><td>140</td><td>Word Break II</td><td></td></tr><tr><td>141</td><td>Linked List Cycle</td><td></td></tr><tr><td>145</td><td>Binary Tree Postorder Traversal</td><td></td></tr><tr><td>146</td><td>LRU Cache</td><td></td></tr><tr><td>148</td><td>Sort List</td><td></td></tr><tr><td>149</td><td>Max Points on a Line</td><td></td></tr><tr><td>153</td><td>Find Minimum in Rotated Sorted Array</td><td></td></tr><tr><td>154</td><td>Find Minimum in Rotated Sorted Array II</td><td></td></tr><tr><td>169</td><td>Majority Element</td><td></td></tr><tr><td>174</td><td>Dungeon Game</td><td></td></tr><tr><td>198</td><td>House Robber</td><td></td></tr><tr><td>200</td><td>Number of Islands</td><td></td></tr><tr><td>204</td><td>Count Primes</td><td></td></tr><tr><td>207</td><td>Course Schedule</td><td></td></tr><tr><td>208</td><td>Implement Trie (Prefix Tree)</td><td></td></tr><tr><td>210</td><td>Course Schedule II</td><td></td></tr><tr><td>216</td><td>Combination Sum III</td><td></td></tr><tr><td>218</td><td>The Skyline Problem</td><td></td></tr><tr><td>221</td><td>Maximal Square</td><td></td></tr><tr><td>239</td><td>Sliding Window Maximum</td><td></td></tr><tr><td>241</td><td>Different Ways to Add Parentheses</td><td></td></tr><tr><td>263</td><td>Ugly Number</td><td></td></tr><tr><td>264</td><td>Ugly Number II</td><td></td></tr><tr><td>268</td><td>Missing Number</td><td></td></tr><tr><td>282</td><td>Expression Add Operators</td><td></td></tr><tr><td>289</td><td>Game of Life</td><td></td></tr><tr><td>295</td><td>Find Median from Data Stream</td><td></td></tr><tr><td>297</td><td>Serialize and Deserialize Binary Tree</td><td></td></tr><tr><td>300</td><td>Longest Increasing Subsequence</td><td></td></tr><tr><td>301</td><td>Remove Invalid Parentheses</td><td></td></tr><tr><td>303</td><td>Range Sum Query - Immutable</td><td></td></tr><tr><td>304</td><td>Range Sum Query 2D - Immutable</td><td></td></tr><tr><td>309</td><td>Best Time to Buy and Sell Stock with Cooldown</td><td></td></tr><tr><td>312</td><td>Burst Balloons</td><td></td></tr><tr><td>315</td><td>Count of Smaller Numbers After Self</td><td></td></tr><tr><td>321</td><td>Create Maximum Number</td><td></td></tr><tr><td>322</td><td>Coin Change</td><td></td></tr><tr><td>329</td><td>Longest Increasing Path in a Matrix</td><td></td></tr><tr><td>332</td><td>Reconstruct Itinerary</td><td></td></tr><tr><td>347</td><td>Top K Frequent Elements</td><td></td></tr><tr><td>377</td><td>Combination Sum IV</td><td></td></tr><tr><td>380</td><td>Insert Delete GetRandom O(1)</td><td></td></tr><tr><td>381</td><td>Insert Delete GetRandom O(1) - Duplicates allowed</td><td></td></tr><tr><td>391</td><td>Perfect Rectangle</td><td></td></tr><tr><td>399</td><td>Evaluate Division</td><td></td></tr><tr><td>404</td><td>Sum of Left Leaves</td><td></td></tr><tr><td>409</td><td>Longest Palindrome</td><td></td></tr><tr><td>410</td><td>Split Array Largest Sum</td><td></td></tr><tr><td>416</td><td>Partition Equal Subset Sum</td><td></td></tr><tr><td>417</td><td>Pacific Atlantic Water Flow</td><td></td></tr><tr><td>432</td><td>All O`one Data Structure</td><td></td></tr><tr><td>438</td><td>Find All Anagrams in a String</td><td></td></tr><tr><td>449</td><td>Serialize and Deserialize BST</td><td></td></tr><tr><td>450</td><td>Delete Node in a BST</td><td></td></tr><tr><td>451</td><td>Sort Characters By Frequency</td><td></td></tr><tr><td>452</td><td>Minimum Number of Arrows to Burst Balloons</td><td></td></tr><tr><td>455</td><td>Assign Cookies</td><td></td></tr><tr><td>460</td><td>LFU Cache</td><td></td></tr><tr><td>461</td><td>Hamming Distance</td><td></td></tr><tr><td>463</td><td>Island Perimeter</td><td></td></tr><tr><td>464</td><td>Can I Win</td><td></td></tr><tr><td>470</td><td>Implement Rand10() Using Rand7()</td><td></td></tr><tr><td>476</td><td>Number Complement</td><td></td></tr><tr><td>477</td><td>Total Hamming Distance</td><td></td></tr><tr><td>480</td><td>Sliding Window Median</td><td></td></tr><tr><td>486</td><td>Predict the Winner</td><td></td></tr><tr><td>488</td><td>Zuma Game</td><td></td></tr><tr><td>494</td><td>Target Sum2</td><td></td></tr><tr><td>494</td><td>Target Sum</td><td></td></tr><tr><td>504</td><td>Base 7</td><td></td></tr><tr><td>516</td><td>Longest Palindromic Subsequence</td><td></td></tr><tr><td>525</td><td>Contiguous Array</td><td></td></tr><tr><td>530</td><td>Minimum Absolute Difference in BST</td><td></td></tr><tr><td>540</td><td>Single Element in a Sorted Array</td><td></td></tr><tr><td>543</td><td>Diameter of Binary Tree</td><td></td></tr><tr><td>546</td><td>Remove Boxes</td><td></td></tr><tr><td>547</td><td>Friend Circles</td><td></td></tr><tr><td>551</td><td>Student Attendance Record I</td><td></td></tr><tr><td>560</td><td>Subarray Sum Equals K</td><td></td></tr><tr><td>561</td><td>Array Partition I</td><td></td></tr><tr><td>566</td><td>Reshape the Matrix</td><td></td></tr><tr><td>567</td><td>Permutation in String</td><td></td></tr><tr><td>576</td><td>Out of Boundary Paths</td><td></td></tr><tr><td>606</td><td>Construct String from Binary Tree</td><td></td></tr><tr><td>611</td><td>Valid Triangle Number</td><td></td></tr><tr><td>617</td><td>Merge Two Binary Trees</td><td></td></tr><tr><td>621</td><td>Task Scheduler</td><td></td></tr><tr><td>628</td><td>Maximum Product of Three Numbers</td><td></td></tr><tr><td>633</td><td>Sum of Square Numbers</td><td></td></tr><tr><td>636</td><td>Exclusive Time of Functions</td><td></td></tr><tr><td>637</td><td>Average of Levels in Binary Tree</td><td></td></tr><tr><td>639</td><td>Decode Ways II</td><td></td></tr><tr><td>652</td><td>Find Duplicate Subtrees</td><td></td></tr><tr><td>654</td><td>Maximum Binary Tree</td><td></td></tr><tr><td>655</td><td>Print Binary Tree</td><td></td></tr><tr><td>657</td><td>Judge Route Circle</td><td></td></tr><tr><td>664</td><td>Strange Printer</td><td></td></tr><tr><td>668</td><td>Kth Smallest Number in Multiplication Table</td><td></td></tr><tr><td>669</td><td>Trim a Binary Search Tree</td><td></td></tr><tr><td>671</td><td>Second Minimum Node In a Binary Tree</td><td></td></tr><tr><td>673</td><td>Number of Longest Increasing Subsequence</td><td></td></tr><tr><td>674</td><td>Longest Continuous Increasing Subsequence</td><td></td></tr><tr><td>675</td><td>Cut Off Trees for Golf Event</td><td></td></tr><tr><td>676</td><td>Implement Magic Dictionary</td><td></td></tr><tr><td>677</td><td>Map Sum Pairs</td><td></td></tr><tr><td>678</td><td>Valid Parenthesis String</td><td></td></tr><tr><td>680</td><td>Valid Palindrome II</td><td></td></tr><tr><td>681</td><td>Next Closest Time</td><td></td></tr><tr><td>682</td><td>Baseball Game</td><td></td></tr><tr><td>683</td><td>K Empty Slots</td><td></td></tr><tr><td>684</td><td>Redundant Connection</td><td></td></tr><tr><td>685</td><td>Redundant Connection II</td><td></td></tr><tr><td>687</td><td>Longest Univalue Path</td><td></td></tr><tr><td>688</td><td>Knight Probability in Chessboard</td><td></td></tr><tr><td>690</td><td>Employee Importance</td><td></td></tr><tr><td>692</td><td>Top K Frequent Words</td><td></td></tr><tr><td>699</td><td>Falling Squares</td><td></td></tr><tr><td>707</td><td>Design Linked List</td><td></td></tr><tr><td>712</td><td>Minimum ASCII Delete Sum for Two Strings</td><td></td></tr><tr><td>715</td><td>Range Module</td><td></td></tr><tr><td>719</td><td>Find K-th Smallest Pair Distance</td><td></td></tr><tr><td>720</td><td>Longest Word in Dictionary</td><td></td></tr><tr><td>724</td><td>Find Pivot Index</td><td></td></tr><tr><td>725</td><td>Split Linked List in Parts</td><td></td></tr><tr><td>726</td><td>Number of Atoms</td><td></td></tr><tr><td>728</td><td>Self Dividing Numbers</td><td></td></tr><tr><td>729</td><td>My Calendar I</td><td></td></tr><tr><td>730</td><td>Count Different Palindromic Subsequences</td><td></td></tr><tr><td>731</td><td>My Calendar II</td><td></td></tr><tr><td>732</td><td>My Calendar III</td><td></td></tr><tr><td>733</td><td>Flood Fill</td><td></td></tr><tr><td>734</td><td>Sentence Similarity</td><td></td></tr><tr><td>735</td><td>Asteroid Collision</td><td></td></tr><tr><td>736</td><td>Parse Lisp Expression</td><td></td></tr><tr><td>737</td><td>Sentence Similarity II</td><td></td></tr><tr><td>740</td><td>Delete and Earn</td><td></td></tr><tr><td>741</td><td>Cherry Pickup</td><td></td></tr><tr><td>742</td><td>Closest Leaf in a Binary Tree</td><td></td></tr><tr><td>743</td><td>Network Delay Time</td><td></td></tr><tr><td>744</td><td>Find Smallest Letter Greater Than Target</td><td></td></tr><tr><td>745</td><td>Prefix and Suffix Search</td><td></td></tr><tr><td>746</td><td>Min Cost Climbing Stairs</td><td></td></tr><tr><td>748</td><td>Shortest Completing Word</td><td></td></tr><tr><td>749</td><td>Contain Virus</td><td></td></tr><tr><td>752</td><td>Open the Lock</td><td></td></tr><tr><td>753</td><td>Cracking the Safe</td><td></td></tr><tr><td>754</td><td>Reach a Number</td><td></td></tr><tr><td>755</td><td>Pour Water</td><td></td></tr><tr><td>758</td><td>Bold Words in String</td><td></td></tr><tr><td>759</td><td>Employee Free Time</td><td></td></tr><tr><td>762</td><td>Prime Number of Set Bits in Binary Representation</td><td></td></tr><tr><td>763</td><td>Partition Labels</td><td></td></tr><tr><td>769</td><td>Max Chunks To Make Sorted</td><td></td></tr><tr><td>773</td><td>Sliding Puzzle</td><td></td></tr><tr><td>775</td><td>Global and Local Inversions</td><td></td></tr><tr><td>778</td><td>Swim in Rising Water</td><td></td></tr><tr><td>784</td><td>Letter Case Permutation</td><td></td></tr><tr><td>786</td><td>K-th Smallest Prime Fraction</td><td></td></tr><tr><td>787</td><td>Cheapest Flights Within K Stops</td><td></td></tr><tr><td>790</td><td>Domino and Tromino Tiling</td><td></td></tr><tr><td>792</td><td>Number of Matching Subsequences</td><td></td></tr><tr><td>799</td><td>Champagne Tower</td><td></td></tr><tr><td>801</td><td>Minimum Swaps To Make Sequences Increasing</td><td></td></tr><tr><td>802</td><td>Find Eventual Safe States</td><td></td></tr><tr><td>803</td><td>Bricks Falling When Hit</td><td></td></tr><tr><td>813</td><td>Largest Sum of Averages</td><td></td></tr><tr><td>815</td><td>Bus Routes</td><td></td></tr><tr><td>817</td><td>Linked List Components</td><td></td></tr><tr><td>818</td><td>Race Car2</td><td></td></tr><tr><td>818</td><td>Race Car</td><td></td></tr><tr><td>823</td><td>Binary Trees With Factors</td><td></td></tr><tr><td>826</td><td>Most Profit Assigning Work</td><td></td></tr><tr><td>827</td><td>Making A Large Island</td><td></td></tr><tr><td>841</td><td>Keys and Rooms</td><td></td></tr><tr><td>847</td><td>Shortest Path Visiting All Nodes</td><td></td></tr><tr><td>848</td><td>Shifting Letters</td><td></td></tr><tr><td>856</td><td>Score of Parentheses</td><td></td></tr><tr><td>863</td><td>All Nodes Distance K in Binary Tree</td><td></td></tr><tr><td>864</td><td>Shortest Path to Get All Keys</td><td></td></tr><tr><td>865</td><td>Smallest Subtree with all the Deepest Nodes</td><td></td></tr><tr><td>871</td><td>Minimum Number of Refueling Stops</td><td></td></tr><tr><td>873</td><td>Length of Longest Fibonacci Subsequence</td><td></td></tr><tr><td>877</td><td>Stone Game</td><td></td></tr><tr><td>879</td><td>Profitable Schemes</td><td></td></tr><tr><td>882</td><td>Reachable Nodes In Subdivided Graph</td><td></td></tr><tr><td>886</td><td>Possible Bipartition</td><td></td></tr><tr><td>889</td><td>Construct Binary Tree from Preorder and Postorder Traversal</td><td></td></tr><tr><td>891</td><td>Sum of Subsequence Widths</td><td></td></tr><tr><td>894</td><td>All Possible Full Binary Trees</td><td></td></tr><tr><td>895</td><td>Maximum Frequency Stack</td><td></td></tr><tr><td>898</td><td>Bitwise ORs of Subarrays</td><td></td></tr><tr><td>901</td><td>Online Stock Span</td><td></td></tr><tr><td>902</td><td>Numbers At Most N Given Digit Set</td><td></td></tr><tr><td>923</td><td>3Sum With Multiplicity</td><td></td></tr><tr><td>926</td><td>Flip String to Monotone Increasing</td><td></td></tr><tr><td>934</td><td>Shortest Bridge</td><td></td></tr><tr><td>935</td><td>Knight Dialer</td><td></td></tr><tr><td>936</td><td>Stamping The Sequence</td><td></td></tr><tr><td>943</td><td>Find the Shortest Superstring</td><td></td></tr><tr><td>952</td><td>Largest Component Size by Common Factor</td><td></td></tr><tr><td>956</td><td>Tallest Billboard</td><td></td></tr><tr><td>959</td><td>Regions Cut By Slashes</td><td></td></tr><tr><td>964</td><td>Least Operators to Express Number</td><td></td></tr><tr><td>967</td><td>Numbers With Same Consecutive Differences</td><td></td></tr><tr><td>972</td><td>Equal Rational Numbers</td><td></td></tr><tr><td>973</td><td>K Closest Points to Origin</td><td></td></tr><tr><td>975</td><td>Odd Even Jump</td><td></td></tr><tr><td>979</td><td>Distribute Coins in Binary Tree</td><td></td></tr><tr><td>980</td><td>Unique Paths III</td><td></td></tr><tr><td>1000</td><td>Minimum Cost to Merge Stones</td><td></td></tr><tr><td>1017</td><td>Convert to Base -2</td><td></td></tr><tr><td>1019</td><td>Next Greater Node In Linked List</td><td></td></tr><tr><td>1024</td><td>Video Stitching</td><td></td></tr><tr><td>1043</td><td>Partition Array for Maximum Sum</td><td></td></tr><tr><td>1092</td><td>Shortest Common Supersequenc</td><td></td></tr><tr><td>1105</td><td>Filling Bookcase Shelves</td><td></td></tr><tr><td>1106</td><td>Parsing A Boolean Expression</td><td></td></tr><tr><td>1124</td><td>Longest Well-Performing Interval</td><td></td></tr><tr><td>1125</td><td>Smallest Sufficient Team</td><td></td></tr><tr><td>1129</td><td>Shortest Path with Alternating Colors</td><td></td></tr></tbody></table><p>的</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Thu Feb 27 2020 18:40:43 GMT+0800 (GMT+08:00) --&gt;&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;题目序号&lt;/th&gt;&lt;th&gt;题目名称&lt;/th&gt;&lt;th&gt;总结&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;
      
    
    </summary>
    
    
      <category term="算法" scheme="http://kiedeng.github.io/categories/%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="LeetCode" scheme="http://kiedeng.github.io/tags/LeetCode/"/>
    
  </entry>
  
  <entry>
    <title>MapReduce工作流程</title>
    <link href="http://kiedeng.github.io/2020/02/20/MapReduce%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B/"/>
    <id>http://kiedeng.github.io/2020/02/20/MapReduce%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B/</id>
    <published>2020-02-20T13:39:47.000Z</published>
    <updated>2020-02-20T13:39:47.432Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Feb 21 2020 01:03:29 GMT+0800 (GMT+08:00) --><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Feb 21 2020 01:03:29 GMT+0800 (GMT+08:00) --&gt;&lt;!-- rebuild by neat --&gt;
      
    
    </summary>
    
    
      <category term="未分类" scheme="http://kiedeng.github.io/categories/%E6%9C%AA%E5%88%86%E7%B1%BB/"/>
    
    
      <category term="默认" scheme="http://kiedeng.github.io/tags/%E9%BB%98%E8%AE%A4/"/>
    
  </entry>
  
  <entry>
    <title>Shuffle机制</title>
    <link href="http://kiedeng.github.io/2020/02/20/Shuffle%E6%9C%BA%E5%88%B6/"/>
    <id>http://kiedeng.github.io/2020/02/20/Shuffle%E6%9C%BA%E5%88%B6/</id>
    <published>2020-02-20T13:38:49.000Z</published>
    <updated>2020-02-20T13:38:49.220Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Fri Feb 21 2020 01:03:29 GMT+0800 (GMT+08:00) --><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Fri Feb 21 2020 01:03:29 GMT+0800 (GMT+08:00) --&gt;&lt;!-- rebuild by neat --&gt;
      
    
    </summary>
    
    
      <category term="未分类" scheme="http://kiedeng.github.io/categories/%E6%9C%AA%E5%88%86%E7%B1%BB/"/>
    
    
      <category term="默认" scheme="http://kiedeng.github.io/tags/%E9%BB%98%E8%AE%A4/"/>
    
  </entry>
  
  <entry>
    <title>InputFormat数据输入</title>
    <link href="http://kiedeng.github.io/2020/02/20/InputFormat%E6%95%B0%E6%8D%AE%E8%BE%93%E5%85%A5/"/>
    <id>http://kiedeng.github.io/2020/02/20/InputFormat%E6%95%B0%E6%8D%AE%E8%BE%93%E5%85%A5/</id>
    <published>2020-02-20T13:38:16.000Z</published>
    <updated>2020-02-28T02:10:46.494Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sun Mar 08 2020 13:43:08 GMT+0800 (GMT+08:00) --><h2 id="切片与MapTask并行度决定机制"><a href="#切片与MapTask并行度决定机制" class="headerlink" title="切片与MapTask并行度决定机制"></a>切片与MapTask并行度决定机制</h2><p><strong>数据块</strong>：Block是HDFS物理上把数据分成一块一块。</p><p><strong>数据切片</strong>：数据切片只是逻辑上对输入进行分片，并不会再磁盘上将其切分成片进行存储。</p><h2 id="Job提交流程源码和切片源码详解"><a href="#Job提交流程源码和切片源码详解" class="headerlink" title="Job提交流程源码和切片源码详解"></a>Job提交流程源码和切片源码详解</h2><ol><li><p>Job提交流程源码详解</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">waitForCompletion()</span><br><span class="line"></span><br><span class="line">submit();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1建立连接</span></span><br><span class="line">connect();</span><br><span class="line"><span class="comment">// 1）创建提交Job的代理</span></span><br><span class="line"><span class="keyword">new</span> Cluster(getConfiguration());</span><br><span class="line"><span class="comment">// （1）判断是本地yarn还是远程</span></span><br><span class="line">initialize(jobTrackAddr, conf); </span><br><span class="line"></span><br><span class="line"><span class="comment">// 2 提交job</span></span><br><span class="line">submitter.submitJobInternal(Job.<span class="keyword">this</span>, cluster)</span><br><span class="line"><span class="comment">// 1）创建给集群提交数据的Stag路径</span></span><br><span class="line">Path jobStagingArea = JobSubmissionFiles.getStagingDir(cluster, conf);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2）获取jobid ，并创建Job路径</span></span><br><span class="line">JobID jobId = submitClient.getNewJobID();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 3）拷贝jar包到集群</span></span><br><span class="line">copyAndConfigureFiles(job, submitJobDir);</span><br><span class="line">rUploader.uploadFiles(job, jobSubmitDir);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 4）计算切片，生成切片规划文件</span></span><br><span class="line">writeSplits(job, submitJobDir);</span><br><span class="line">maps = writeNewSplits(job, jobSubmitDir);</span><br><span class="line">input.getSplits(job);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 5）向Stag路径写XML配置文件</span></span><br><span class="line">writeConf(conf, submitJobFile);</span><br><span class="line">conf.writeXml(out);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 6）提交Job,返回提交状态</span></span><br><span class="line">status = submitClient.submitJob(jobId, submitJobDir.toString(), job.getCredentials());</span><br></pre></td></tr></table></figure></li></ol><p><img src="https://kiedeng.site/usr/uploads/2020/02/2136348625.png" alt="Snipaste_2020-02-20_22-05-42.png"></p><h2 id="FileInputFormat切片机制"><a href="#FileInputFormat切片机制" class="headerlink" title="FileInputFormat切片机制"></a>FileInputFormat切片机制</h2><h3 id="1-切片机制"><a href="#1-切片机制" class="headerlink" title="1 切片机制"></a>1 切片机制</h3><ul><li>简单的按照文件的内容长度进行切片</li><li>切片大小，默认等于Block大小</li><li>切片时不考虑数据集整体，而是逐个针对每一个文件单独切片</li></ul><p><strong>注</strong>：每次切片，都要判断切完剩下的部分是否大于块的1.1倍，不大于1.1倍就划分一块切片</p><h3 id="2-源码中计算机切片大小的公式"><a href="#2-源码中计算机切片大小的公式" class="headerlink" title="2 源码中计算机切片大小的公式"></a>2 源码中计算机切片大小的公式</h3><ul><li>Math. max(minSize, Math.min(maxSize, blockSize));</li><li>maprecduce.input.fileinputformat.split.minsize=1默认值为1</li><li>mapreduce.input.fileinputformat.split maxsize=LongMAXValue 默认值Long.MAXValue,因此，默认情况下，切片大小=blocksize</li></ul><h3 id="3-获取切片信息API"><a href="#3-获取切片信息API" class="headerlink" title="3 获取切片信息API"></a>3 获取切片信息API</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//获取切片的文件名称</span></span><br><span class="line">String name=inputSplit.getPath（）.getName（）：</span><br><span class="line"><span class="comment">//根据文件类型获取切片信息</span></span><br><span class="line">FileSplit inputSplit =（FileSplit）context.get InputSplit（）；</span><br></pre></td></tr></table></figure><h2 id="CombineTextInputFormat切片机制"><a href="#CombineTextInputFormat切片机制" class="headerlink" title="CombineTextInputFormat切片机制"></a>CombineTextInputFormat切片机制</h2><p>​ 默认的TextInputFormat切片机制是对任务按文件规划切片，会产生大量小文件，产生大量的MapTask，处理效率极其低下，故CombineTextInputFormat来处理大量小文件的情况。</p><h3 id="1-虚拟存储切片最大值设置"><a href="#1-虚拟存储切片最大值设置" class="headerlink" title="1 虚拟存储切片最大值设置"></a>1 虚拟存储切片最大值设置</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CombineTextInputFormat. setMaxInputSplitSize(job,<span class="number">4194304</span>):<span class="comment">//4m-</span></span><br></pre></td></tr></table></figure><h3 id="2-切片机制"><a href="#2-切片机制" class="headerlink" title="2 切片机制"></a>2 切片机制</h3><p>生成切片过程包括：虚拟存储过程和切片过程二部分</p><ul><li><p>虚拟存储过程</p><blockquote><p>将目录下的所有文件与setMaxInputSize比较，小于则切分为一块，大于且小于两倍，则平分这一块，大于两倍，则切出一块setMaxInputSize的块</p></blockquote></li><li><p>切片过程</p><blockquote><p>判断虚拟存储文件大小是否大于setMaxInputSplitSize值，大于或等于则单独形成一个切片，否则和下一个切片进行合并，形成一个切片</p></blockquote></li></ul><h2 id="CombineTextInputFormat案例实操"><a href="#CombineTextInputFormat案例实操" class="headerlink" title="CombineTextInputFormat案例实操"></a>CombineTextInputFormat案例实操</h2><p>需求：将输入的大量小文件合并成一个切片统一处理（以WordCount为基础），准备四个文件。</p><p>只需要在Driver中添加输入格式即可：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 如果不设置InputFormat，它默认用的是TextInputFormat.class</span></span><br><span class="line">job.setInputFormatClass(CombineTextInputFormat<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//虚拟存储切片最大值设置4m</span></span><br><span class="line">CombineTextInputFormat.setMaxInputSplitSize(job, <span class="number">4194304</span>);</span><br></pre></td></tr></table></figure><h2 id="FileInputFormat实现类"><a href="#FileInputFormat实现类" class="headerlink" title="FileInputFormat实现类"></a>FileInputFormat实现类</h2><p>​ <strong>FileInputFormat</strong> 常见的接口实现类包括：<strong>TextinputFormat、KeyValue TextInputFormat、NLinelnputFormat、CombineTextinputFormat，自定义InputFormat</strong>等。</p><h3 id="1-TextInputFormat"><a href="#1-TextInputFormat" class="headerlink" title="1 TextInputFormat"></a>1 TextInputFormat</h3><p>FileInputFile默认的实现类，按行读，键为字节偏移量，LongWritable类型</p><h3 id="2-KeyValueTextInputFormat"><a href="#2-KeyValueTextInputFormat" class="headerlink" title="2 KeyValueTextInputFormat"></a>2 KeyValueTextInputFormat</h3><p>通过分隔符，分为key，value，课通过设置</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 设置切割符</span></span><br><span class="line">conf.set(KeyValueLineRecordReader.KEY_VALUE_SEPERATOR, <span class="string">" "</span>);</span><br><span class="line"><span class="comment">// 设置输入格式</span></span><br><span class="line">job.setInputFormatClass(KeyValueTextInputFormat<span class="class">.<span class="keyword">class</span>)</span>;</span><br></pre></td></tr></table></figure><h3 id="3-NlineInputFormat"><a href="#3-NlineInputFormat" class="headerlink" title="3 NlineInputFormat"></a>3 NlineInputFormat</h3><p>按照行数N来划分，即切片数=输入文件总行数/N</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 7设置每个切片InputSplit中划分三条记录</span><br><span class="line">NLineInputFormat.setNumLinesPerSplit(job, 3);   </span><br><span class="line">&#x2F;&#x2F; 8使用NLineInputFormat处理记录数  </span><br><span class="line">job.setInputFormatClass(NLineInputFormat.class);</span><br></pre></td></tr></table></figure><h3 id="4-自定义InputFormat"><a href="#4-自定义InputFormat" class="headerlink" title="4 自定义InputFormat"></a>4 自定义InputFormat</h3><blockquote><p>需要自定义一个类继承FileInputFormat</p><p>改写RecordReader，实现封装为KV</p><p>输出是使用SequenceFileOutFormat输出合并文件</p></blockquote><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sun Mar 08 2020 13:43:08 GMT+0800 (GMT+08:00) --&gt;&lt;h2 id=&quot;切片与MapTask并行度决定机制&quot;&gt;&lt;a href=&quot;#切片与MapTask并行度决定机制&quot; class=&quot;headerlink&quot; 
      
    
    </summary>
    
    
      <category term="Hadoop" scheme="http://kiedeng.github.io/categories/Hadoop/"/>
    
    
      <category term="MapReduce" scheme="http://kiedeng.github.io/tags/MapReduce/"/>
    
  </entry>
  
</feed>
