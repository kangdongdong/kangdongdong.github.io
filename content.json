{"meta":{"title":"Hexo","subtitle":"","description":"","author":"John Doe","url":"http://kiedeng.github.io","root":"/"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2020-02-09T14:37:29.946Z","updated":"2020-02-09T14:37:29.946Z","comments":false,"path":"/404.html","permalink":"http://kiedeng.github.io/404.html","excerpt":"","text":""},{"title":"书单","date":"2020-02-09T06:13:49.098Z","updated":"2020-02-09T03:33:37.347Z","comments":false,"path":"books/index.html","permalink":"http://kiedeng.github.io/books/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2020-02-09T03:33:37.348Z","updated":"2020-02-09T03:33:37.348Z","comments":true,"path":"links/index.html","permalink":"http://kiedeng.github.io/links/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2020-02-09T15:26:19.807Z","updated":"2020-02-09T15:26:19.807Z","comments":false,"path":"repository/index.html","permalink":"http://kiedeng.github.io/repository/index.html","excerpt":"","text":""},{"title":"分类","date":"2020-02-09T15:25:56.144Z","updated":"2020-02-09T03:33:37.347Z","comments":false,"path":"categories/index.html","permalink":"http://kiedeng.github.io/categories/index.html","excerpt":"","text":""},{"title":"简历","date":"2020-02-09T16:43:45.968Z","updated":"2020-02-09T16:43:45.968Z","comments":false,"path":"about/index.html","permalink":"http://kiedeng.github.io/about/index.html","excerpt":"","text":"应届生求职模板基本信息： x某某 / gender / age&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;现&ensp;在&ensp;地： 山东青岛手&ensp;机&ensp;号： 178 xxxx xxxx&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;邮&emsp;&emsp;箱： congsw@foxmail.com证&emsp;&emsp;书： 英语四/六级、计算机二级&emsp;&emsp;&emsp;&emsp;&ensp;实习经验： x年GitHub： https://github.com/congshengwuCSDN： &ensp;https://blog.csdn.net/c1024197824求职意向期望职位： 安卓开发工程师&emsp;&emsp;&emsp;&emsp;期望薪资： 0k-1000k教育背景xxxx大学&emsp;&emsp;&emsp;&emsp;&emsp;2015.09-2019.06&emsp;&emsp;&emsp;&emsp;&emsp;电子信息工程实习经历公司： xxxxxx信息科技有限公司&emsp;&emsp;职位： 安卓开发工程师&emsp;&emsp;时间： 2018.03-2019.03项目名称： xxxxxxxxxx项目简介： xxxxxxxxxx主要工作：xxxxxxxxxxxx。xxxxxxxxxxxx。xxxxxxxxxxxx。技术栈：基于谷歌AAC框架实现MVVM应用架构网络请求：Retrofit+OkHttp+RxJavaJson解析：谷歌GsonXML/Html解析：Jsoup图片加载：GlideUI及数据加载相关：DataBinding、Paging、自定义View个人作品名称： xxxx&emsp;&emsp;简介： xxxxxxxxxxxxxxxxxxxx。名称： yyyy简介： yyyyyyyyyyyyyyyyyyyy。名称： zzzz简介： zzzzzzzzzzzzzzzzzzzz。技能清单以下均为我熟练使用的技能：编程语言：Java、C安卓开发：熟悉安卓UI设计、布局、自定义控件开发，安卓数据存储SharedPreferences、文件等，微博、微信等第三方SDK集成，处理ANR、OOM等安卓框架：Gson、FastJson、谷歌AAC、EventBus、Glide、Retrofit、RxJava、OkHttp、Jsoup等其他：正则表达式、Git、SVN等以下是我接触并了解的技能：&emsp;&emsp;&emsp;Kotlin（学习中）、Linux简单命令、Java Servlet、Mysql、Html、爬虫等等自我评价&emsp;&emsp;我是一个热爱技术热爱编程的人，大学四年自学编程，做过很多小项目（贪吃蛇、计算器、简单的数据库读取录入系统等等），上架了3款个人开发的安卓小应用，各应用市场累计60多万的下载量，开源了几个小项目并得到了一些star，参与过两个商业安卓应用的开发，其中在开发“猫博”App过程中积累了我安卓开发的大部分经验和学习方法，真是受益匪浅。&emsp;&emsp;我希望在以后的工作中，深度上能学习掌握更多关于安卓开发的高级知识及数据结构算法；广度上能扩宽自己的技术栈，如前端、后端、混合开发以及其他比较新潮有趣的技术等；高度上希望经过未来几年的职业生涯发展，能成为软件架构师级的技术专家。"},{"title":"标签","date":"2020-02-09T03:33:37.349Z","updated":"2020-02-09T03:33:37.349Z","comments":false,"path":"tags/index.html","permalink":"http://kiedeng.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"HDFS客户端操作","slug":"HDFS客户端操作","date":"2020-02-13T03:16:18.000Z","updated":"2020-02-13T05:12:33.597Z","comments":true,"path":"2020/02/13/HDFS客户端操作/","link":"","permalink":"http://kiedeng.github.io/2020/02/13/HDFS%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%93%8D%E4%BD%9C/","excerpt":"","text":"客户端环境准备将编译hadoop jar包放在路径下（比如：D:\\environment\\hadoop-2.7.2）配置HADOOP_HOME环境变量HADOOP_HOME : D:\\environment\\hadoop-2.7.2配置Path环境变量%HADOOP_HOME%\\bin创建一个Maven工程导入相应的依赖坐标+日志添加​junit​junit​RELEASE​org.apache.logging.log4j​log4j-core​2.8.2​org.apache.hadoop​hadoop-common​2.7.2​org.apache.hadoop​hadoop-client​2.7.2​org.apache.hadoop​hadoop-hdfs​2.7.2​jdk.tools​jdk.tools​1.8​system​${JAVA_HOME}/lib/tools.jar需要再项目的src/main/resources目录下，新建一个文件，命令为”log4j.properties”,在文件中填写log4j.rootLogger=INFO, stdoutlog4j.appender.stdout=org.apache.log4j.ConsoleAppenderlog4j.appender.stdout.layout=org.apache.log4j.PatternLayoutlog4j.appender.stdout.layout.ConversionPattern=%d %p [%c] - %m%nlog4j.appender.logfile=org.apache.log4j.FileAppenderlog4j.appender.logfile.File=target/spring.loglog4j.appender.logfile.layout=org.apache.log4j.PatternLayoutlog4j.appender.logfile.layout.ConversionPattern=%d %p [%c] - %m%n创建包名：com.atguigu.hdfs创建HdfsClient类12345678910111213141516171819public class HdfsClient&#123; @Testpublic void testMkdirs() throws IOException, InterruptedException, URISyntaxException&#123; // 1 获取文件系统 Configuration configuration = new Configuration(); // 配置在集群上运行 // configuration.set(\"fs.defaultFS\", \"hdfs://hadoop102:9000\"); // FileSystem fs = FileSystem.get(configuration); FileSystem fs = FileSystem.get(new URI(\"hdfs://hadoop102:9000\"), configuration, \"atguigu\"); // 2 创建目录 fs.mkdirs(new Path(\"/1108/daxian/banzhang\")); // 3 关闭资源 fs.close(); &#125;&#125;执行程序客户端去操作HDFS时，是有一个用户身份的。默认情况下，HDFS客户端API会从JVM中获取一个参数来作为自己的用户身份：-DHADOOP_USER_NAME=atguigu，atguigu为用户名称。1234567891011public static void main(String[] args) throws Exception &#123; // 配置文件 Configuration conf = new Configuration(); conf.set(\"fs.defaultFS\", \"hdfs://hadoop102:9000\"); // 获取客户端对象 FileSystem fs = FileSystem.get(conf); fs.mkdirs(new Path(\"/kangdong\")); // 关闭客户端 fs.close(); System.out.println(\"Over!\"); &#125;HDFS的API操作HDFS文件上传（测试参数优先级）编写源代码1234567891011public static void main(String[] args) throws Exception &#123; // 配置文件 Configuration conf = new Configuration(); conf.set(\"fs.defaultFS\", \"hdfs://hadoop102:9000\"); // 获取客户端对象 FileSystem fs = FileSystem.get(conf); fs.mkdirs(new Path(\"/kangdong\")); // 关闭客户端 fs.close(); System.out.println(\"Over!\"); &#125;将hdfs-site.xml拷贝到项目的根目录（即资源目录下）123456789&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?&gt;&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt;参数优先级参数优先级排序：（1）客户端代码中设置的值 &gt;（2）ClassPath下的用户自定义配置文件 &gt;（3）然后是服务器的默认配置HDFS文件的下载12345// boolean delSrc 指是否将原文件删除// Path src 指要下载的文件路径// Path dst 指将文件下载到的路径// boolean useRawLocalFileSystem 是否开启文件校验fs.copyToLocalFile(false, new Path(\"/banzhang.txt\"), new Path(\"e:/banhua.txt\"), true);HDFS文件的删除1fs.delete(new Path(\"/0508/\"), true);//第一参数是路径，第二个参数是判断是否递归删除HDFS文件的改名1fs.rename(new Path(\"/banzhang.txt\"), new Path(\"/banhua.txt\"));HDFS文件详情的查看123456789101112131415161718192021222324252627282930313233343536373839404142@Testpublic void testListFiles() throws IOException, InterruptedException, URISyntaxException&#123; // 1获取文件系统 Configuration configuration = new Configuration(); FileSystem fs = FileSystem.get(new URI(\"hdfs://hadoop102:9000\"), configuration, \"atguigu\"); // 2 获取文件详情 RemoteIterator&lt;LocatedFileStatus&gt; listFiles = fs.listFiles(new Path(\"/\"), true); while(listFiles.hasNext())&#123; LocatedFileStatus status = listFiles.next(); // 输出详情 // 文件名称 System.out.println(status.getPath().getName()); // 长度 System.out.println(status.getLen()); // 权限 System.out.println(status.getPermission()); // 分组 System.out.println(status.getGroup()); // 获取存储的块信息 BlockLocation[] blockLocations = status.getBlockLocations(); for (BlockLocation blockLocation : blockLocations) &#123; // 获取块存储的主机节点 String[] hosts = blockLocation.getHosts(); for (String host : hosts) &#123; System.out.println(host); &#125; &#125; System.out.println(\"-----------班长的分割线----------\"); &#125;// 3 关闭资源fs.close();&#125;","categories":[{"name":"Hadoop","slug":"Hadoop","permalink":"http://kiedeng.github.io/categories/Hadoop/"}],"tags":[{"name":"Eclipse","slug":"Eclipse","permalink":"http://kiedeng.github.io/tags/Eclipse/"}]},{"title":"Hadoop编译源码","slug":"Hadoop编译源码","date":"2020-02-12T03:29:53.000Z","updated":"2020-02-13T02:02:58.820Z","comments":true,"path":"2020/02/12/Hadoop编译源码/","link":"","permalink":"http://kiedeng.github.io/2020/02/12/Hadoop%E7%BC%96%E8%AF%91%E6%BA%90%E7%A0%81/","excerpt":"","text":"jar包准备hadoop-2.7.2-src.tar.gzjdk-8u144-linux-x64.tar.gzapache-ant-1.9.9-bin.tar.gz（build工具，打包用的）apache-maven-3.0.5-bin.tar.gzprotobuf-2.5.0.tar.gz（序列化的框架）jar包安装JDK解压，配置环境变量JAVA_HOME和PATH#JAVA_HOME：export JAVA_HOME=/opt/module/jdk1.8.0_144export PATH=$PATH:$JAVA_HOME/binsource /etc/profile进行生效Maven解压，配置MAVEN_HOME和PATH[root@hadoop101 software]# tar -zxvf apache-maven-3.0.5-bin.tar.gz -C /opt/module/[root@hadoop101 apache-maven-3.0.5]# vi conf/settings.xml​​nexus-aliyun​central​Nexus aliyun​http://maven.aliyun.com/nexus/content/groups/public​[root@hadoop101 apache-maven-3.0.5]# vi /etc/profile#MAVEN_HOMEexport MAVEN_HOME=/opt/module/apache-maven-3.0.5export PATH=$PATH:$MAVEN_HOME/bin[root@hadoop101 software]#source /etc/profile验证命令：mvn-versionant解压、配置 ANT _HOME和PATH[root@hadoop101 software]# tar -zxvf apache-ant-1.9.9-bin.tar.gz -C /opt/module/[root@hadoop101 apache-ant-1.9.9]# vi /etc/profile#ANT_HOMEexport ANT_HOME=/opt/module/apache-ant-1.9.9export PATH=$PATH:$ANT_HOME/bi[root@hadoop101 software]#source /etc/profile安装 glibc-headers 和 g++ 命令如下[root@hadoop101 apache-ant-1.9.9]# yum install glibc-headers[root@hadoop101 apache-ant-1.9.9]# yum install gcc-c++安装make和cmake[root@hadoop101 apache-ant-1.9.9]# yum install make[root@hadoop101 apache-ant-1.9.9]# yum install cmake解压protobuf ，进入到解压后protobuf主目录，/opt/module/protobuf-2.5.0，然后相继执行命令[root@hadoop101 software]# tar -zxvf protobuf-2.5.0.tar.gz -C /opt/module/[root@hadoop101 opt]# cd /opt/module/protobuf-2.5.0/[root@hadoop101 protobuf-2.5.0]#./configure[root@hadoop101 protobuf-2.5.0]# make[root@hadoop101 protobuf-2.5.0]# make check[root@hadoop101 protobuf-2.5.0]# make install[root@hadoop101 protobuf-2.5.0]# ldconfig[root@hadoop101 hadoop-dist]# vi /etc/profile#LD_LIBRARY_PATHexport LD_LIBRARY_PATH=/opt/module/protobuf-2.5.0export PATH=$PATH:$LD_LIBRARY_PATH[root@hadoop101 software]#source /etc/profile安装openssl库[root@hadoop101 software]#yum install openssl-devel安装 ncurses-devel库[root@hadoop101 software]#yum install ncurses-devel编译源码解压源码到/opt/目录tar -zxvf hadoop-2.7.2-src.tar.gz -C /opt/进入源码主目录通过maven执行编译命令mvn package -Pdist,native -DskipTests -Dtar成功的64位hadoop包在/opt/hadoop-2.7.2-src/hadoop-dist/target下","categories":[{"name":"Hadoop","slug":"Hadoop","permalink":"http://kiedeng.github.io/categories/Hadoop/"}],"tags":[{"name":"默认","slug":"默认","permalink":"http://kiedeng.github.io/tags/%E9%BB%98%E8%AE%A4/"}]},{"title":"软件推荐","slug":"软件推荐","date":"2020-02-11T10:48:17.000Z","updated":"2020-02-11T11:25:52.268Z","comments":true,"path":"2020/02/11/软件推荐/","link":"","permalink":"http://kiedeng.github.io/2020/02/11/%E8%BD%AF%E4%BB%B6%E6%8E%A8%E8%8D%90/","excerpt":"","text":"TinyTask自动化操作工具Ditto复制神器SecureCRT一般大数据使用的远程工具PanDownload网盘下载天若OCR文字识别用于文字识别Snipaste截图贴图工具Typoramarkdown编辑器Notepad++编辑器，可以进行文件夹文字查找Sublime编辑器，可以远程服务器Bandizip解压工具VMware虚拟机Xshell/Xftp远程连接工具Adobe Acrobat DCpdf阅读，编辑Anki记忆工具Everything查看文件PotPlayer播放器Chrome浏览器","categories":[{"name":"工具","slug":"工具","permalink":"http://kiedeng.github.io/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"自动化","slug":"自动化","permalink":"http://kiedeng.github.io/tags/%E8%87%AA%E5%8A%A8%E5%8C%96/"}]},{"title":"Linux使用手册","slug":"Linux使用手册","date":"2020-02-10T08:57:11.000Z","updated":"2020-02-11T04:56:13.605Z","comments":true,"path":"2020/02/10/Linux使用手册/","link":"","permalink":"http://kiedeng.github.io/2020/02/10/Linux%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C/","excerpt":"","text":"用户管理命令#添加useradd kiedeng 或者 useradd -g [组名] 用户名#设置密码useradd 用户名#查看用户是否存在id 用户名#查看创建的用户cat /etc/passwd#切换用户su 用户名（没有获得环境变量）su - 用户名 （获得环境变量）#删除用户userdel 用户名userdel -r 用户名 （用户和用户目录全部删除）#设置root权限vim /etc/sudoers在root下中添加一行用户名 ALL=(ALL) ALL用户名 ALL=(ALL) NOPASSWDALL （不需要密码）修改usermod 修改用户usemod -g 用户组 用户名用户组管理添加：groupadd 组名删除：groupdel 组名修改组：groupmod -n 新组名 老组名查看组：cat /etc/group文件权限类总共10位：0~90位：-表示文件，d代表文件，l代表链接文档1-3位确定属主的该文件权限4-6位确定属组的该文件的权限7-9位确定其他用户改文件的权限修改文件权限chmod 777 a.txtchmod -R 777 xiyou （递归删除）改变所有者chown [选项] [最终用户] [文件或者目录] 选项为-R （递归操作）改变所属组chgrp [最终用户组] [文件或者目录]搜索查找类find 查找文件或者目录基本语法：find [搜索范围] [选项]选项-name&lt;查询方式&gt; 按照指定文件名查找-user&lt;用户名&gt; 指定用户查找-size&lt;文件大小&gt; 按照文件大小查找 （+为大于，-为小于）比如：find /home -size +20458locate快速定位文件路径更新：updatedb基本语法：locate 搜索文件grep 过滤查找及“|”管道符基本语法：grep 选项 查找内容 源文件压缩和解压缩gzip/gunzip压缩只能压缩文件，不能压缩目录命令：gzip 文件；gunzip 文件. gzzip/unzip压缩基本语法：zip [选项] xxx.zip 将要压缩的内容 （目录或文件）unzip [选项] xxx.zip 解压文件选项：-d&lt;目录&gt; 指定压缩后文件存放的目录tar 打包tar [选项] xxx.tar.gz 将要打包进去的内容选项-c 产生tar打包文件-v 显示详细信息-f 指定压缩后的文件名-z 打包同时压缩-x 解包.tar文件压缩：tar -zcvf kie.tar.gz a.txt b.txt解压：tar -zxvf kie.tar.gz -C /opt磁盘分区类","categories":[{"name":"使用手册","slug":"使用手册","permalink":"http://kiedeng.github.io/categories/%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://kiedeng.github.io/tags/Linux/"}]},{"title":"hadoop集群搭建","slug":"hadoop集群搭建","date":"2020-02-10T06:11:15.000Z","updated":"2020-02-11T17:12:40.789Z","comments":true,"path":"2020/02/10/hadoop集群搭建/","link":"","permalink":"http://kiedeng.github.io/2020/02/10/hadoop%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/","excerpt":"","text":"克隆虚拟机配置好的Linux虚拟机-&gt; 管理 -&gt; 克隆删除网卡，复制物理地址：vim /etc/udev/rules.d/70-persistent-net.rules删除eht0的那一行将下一行的eth0改为eth1复制address物理地址配置网络：vim /etc/sysconfig/network-scripts/ifcfg-eth0HWADDR:粘贴物理地址IPADDR=192.168.1.101 设置ipONBOOT=yesNM_CONTROLLED=yesB00TPROTO=staticGATEWAY=192.168.1.2DNS1=192.168.1.2 和网关一致修改主机名称：vim /etc/sysconfig/networkNETWORKING=yesHOSTNAME=hadoopl 01修改主机映射：vim /etc/hosts安装JDK通过sftp将jdk放在/opt/software下tar -zxvf [gz文件名] -C [解压的路径]设置环境路径#JAVA_HOMEexport JAVA_HOME=/opt/module/jdk1.8.0_144export PATH=$PATH:$JAVA_HOME/bin让修改以后的文件生效source /etc/profile测试是否成功指令java -version安装Hadoop将hadoop-2.7.2.tar.gz传入，解压在/etc/profile添加环境变量##HADOOP_HOMEexport HADOOP_HOME=/opt/module/hadoop-2.7.2export PATH=$PATH:$HADOOP_HOME/binexport PATH=$PATH:$HADOOP_HOME/sbin生效文件：source /etc/profileHadoop的目录结构bin目录：存放对Hadoop相关服务（HDFS和YARN）进行操作的脚本etc目录：Hadoop的配置目录，存放Hadoop的配置文件lib目录：存放Hadoop的本地库（对数据进行压缩解压功能）sbin目录：存放启动或者停止Hadoop相关服务的脚本share目录：存放hadoop的jar包，官方文档和案例Hadoop的运行模式​ 本地模式，伪分布式模式，完成分布式模式一，本地模式官方Grep案例在hadoop-2.7.2文件下面创建一个input文件夹复制文件到input文件夹里面执行share文件夹下的MapReduce程序bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar grep input output ‘dfs[a-z.]+’查看输出结果cat output/*官方WordCount案例（计算单词个数）创建文件夹（wcinput）在该文件夹创建并编辑文件内容执行hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount wcinput wcoutput查看结果hadoop-2.7.2]$ cat wcoutput/part-r-00000二，伪分布式运行模式启动HDFS并运行MapReduce程序配置集群hadoop-env.sh(添加jdk路径)export JAVA_HOME=/opt/module/jdk1.8.0_144core-site.xmlfs.defaultFShdfs://hadoop101:9000hadoop.tmp.dir/opt/module/hadoop-2.7.2/data/tmphdfs-site.xmldfs.replication1启动集群格式化NameNode（第一次启动时格式化，以后就不要格式化bin/hdfs namenode -format启动NameNodesbin/hadoop-daemon.sh start namenode启动DataNodesbin/hadoop-daemon.sh start datanode查看集群web访问默认端口：50070打开失败：https://www.cnblogs.com/zlslch/p/6604189.htmllog日志：/opt/module/hadoop-2.7.2/logs不能一直格式化NameNode原因会产生新的集群id，导致NameNode和DataNode的集群id不一致，集群找不到数据，所以格式化前先删除data和log日志操作集群（wordcount）执行操作和本地模式一样启动YARN并运行MapReduce程序配置集群yarn-env.sh(添加路径)export JAVA_HOME=/opt/module/jdk1.8.0_144配置yarn-site.xmlyarn.nodemanager.aux-servicesmapreduce_shuffleyarn.resourcemanager.hostnamehadoop101mapred-env.sh(添加jdk路径)(对mapred-site.xml.template重新命名为) mapred-site.xmlmapreduce.framework.nameyarn启动集群启动前必须先启动NameNode和DataNode启动ResourceManagersbin/yarn-daemon.sh start resourcemanager启动NodeManagersbin/yarn-daemon.sh start nodemanager集群操作yarn访问端口：8088删除文件系统的ouput文件bin/hdfs dfs -rm -R /user/kiedong/output执行MapReduce程序bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/atguigu/input /user/atguigu/output配置历史服务器配置mapred-site.xml,添加mapreduce.jobhistory.addresshadoop101:10020mapreduce.jobhistory.webapp.addresshadoop101:19888启动历史服务器sbin/mr-jobhistory-daemon.sh start historyserver端口：19888配置日志的聚集日志聚集的概念：应用程序运行完成以后，程序运行日志上传到HDFS系统上日志聚集的好处：方便开发调试注意：开启此功能，需要重新启动NodeManager，ResourceManager和HistoryManageryarn-site.xmlyarn.log-aggregation-enabletrueyarn.log-aggregation.retain-seconds604800关闭,然后NodeManager 、ResourceManager和HistoryManager执行WordCount案例查看日志端口：19888完全分布式运行模式（重点）主要步骤：准备三台客户机（关闭防火墙，静态ip，主机名称）安装JDK配置环境变量安装Hadoop配置环境变量配置集群单点启动配置ssh群起并测试集群编写集群分发脚本xsyncscp（secure copy）安全拷贝scp可以实现服务器与服务器之间的数据拷贝语法:将hadoop101传给hadoop102scp -r /opt/module root@hadoop102:/opt/modulersync远程同步工具主要用于备份和镜像。与scp区别：rsync只对差异性文件做更新。scp是复制所有文件rsync -rvl /opt/software root@hadoop102:/opt/software-r 递归 -v显示复制过程 -l拷贝符号连接xsync集群分发脚本（本集群使用）需求：循环复制文件到所有节点的相同目录下在home/用户名/bin这个目录下存放脚本，这样次用户可以在系统任何地方直接执行编写代码：vim xsync12345678910111213141516171819202122232425#!/bin/bash#1 获取输入参数个数，如果没有参数，直接退出pcount=$#if((pcount==0)); thenecho no args;exit;fi#2 获取文件名称p1=$1fname=`basename $p1`echo fname=$fname#3 获取上级目录到绝对路径pdir=`cd -P $(dirname $p1); pwd`echo pdir=$pdir#4 获取当前用户名称user=`whoami`#5 循环for((host=103; host&lt;105; host++)); do echo ------------------- hadoop$host -------------- rsync -rvl $pdir/$fname $user@hadoop$host:$pdirdone修改脚本xsync具有执行权限chomod 777 xsync配置集群核心配置文件core-site.xmlfs.defaultFShdfs://hadoop102:9000hadoop.tmp.dir/opt/module/hadoop-2.7.2/data/tmpHDFS配置文件hadoop-en.sh：配置环境变量hdfs-site.xmldfs.replication3dfs.namenode.secondary.http-addresshadoop104:50090YARN配置文件yarn-env.sh：配置环境变量yarn-site.xmlyarn.nodemanager.aux-servicesmapreduce_shuffleyarn.resourcemanager.hostnamehadoop103MapReduce配置文件mapred-env.sh：配置环境变量配置mapred-env.shcp mapred-site.xml.template mapred-site.xmlmapreduce.framework.nameyarn集群单点启动第一次启动，需要格式化NameNodehadoop namenode -format在hadoop102上启动NameNodehadoop-daemon.sh start namenode在hadoop102,103,104分别启动DataNodessh无密码登陆配置原理将A服务器生成的公钥拷贝给B服务器，当A将数据用私钥A加密，则B用A的公钥解密，并将数据用公钥加密给A生成公钥和私钥ssh-keygen -t rsa将公钥拷贝到免密的目标机器上ssh-copy-id hadoop102ssh-copy-id hadoop103ssh-copy-id hadoop104注意：root用户需要再进行一次拷贝，在hadoop103生成公私钥拷贝给其他机器.ssh文件夹下文件功能解释known_hosts:记录ssh访问过计算机的公钥id_rsa : 生成的私钥id_rsa.pub:生成的公钥authorized_keys ： 存放授权过得无密登录服务器公钥群起集群配置slaves，并同步slaveshadoop102hadoop103hadoop104启动集群第一次先格式化NameNode（先停止以前运行的namenode和datanode，然后删除data和log数据）启动sbin/start-dfs.sh (hadoop102上)sbin/start-yarn.sh（hadoop03上）","categories":[{"name":"部署","slug":"部署","permalink":"http://kiedeng.github.io/categories/%E9%83%A8%E7%BD%B2/"}],"tags":[{"name":"Hadoop","slug":"Hadoop","permalink":"http://kiedeng.github.io/tags/Hadoop/"},{"name":"大数据","slug":"大数据","permalink":"http://kiedeng.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}]},{"title":"Linux安装与配置","slug":"Linux安装与配置","date":"2020-02-10T05:35:12.000Z","updated":"2020-02-11T02:47:13.265Z","comments":true,"path":"2020/02/10/Linux安装与配置/","link":"","permalink":"http://kiedeng.github.io/2020/02/10/Linux%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/","excerpt":"","text":"安装时注意事项(用VMware安装centos[大数据虚拟机])检查BIOS虚拟化支持内存默认设置为2048MB最大磁盘大小默认为20GB是否对CD媒体进行测试，直接跳过Skip创建自定义分区(都是标准分区)boot 默认： 100MBwap 默认：2048MB/ 默认：15360自定义系统软件基本系统：兼容程序库；基本应用程序：互联网浏览器桌面：除了KDE,其余都选语言支持：中文支持Kdump去掉查看网络IP和网关编辑 -&gt; 虚拟网络编辑器 -&gt; NAT模式 即可看到子网IPNET设置可以看到网关设置IP自动获取登录后，通过界面来设置自动获取指定固定ip​ 直接修改配置文件来指定IP,并可以连接到外网(程序员推荐)，编辑 vi /etc/sysconfig/network-scripts/ifcfg-eth0​ 要求：将ip地址配置的静态的，ip地址为192.168.xxx.xxx1234567891011121314DEVICE&#x3D;eth0 #接口名（设备,网卡）HWADDR&#x3D;00:0C:2x:6x:0x:xx #MAC地址 TYPE&#x3D;Ethernet #网络类型（通常是Ethemet）UUID&#x3D;926a57ba-92c6-4231-bacb-f27e5e6a9f44 #随机id#系统启动的时候网络接口是否有效（yes&#x2F;no）ONBOOT&#x3D;yes # IP的配置方法[none|static|bootp|dhcp]（引导时不使用协议|静态分配IP|BOOTP协议|DHCP协议）BOOTPROTO&#x3D;static #IP地址IPADDR&#x3D;192.168.189.130 #网关 GATEWAY&#x3D;192.168.189.2 #域名解析器DNS1&#x3D;192.168.189.2重启网络服务或者重启系统生效：service network restart 、reboot修改主机名查看当前主机名：hostname修改主机名：/etc/hostname修改主机映射文件：vim /etc/sysconfig/network1234NETWORKING&#x3D;yesNETWORKING_IPV6&#x3D;noHOSTNAME&#x3D; hadoop &#x2F;&#x2F;写入新的主机名注意：主机名称不要有“_”下划线修改ip与主机的映射：/etc/hosts1192.168.102.130 hadoopWindows设置本地dns解析C:\\Windows\\System32\\drivers\\etc\\hosts添加内容：192.168.102.130 hadoop","categories":[{"name":"部署","slug":"部署","permalink":"http://kiedeng.github.io/categories/%E9%83%A8%E7%BD%B2/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://kiedeng.github.io/tags/Linux/"},{"name":"VMware","slug":"VMware","permalink":"http://kiedeng.github.io/tags/VMware/"},{"name":"centos","slug":"centos","permalink":"http://kiedeng.github.io/tags/centos/"}]},{"title":"git的使用","slug":"git的使用","date":"2020-02-10T03:44:17.000Z","updated":"2020-02-10T05:13:33.539Z","comments":true,"path":"2020/02/10/git的使用/","link":"","permalink":"http://kiedeng.github.io/2020/02/10/git%E7%9A%84%E4%BD%BF%E7%94%A8/","excerpt":"","text":"Git的优势：大部分操作在本地完成，不需要联网完整性保证尽可能添加数据而不是删除或修改数据分支操作非常快捷流畅与Linux命令全面兼容代码托管中心代码托管中心的任务：维护远程库局域网环境：GitLab服务器外网环境：GitHub，码云Git命令行操作本库初始化（选择文件夹进行初始化）1git init设置签名作用：区分不同开发者的身份辨析：这里设置的签名和登录远程库(代码托管中心)的账号、密码没有任何关系。命令：123456789项目级别&#x2F;仓库级别：仅在当前本地库范围内有效git config user.name kiedenggit config user.email kiedeng@qq.com信息保存位置：.&#x2F;.git&#x2F;config 文件系统用户级别：登录当前操作系统的用户范围git config --global user.name tom_glbgit config --global goodMorning_pro@atguigu.com信息保存位置：~&#x2F;.gitconfig 文件基本操作123456789101112# 状态查看git status# 添加 (将工作区的文件或目录提交到暂存区)git [filename]# 提交 (将暂存区的文件提交的本地库)git commit -m &quot;commit message&quot; [filename]# 查看历史版本git loggit reflog# 版本的前进与后退（基于索引值操作）git reset --hard [局部索引值]git reset --hard a6ace91分支管理分支：在版本控制过程中，使用多条线同时推进多个任务。12345678# 创建分支git branch [分支名]# 查看分支git branch -v# 切换分支git checkout [分支名]# 合并git merge [被和并的分支名]GitHub12345678# 查看所有远程地址别名git remote -v# 创建远程库地址别名git remote add [别名] [远程地址]# 推送 (将本地库上传到github仓库)git push [别名] [分支名]# 克隆(这样克隆：把远程库下载到本地，初始化本地库，创建别名)git origin [远程地址]","categories":[{"name":"使用手册","slug":"使用手册","permalink":"http://kiedeng.github.io/categories/%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://kiedeng.github.io/tags/Git/"},{"name":"GitHub","slug":"GitHub","permalink":"http://kiedeng.github.io/tags/GitHub/"}]},{"title":"hexo搭建","slug":"hexo搭建","date":"2020-02-10T01:10:23.000Z","updated":"2020-02-10T03:42:36.626Z","comments":true,"path":"2020/02/10/hexo搭建/","link":"","permalink":"http://kiedeng.github.io/2020/02/10/hexo%E6%90%AD%E5%BB%BA/","excerpt":"","text":"官方文档： 链接一，使用Windows完成本地部署安装node.js和git,默认安装方式即可安装hexo，打开cmd执行1npm install hexo-cli -gcmd移动到选择的一个文件夹，比如：d:\\blog(下面全部假设初始化在本路径),进行hexo的初始化1hexo init blog在此目录安装1npm install启动服务器，访问的默认地址：http://localhost:4000/1hexo s二，使用GitHub完成远程部署注册，登录github新建仓库步骤如下：点击右上角+号，new repository，在Repository name处填 （你的gitusername）.github.io（比如：kiedeng.github.io），然后直接点Create repository在你初始化的路径（比如的d:\\blog）下有一个_config.xml,用记事本打开此文件，最后几行添加github信息#(对于repo，比如：https://github.com/kiedeng/kiedeng.github.io.git)deploy:type: gitrepo: https://github.com/( yours username)/（your username）.github.io.gitbranck: master将cmd移动到d:\\blog下，安装1npm install hexo-deployer-git --save执行123456# 清理hexo clean# 生成静态文件hexo generate# 上传hexo deploy在弹出的git窗口中输入你的GitHub邮箱和密码部署完成，等待一会，使用比如：http://kiedeng.github.io/访问三，更换hexo主题找到hexo的主题推荐主题：链接选择一款，到达它们的github仓库（如果该主题作者的有文档，按文档即可完成更换）将该主题下载下来（克隆也行），解压到d:\\blog\\themes,将该文件目录更名，比如：kiedeng打开d:\\blog_config.xml,将theme: 后面的参数改为1theme: kiedeng然后就可以部署和上传了四，绑定域名选择一个合适的域名，买下域名在域名的详细界面，打开解析设置dns解析在d:\\blog\\source目录下，新建一个叫CNAME的文件（强调：不能有后缀），里面的内容为你的域名，比如:www.kangdong.store等待一小会即可进行访问","categories":[{"name":"部署","slug":"部署","permalink":"http://kiedeng.github.io/categories/%E9%83%A8%E7%BD%B2/"}],"tags":[{"name":"教程","slug":"教程","permalink":"http://kiedeng.github.io/tags/%E6%95%99%E7%A8%8B/"},{"name":"hexo","slug":"hexo","permalink":"http://kiedeng.github.io/tags/hexo/"}]}]}